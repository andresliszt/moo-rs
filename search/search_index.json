{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"moo-rs","text":"<p>Evolution is a mystery</p> <p> </p>"},{"location":"index.html#overview","title":"Overview","text":"<p><code>moo-rs</code> is a project for solving multi-objective optimization problems with evolutionary algorithms, combining:</p> <ul> <li>moors: a pure-Rust crate for high-performance implementations of genetic algorithms</li> <li>pymoors: a Python extension crate (via pyo3) exposing <code>moors</code> algorithms with a Pythonic API</li> </ul> <p>Inspired by the amazing Python project pymoo, <code>moo-rs</code> delivers both the speed of Rust and the ease-of-use of Python.</p>"},{"location":"index.html#key-features","title":"Key Features","text":"<ul> <li>Implemented in Rust for superior performance.</li> <li>Accessible in Python through pyo3.</li> <li>Specialized in solving multi-objective optimization problems using genetic algorithms.</li> </ul>"},{"location":"index.html#available-multi-objective-algorithms","title":"Available Multi-Objective Algorithms","text":"<p>A concise index of the currently available algorithms.</p> Algorithm Description NSGA-II Baseline Pareto-based MOEA with fast non-dominated sorting and crowding distance. Robust, widely used for 2\u20133 objectives. NSGA-III Many-objective extension of NSGA-II using reference points to maintain diversity and guide convergence. IBEA Indicator-Based EA that optimizes a quality indicator (e.g., hypervolume/\u03b5-indicator) to drive selection. SPEA-II Strength Pareto EA with enhanced fitness assignment, density estimation (k-NN), and external archive. AGEMOEA Approximation-guided MOEA that directly improves the Pareto-front approximation via set-level indicators. RNSGA-II Reference-point oriented NSGA-II variant; biases the search toward regions of interest while preserving diversity. REVEA Reference vector/region\u2013guided evolutionary algorithm using directional vectors to balance diversity and convergence. Custom Defined Algorithms User defined algorithms by defining selection and survival operators"},{"location":"index.html#introduction-to-multi-objective-optimization","title":"Introduction to Multi-Objective Optimization","text":"<p>Multi-objective optimization refers to a set of techniques and methods designed to solve problems where multiple objectives must be satisfied simultaneously. These objectives are often conflicting, meaning that improving one may deteriorate another. For instance, one might seek to minimize production costs while maximizing product quality at the same time.</p>"},{"location":"index.html#general-formulation","title":"General Formulation","text":"<p>A multi-objective optimization problem can be formulated in a generic mathematical form. If we have \\(k\\) objective functions to optimize, it can be expressed as:</p> \\[ \\begin{aligned} &amp;\\min_x \\quad (f_1(x), f_2(x), \\dots, f_k(x)) \\\\ &amp;\\text{subject to:} \\\\ &amp;g_i(x) \\leq 0, \\quad i = 1, \\dots, m \\\\ &amp;h_j(x) = 0, \\quad j = 1, \\dots, p \\end{aligned} \\] <p>Where: - \\( x \\) represents the set of decision variables. - \\( f_i(x) \\) are the objective functions. - \\( g_i(x) \\leq 0 \\) and \\( h_j(x) = 0 \\) represent the constraints_fn of the problem (e.g., resource limits, quality requirements, etc.).</p> <p>Unlike single-objective optimization, here we seek to optimize all objectives simultaneously. However, in practice, there is no single \u201cbest\u201d solution for all objectives. Instead, we look for a set of solutions known as the Pareto front or Pareto set.</p>"},{"location":"index.html#quickstart","title":"Quickstart","text":"<p>The well known ZTD3 problem solved with the NSGA-II algorithm!</p> RustPython <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Nsga2,\n    RandomSamplingFloat,\n    GaussianMutation,\n    ExponentialCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_zdt3(population: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the ZDT3 objectives in a fully vectorized manner.\n    \"\"\"\n    # First objective: f1 is simply the first column.\n    f1 = population[:, 0]\n    n = population.shape[1]\n    # Compute g for each candidate: g = 1 + (9/(n-1)) * sum(x[1:])\n    g = 1 + (9 / (n - 1)) * np.sum(population[:, 1:], axis=1)\n    # Compute h for each candidate: h = 1 - sqrt(f1/g) - (f1/g)*sin(10*pi*f1)\n    h = 1 - np.sqrt(f1 / g) - (f1 / g) * np.sin(10 * np.pi * f1)\n    # Compute the second objective: f2 = g * h\n    f2 = g * h\n    return np.column_stack((f1, f2))\n\n\ndef zdt3_theoretical_front():\n    \"\"\"\n    Compute the theoretical Pareto front for ZDT3.\n\n    Returns:\n        f1_theo (np.ndarray): f1 values on the theoretical front.\n        f2_theo (np.ndarray): Corresponding f2 values.\n\n    Instead of using a dense linspace, we sample only a few points per interval to\n    clearly illustrate the discontinuous nature of the front.\n    \"\"\"\n    # Define the intervals for f1 where the Pareto front exists\n    intervals = [\n        (0.0, 0.0830015349),\n        (0.1822287280, 0.2577623634),\n        (0.4093136748, 0.4538828821),\n        (0.6183967944, 0.6525117038),\n        (0.8233317983, 0.85518),\n    ]\n\n    f1_theo = np.array([])\n    f2_theo = np.array([])\n\n    # Use a small number of points per interval (e.g., 20) to highlight the discontinuities.\n    for start, end in intervals:\n        f1_vals = np.linspace(start, end, 20)\n        f2_vals = 1 - np.sqrt(f1_vals) - f1_vals * np.sin(10 * np.pi * f1_vals)\n        f1_theo = np.concatenate((f1_theo, f1_vals))\n        f2_theo = np.concatenate((f2_theo, f2_vals))\n\n    return f1_theo, f2_theo\n\n\n# Set up the NSGA2 algorithm with the above definitions\nalgorithm = Nsga2(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=ExponentialCrossover(exponential_crossover_rate=0.75),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_zdt3,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-5),\n    num_vars=30,\n    population_size=200,\n    num_offsprings=200,\n    num_iterations=300,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    verbose=False,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\n\n# Extract the obtained fitness values (each row is [f1, f2])\nobtained_fitness = best.fitness\nf1_found = obtained_fitness[:, 0]\nf2_found = obtained_fitness[:, 1]\n\n# Compute the theoretical Pareto front for ZDT3\nf1_theo, f2_theo = zdt3_theoretical_front()\n\n# Plot the theoretical Pareto front and the obtained front\nplt.figure(figsize=(10, 6))\n# Plot theoretical front as markers (e.g., diamonds) to show discontinuities.\nplt.scatter(\n    f1_theo, f2_theo, marker=\"D\", color=\"blue\", label=\"Theoretical Pareto Front\"\n)\n# Plot obtained front as red circles.\nplt.scatter(f1_found, f2_found, c=\"r\", marker=\"o\", s=10, label=\"Obtained Front\")\nplt.xlabel(\"$f_1$\", fontsize=14)\nplt.ylabel(\"$f_2$\", fontsize=14)\nplt.title(\"ZDT3 Pareto Front: Theoretical vs Obtained\", fontsize=16)\nplt.legend()\nplt.grid(True)\n</code></pre> <p></p> <pre><code>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::Nsga2Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, RandomSamplingFloat, ExponentialCrossover},\n    genetic::Population\n};\nuse plotters::prelude::*;\n\n/// Evaluate the ZDT3 objectives in a fully vectorized manner.\nfn evaluate_zdt3(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    // First objective: f1 is simply the first column.\n    // NOTE: We clamp to [0,1] during evaluation to keep the domain consistent with ZDT3.\n    // This mirrors the Python setup where variables are constrained to [0,1].\n    let n = genes.nrows();\n    let m = genes.ncols();\n\n    let clamped = genes.mapv(|v| v.clamp(0.0, 1.0));\n    let f1 = clamped.column(0).to_owned();\n\n    // Compute g for each candidate: g = 1 + (9/(n-1)) * sum(x[1:])\n    let tail = clamped.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);\n\n    // Compute h for each candidate: h = 1 - sqrt(f1/g) - (f1/g)*sin(10*pi*f1)\n    let ratio = &amp;f1 / &amp;g;\n    let sin_term = f1.mapv(|v| (10.0 * std::f64::consts::PI * v).sin());\n    let h = 1.0 - ratio.mapv(|r| r.sqrt()) - &amp;(&amp;ratio * &amp;sin_term);\n\n    // Compute the second objective: f2 = g * h\n    let f2 = &amp;g * &amp;h;\n\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result\n}\n\n// Create constraints using the macro impl_constraints_fn\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\n\n/// Compute the theoretical Pareto front for ZDT3.\n///\n/// Returns:\n///     f1_theo (np.ndarray): f1 values on the theoretical front.\n///     f2_theo (np.ndarray): Corresponding f2 values.\n///\n/// Instead of using a dense linspace, we sample only a few points per interval to\n/// clearly illustrate the discontinuous nature of the front.\nfn zdt3_theoretical_front() -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    // Define the intervals for f1 where the Pareto front exists\n    let intervals: &amp;[(f64, f64)] = &amp;[\n        (0.0, 0.0830015349),\n        (0.1822287280, 0.2577623634),\n        (0.4093136748, 0.4538828821),\n        (0.6183967944, 0.6525117038),\n        (0.8233317983, 0.85518),\n    ];\n\n    let mut f1_theo: Vec&lt;f64&gt; = Vec::new();\n    let mut f2_theo: Vec&lt;f64&gt; = Vec::new();\n\n    // Use a small number of points per interval (e.g., 20) to highlight the discontinuities.\n    for (start, end) in intervals.iter().copied() {\n        let steps = 20usize;\n        for i in 0..steps {\n            let t = i as f64 / (steps as f64 - 1.0);\n            let f1 = start + t * (end - start);\n            let f2 = 1.0 - f1.sqrt() - f1 * (10.0 * std::f64::consts::PI * f1).sin();\n            f1_theo.push(f1);\n            f2_theo.push(f2);\n        }\n    }\n\n    (f1_theo, f2_theo)\n}\n\n// Set up the NSGA2 algorithm with the above definitions\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let mut algorithm = Nsga2Builder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(ExponentialCrossover::new(0.75))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-5))\n        .fitness_fn(evaluate_zdt3)\n        .constraints_fn(BoundConstraints)\n        .num_vars(30)\n        .population_size(200)\n        .num_offsprings(200)\n        .num_iterations(300)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(42)\n        .build()\n        .expect(\"Failed to build NSGA2\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"NSGA2 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// Compute the theoretical Pareto front for ZDT3\nlet (f1_theo, f2_theo) = zdt3_theoretical_front();\n\n// Plot the theoretical Pareto front and the obtained front\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    // Compute min/max from actual data\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n\n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n\n    // Add a small margin (5%)\n    let xr = (x_max - x_min);\n    let yr = (y_max - y_min);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"ZDT3 Pareto Front: Theoretical vs Obtained\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    // Plot theoretical front as markers (e.g., diamonds) to show discontinuities.\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));\n\n    // Plot obtained front as red circles.\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\n// Emit as rich output for evcxr\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</code></pre> <p></p>"},{"location":"index.html#advantages-for-multi-objective-optimization","title":"Advantages for Multi-Objective Optimization","text":"<ol> <li>Natural Handling of Multiple Objectives: By operating on a population of solutions, GAs can maintain an approximation to the Pareto front during execution.</li> <li>Flexibility: They can be easily adapted to different kinds of problems (discrete, continuous, constrained, etc.).</li> <li>Robustness: They tend to perform well in the presence of noise or uncertainty in the problem, offering acceptable performance under less-than-ideal conditions.</li> </ol>"},{"location":"index.html#beauty-and-misbehavior-optimization-problem","title":"Beauty and Misbehavior Optimization Problem","text":"<p>In this unique optimization problem, there is only one individual who optimizes both beauty and misbehavior at the same time: my little dog Arya!</p> <p>Arya not only captivates with her beauty, but she also misbehaves in the most adorable way possible. This problem serves as a reminder that sometimes the optimal solution is as heartwarming as it is delightfully mischievous.</p>"},{"location":"__init__.html","title":"init","text":""},{"location":"development.html","title":"Development Guide","text":""},{"location":"development.html#prerequisites","title":"Prerequisites","text":"<p>Before you proceed, make sure you have Rust installed. We recommend using rustup for an easy setup:</p> <pre><code># For Linux/Mac:\ncurl --proto '=https' --tlsv1.2 https://sh.rustup.rs -sSf | sh\n\n# For Windows:\n# Download and run the installer:\n# https://rustup.rs/\n</code></pre> <p>Also <code>pymoors</code> uses uv. Make sure it\u2019s available on your <code>PATH</code> so the <code>make</code> commands can run properly.</p> <p>Note: <code>moors</code> doesn\u2019t use <code>uv</code></p>"},{"location":"development.html#moors-vs-pymoors","title":"moors vs pymoors","text":"<pre><code>moo-rs/\n\u251c\u2500\u2500 moors/    \u2190 Rust crate\n\u2514\u2500\u2500 pymoors/  \u2190 Python/pyo3 crate\n</code></pre> <p>moors - A pure-Rust crate implementing multi-objective evolutionary algorithms and operators entirely in Rust. - Mathematical core: defines fitness functions, sampling, crossover, mutation and duplicate cleaning as Rust structs and closures. - High performance: leverages <code>ndarray</code>, <code>faer</code> and <code>rayon</code> for efficient numeric computation and parallelism. - Rust-native API: consumed via <code>Cargo.toml</code> without FFI overhead.</p> <p>pymoors - A Python extension crate: uses pyo3 to expose the complete <code>moors</code> core to Python. - Pythonic interface: provides classes and functions that work seamlessly with NumPy arrays and the Python scientific ecosystem. - Rapid prototyping: enables experimentation in notebooks or scripts while delegating compute-intensive work to Rust. - Easy installation: <code>pip install pymoors</code> compiles and installs the bindings via Maturin.</p>"},{"location":"development.html#working-in-pymoors","title":"Working in <code>pymoors</code>","text":"<pre><code># dev build &amp; install (uv + maturin)\nmake build-dev\n\n# release build &amp; install\nmake build-release\n\n# format &amp; lint Python (ruff)\nmake lint-python\n\n# lint Rust bindings\nmake lint-rust\n\n# run tests (excluding benchmarks)\nmake test\n\n# run benchmark suite\nmake test-benchmarks\n\n# build documentation site (mkdocs)\nmake docs\n</code></pre>"},{"location":"development.html#working-in-moors","title":"Working in <code>moors</code>","text":"<pre><code># debug build\nmake build-dev\n\n# optimized build\nmake build-release\n\n# run tests\nmake test\n\n# format code (cargo fmt)\nmake fmt\n\n# check formatting / lint Rust\nmake lint\n\n# run benchmarks\nmake bench\n</code></pre>"},{"location":"development.html#from-the-repo-root","title":"From the Repo Root","text":"<pre><code># run pymoors dev build from root\nmake pymoors-build-dev\n\n# run pymoors lint-Python from root\nmake pymoors-lint-python\n\n# run pymoors tests from root\nmake pymoors-test\n\n# run moors tests from root\nmake moors-test\n\n# run moors benchmarks from root\nmake moors-bench\n</code></pre> <p>Use <code>make help</code> at root to list all available <code>pymoors-&lt;target&gt;</code> and <code>moors-&lt;target&gt;</code> commands.</p>"},{"location":"development.html#contributing","title":"Contributing","text":"<pre><code># Fork &amp; clone the repo\ngit clone https://github.com/your-username/moo-rs.git\ncd moo-rs\n\n# Create a feature branch\ngit checkout -b feat/your-feature-name\n\n# Commit:\n#   Use imperative messages, e.g. \"feat: add new operator\" or \"fix: correct off-by-one\"\n#   Reference issues: \"Fixes #123\"\n\n# Push &amp; open PR:\ngit push origin feat/your-feature-name\n</code></pre>"},{"location":"macros.html","title":"Macros","text":"In\u00a0[\u00a0]: Copied! <pre>def define_env(env):\n    \"\"\"\n    Defines a macro `docs_rs(item_type, item_name)` that returns\n    the URL to docs.rs/moors/&lt;version&gt;/moors/&lt;type&gt;.&lt;item&gt;.html\n    \"\"\"\n    version = env.variables.get(\"moors_crate_version\")\n    base = f\"https://docs.rs/moors/{version}/moors/\"\n\n    @env.macro\n    def docs_rs(item_type: str, path: str, label: str | None = None) -&gt; str:\n        parts = path.split(\".\")\n        name, *rest = parts[::-1]\n        # reconstruct the URL path\n        if rest:\n            parts_url = \"/\".join(parts[:-1]) + f\"/{item_type}.{name}.html\"\n        else:\n            parts_url = f\"{item_type}.{name}.html\"\n        url = base + parts_url\n        text = label or name\n        # return raw HTML\n        return f'&lt;a href=\"{url}\" target=\"_blank\" rel=\"noopener\"&gt;{text}&lt;/a&gt;'\n</pre> def define_env(env):     \"\"\"     Defines a macro `docs_rs(item_type, item_name)` that returns     the URL to docs.rs/moors//moors/..html     \"\"\"     version = env.variables.get(\"moors_crate_version\")     base = f\"https://docs.rs/moors/{version}/moors/\"      @env.macro     def docs_rs(item_type: str, path: str, label: str | None = None) -&gt; str:         parts = path.split(\".\")         name, *rest = parts[::-1]         # reconstruct the URL path         if rest:             parts_url = \"/\".join(parts[:-1]) + f\"/{item_type}.{name}.html\"         else:             parts_url = f\"{item_type}.{name}.html\"         url = base + parts_url         text = label or name         # return raw HTML         return f'{text}'"},{"location":"reference.html","title":"Reference","text":"<p>::: pymoors</p>"},{"location":"getting_started/installation.html","title":"Installation","text":"RustPython <p>Make sure your rust version is greater than or equal to <code>1.76.0</code>, and then you can install moors directly from crates.io doing</p> <pre><code>cargo add moors\n</code></pre> <p>Make sure your python version is greater than or equal to <code>3.10</code> and then can install pymoors directly from PyPI doing</p> <pre><code>pip install pymoors\n</code></pre>"},{"location":"getting_started/installation.html#development","title":"Development","text":"<pre><code># Fork &amp; clone the repo\ngit clone https://github.com/your-username/moo-rs.git\n# Go directly to the pymoors/moors directory\ncd moo-rs/pymoors # or cd moo-rs/moors\n# Build in dev mod\nmake build-dev\n# or build in release mode\nmake build-release\n</code></pre> <p>For detailed requirements to install from source, see the Developer Guide.</p>"},{"location":"getting_started/knapsack.html","title":"Example: The Multi-Objective Knapsack Problem","text":"<p>The multi-objective knapsack problem is a classic example in optimization where we aim to select items, each with its own benefits and costs, subject to certain constraints_fn (e.g., weight capacity). In the multi-objective version, we want to optimize more than one objective function simultaneously\u2014often, maximizing multiple benefits or qualities at once.</p>"},{"location":"getting_started/knapsack.html#mathematical-formulation","title":"Mathematical Formulation","text":"<p>Suppose we have \\(n\\) items. Each item \\(i\\) has: - A profit \\(p_i\\). - A quality \\(q_i\\). - A weight \\(w_i\\).</p> <p>Let \\((x_i)\\) be a binary decision variable where \\(x_i = 1\\) if item \\(i\\) is selected and \\(x_i = 0\\) otherwise. We define a knapsack capacity \\(C\\). A common multi-objective formulation for this problem is:</p> \\[ \\begin{aligned} &amp;\\text{Maximize} &amp;&amp; f_1(x) = \\sum_{i=1}^{n} p_i x_i \\\\ &amp;\\text{Maximize} &amp;&amp; f_2(x) = \\sum_{i=1}^{n} q_i x_i \\\\ &amp;\\text{subject to} &amp;&amp; \\sum_{i=1}^{n} w_i x_i \\leq C,\\\\ &amp; &amp;&amp; x_i \\in \\{0, 1\\}, \\quad i = 1,\\dots,n. \\end{aligned} \\] RustPython <pre><code>use ndarray::{Array1, Array2, Axis, stack, Ix1, Ix2};\nuse ordered_float::OrderedFloat;\nuse std::collections::HashSet;\n\nuse moors::{\n    algorithms::{Nsga2, Nsga2Builder},\n    duplicates::ExactDuplicatesCleaner,\n    operators::{BitFlipMutation, RandomSamplingBinary, SinglePointBinaryCrossover},\n    genetic::Population\n};\n\n// problem data\nconst PROFITS: [f64; 5] = [2.0, 3.0, 6.0, 1.0, 4.0];\nconst QUALITIES: [f64; 5] = [5.0, 2.0, 1.0, 6.0, 4.0];\nconst WEIGHTS: [f64; 5] = [2.0, 3.0, 6.0, 2.0, 3.0];\nconst CAPACITY: f64 = 7.0;\n\nfn fitness_knapsack(populationulation_genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    // Calculate total profit\n    let profits_arr = Array1::from_vec(PROFITS.to_vec());\n    let profit_sum = populationulation_genes.dot(&amp;profits_arr);\n\n    // Calculate total quality\n    let qualities_arr = Array1::from_vec(QUALITIES.to_vec());\n    let quality_sum = populationulation_genes.dot(&amp;qualities_arr);\n\n    // We want to maximize profit and quality,\n    // so in moors we minimize the negative values\n    stack(Axis(1), &amp;[(-&amp;profit_sum).view(), (-&amp;quality_sum).view()]).expect(\"stack failed\")\n}\n\nfn constraints_knapsack(populationulation_genes: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    // Calculate total weight\n    let weights_arr = Array1::from_vec(WEIGHTS.to_vec());\n    // Inequality constraint: weight_sum &lt;= capacity\n    populationulation_genes.dot(&amp;weights_arr) - CAPACITY\n}\n\n// NOTE: The clone is only needed for the notebook source of this file. Also, most of the cases\n// you don't need to specify the Population&lt;Ix2, Ix1&gt; signature\nlet population: Population&lt;Ix2, Ix1&gt; = {\n    let mut algorithm = Nsga2Builder::default()\n        .fitness_fn(fitness_knapsack)\n        .constraints_fn(constraints_knapsack)\n        .sampler(RandomSamplingBinary)\n        .crossover(SinglePointBinaryCrossover)\n        .mutation(BitFlipMutation::new(0.5))\n        .duplicates_cleaner(ExactDuplicatesCleaner)\n        .num_vars(5)\n        .population_size(16)\n        .num_offsprings(16)\n        .num_iterations(10)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .build()\n        .unwrap();\n\n    algorithm.run().expect(\"NSGA2 run failed\");\n\n    let population = algorithm.population().expect(\"populationulation should have been initialized\");\n    population.clone()\n};\n</code></pre> <pre><code>Warning: Only 15 offspring were generated out of the desired 16.\n</code></pre> <pre><code>// Get genes\n&gt;&gt;&gt; population.genes\n[[1.0, 0.0, 0.0, 1.0, 1.0],\n [1.0, 1.0, 0.0, 1.0, 0.0],\n [0.0, 1.0, 0.0, 0.0, 1.0],\n [1.0, 0.0, 0.0, 0.0, 1.0],\n [1.0, 0.0, 0.0, 1.0, 0.0],\n [0.0, 0.0, 0.0, 1.0, 1.0],\n [0.0, 0.0, 1.0, 0.0, 0.0],\n [1.0, 1.0, 0.0, 0.0, 0.0],\n [0.0, 1.0, 0.0, 1.0, 0.0],\n [0.0, 0.0, 0.0, 1.0, 0.0],\n [0.0, 0.0, 0.0, 0.0, 1.0],\n [1.0, 0.0, 0.0, 0.0, 0.0],\n [0.0, 1.0, 0.0, 0.0, 0.0],\n [0.0, 0.0, 0.0, 0.0, 0.0]], shape=[14, 5], strides=[5, 1], layout=Cc (0x5), const ndim=2\n</code></pre> <pre><code>// Get fitness\n&gt;&gt;&gt; population.fitness\n[[-7.0, -15.0],\n [-6.0, -13.0],\n [-7.0, -6.0],\n [-6.0, -9.0],\n [-3.0, -11.0],\n [-5.0, -10.0],\n [-6.0, -1.0],\n [-5.0, -7.0],\n [-4.0, -8.0],\n [-1.0, -6.0],\n [-4.0, -4.0],\n [-2.0, -5.0],\n [-3.0, -2.0],\n [-0.0, -0.0]], shape=[14, 2], strides=[2, 1], layout=Cc (0x5), const ndim=2\n</code></pre> <pre><code>// Get constraints\n&gt;&gt;&gt; population.constraints\n[0.0, 0.0, -1.0, -2.0, -3.0, -2.0, -1.0, -2.0, -2.0, -5.0, -4.0, -5.0, -4.0, -7.0], shape=[14], strides=[1], layout=CFcf (0xf), const ndim=1\n</code></pre> <pre><code>// Get rank (for Nsga2)\n&gt;&gt;&gt; population.constraints\n[0.0, 0.0, -1.0, -2.0, -3.0, -2.0, -1.0, -2.0, -2.0, -5.0, -4.0, -5.0, -4.0, -7.0], shape=[14], strides=[1], layout=CFcf (0xf), const ndim=1\n</code></pre> <p>Note that in this example there is just one individual with rank 0, i.e Pareto optimal. Algorithms in <code>moors</code> store all individuals with rank 0 in a special attribute <code>best</code></p> <pre><code>&gt;&gt;&gt; let best = population.best();\n&gt;&gt;&gt; best\nPopulation { genes: [[1.0, 0.0, 0.0, 1.0, 1.0]], shape=[1, 5], strides=[5, 1], layout=CFcf (0xf), const ndim=2, fitness: [[-7.0, -15.0]], shape=[1, 2], strides=[2, 1], layout=CFcf (0xf), const ndim=2, constraints: [0.0], shape=[1], strides=[1], layout=CFcf (0xf), const ndim=1, rank: Some([0], shape=[1], strides=[1], layout=CFcf (0xf), const ndim=1), survival_score: Some([inf], shape=[1], strides=[1], layout=CFcf (0xf), const ndim=1), constraint_violation_totals: Some([0.0], shape=[1], strides=[1], layout=CFcf (0xf), const ndim=1) }\n</code></pre> <pre><code>// Get the best individual (just 1 in this example)\n&gt;&gt;&gt; best.get(0)\nIndividual { genes: [1.0, 0.0, 0.0, 1.0, 1.0], shape=[5], strides=[1], layout=CFcf (0xf), const ndim=1, fitness: [-7.0, -15.0], shape=[2], strides=[1], layout=CFcf (0xf), const ndim=1, constraints: 0.0, shape=[], strides=[], layout=CFcf (0xf), const ndim=0, rank: Some(0), survival_score: Some(inf), constraint_violation_totals: Some(0.0) }\n</code></pre> <pre><code>import numpy as np\n\nfrom pymoors import (\n    Nsga2,\n    RandomSamplingBinary,\n    BitFlipMutation,\n    SinglePointBinaryCrossover,\n    ExactDuplicatesCleaner,\n)\nfrom pymoors.typing import TwoDArray\n\n\nPROFITS = np.array([2, 3, 6, 1, 4])\nQUALITIES = np.array([5, 2, 1, 6, 4])\nWEIGHTS = np.array([2, 3, 6, 2, 3])\nCAPACITY = 7\n\n\ndef knapsack_fitness(genes: TwoDArray) -&gt; TwoDArray:\n    # Calculate total profit\n    profit_sum = np.sum(PROFITS * genes, axis=1, keepdims=True)\n    # Calculate total quality\n    quality_sum = np.sum(QUALITIES * genes, axis=1, keepdims=True)\n\n    # We want to maximize profit and quality,\n    # so in pymoors we minimize the negative values\n    f1 = -profit_sum\n    f2 = -quality_sum\n    return np.column_stack([f1, f2])\n\n\ndef knapsack_constraint(genes: TwoDArray) -&gt; TwoDArray:\n    # Calculate total weight\n    weight_sum = np.sum(WEIGHTS * genes, axis=1, keepdims=True)\n    # Inequality constraint: weight_sum &lt;= capacity\n    return weight_sum - CAPACITY\n\n\nalgorithm = Nsga2(\n    sampler=RandomSamplingBinary(),\n    crossover=SinglePointBinaryCrossover(),\n    mutation=BitFlipMutation(gene_mutation_rate=0.5),\n    fitness_fn=knapsack_fitness,\n    constraints_fn=knapsack_constraint,\n    duplicates_cleaner=ExactDuplicatesCleaner(),\n    num_vars=5,\n    population_size=16,\n    num_offsprings=16,\n    num_iterations=10,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    verbose=False,\n)\n\nalgorithm.run()\n</code></pre> <p>In this small example, the algorithm finds a single solution on the Pareto front: selecting the items (A, D, E), with a profit of 7 and a quality of 15. This means there is no other combination that can match or exceed both objectives without exceeding the knapsack capacity (7).</p> <p>Once the algorithm finishes, it stores a <code>population</code> attribute that contains all the individuals evaluated during the search.</p> <pre><code>&gt;&gt;&gt; population = algorithm.population\n# Get genes\n&gt;&gt;&gt; population.genes\narray([[1., 0., 0., 1., 1.],\n       [1., 1., 0., 1., 0.],\n       [0., 1., 0., 0., 1.],\n       [1., 0., 0., 0., 1.],\n       [1., 0., 0., 1., 0.],\n       [0., 0., 0., 1., 1.],\n       [0., 0., 1., 0., 0.],\n       [1., 1., 0., 0., 0.],\n       [0., 1., 0., 1., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 1., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0.]])\n</code></pre> <pre><code># Get fitness\n&gt;&gt;&gt; population.fitness\narray([[ -7., -15.],\n       [ -6., -13.],\n       [ -7.,  -6.],\n       [ -6.,  -9.],\n       [ -3., -11.],\n       [ -5., -10.],\n       [ -6.,  -1.],\n       [ -5.,  -7.],\n       [ -4.,  -8.],\n       [ -2.,  -5.],\n       [ -4.,  -4.],\n       [ -1.,  -6.],\n       [ -3.,  -2.],\n       [ -0.,  -0.]])\n</code></pre> <pre><code># Get constraints\n&gt;&gt;&gt; population.constraints\narray([[ 0.],\n       [ 0.],\n       [-1.],\n       [-2.],\n       [-3.],\n       [-2.],\n       [-1.],\n       [-2.],\n       [-2.],\n       [-5.],\n       [-4.],\n       [-5.],\n       [-4.],\n       [-7.]])\n</code></pre> <pre><code># Get rank (for Nsga2)\n&gt;&gt;&gt; population.rank\narray([0, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 6], dtype=uint64)\n</code></pre> <pre><code>&gt;&gt;&gt; best = population.best\n&gt;&gt;&gt; best\n[&lt;pymoors.schemas.Individual at 0x1c6699386e0&gt;]\n</code></pre> <pre><code>&gt;&gt;&gt; best[0].genes\narray([1., 0., 0., 1., 1.])\n</code></pre> <pre><code>&gt;&gt;&gt; best[0].fitness\narray([ -7., -15.])\n</code></pre> <p>\u2139\ufe0f Note \u2013 Population Size and Duplicates</p> <p>Note that although the specified <code>population_size</code> was 16, the final population ended up being 13 individuals, of which 1 had <code>rank = 0</code>. This is because we used the <code>keep_infeasible=False</code> argument, removing any individual that did not satisfy the constraints_fn (in this case, the weight constraint). We also used a duplicate remover called <code>ExactDuplicatesCleaner</code> that eliminates all exact duplicates\u2014meaning whenever <code>genes1 == genes2</code> in every component.</p> <p>\ud83d\udca1 Tip \u2013 Variable Types in pymoors</p> <p>In pymoors, there is no strict enforcement of whether variables are integer, binary, or real. The core Rust implementation works with <code>f64</code> ndarrays. To preserve a specific variable type\u2014binary, integer, or real\u2014you must ensure that the genetic operators themselves maintain it.</p> <p>It is the user's responsibility to choose the appropriate genetic operators for the variable type in question. In the knapsack example, we use binary-style genetic operators, which is why the solutions are arrays of 0 s and 1 s.</p> <p>Info</p> <p>Note that although the specified <code>population_size</code> was 16, the final population ended up being 13 individuals, of which 1 had <code>rank = 0</code>. This is because we used the <code>keep_infeasible</code> argument was set in false, removing any individual that did not satisfy the constraints_fn (in this case, the weight constraint). We also used a duplicate remover called <code>ExactDuplicatesCleaner</code> that eliminates all exact duplicates\u2014meaning whenever <code>genes1 == genes2</code> in every component.</p> <p>\ud83d\udca1 Tip \u2013 Variable Types</p> <p>In pymoors, there is no strict enforcement of whether variables are integer, binary, or real. The core Rust implementation works with <code>f64</code> ndarrays. To preserve a specific variable type\u2014binary, integer, or real\u2014you must ensure that the genetic operators themselves maintain it.</p> <p>It is the user's responsibility to choose the appropriate genetic operators for the variable type in question. In the knapsack example, we use binary-style genetic operators, which is why the solutions are arrays of 0 s and 1 s.</p>"},{"location":"getting_started/real_valued.html","title":"Example: A Real-Valued Multi-Objective Optimization Problem","text":"<p>Below is a simple two-variable multi-objective problem to illustrate real-valued optimization with <code>pymoors</code>. We have two continuous decision variables, \\(x_1\\) and \\(x_2\\), both within a given range. We define two objective functions to be minimized simultaneously, and we solve this using the popular NSGA2 algorithm.</p>"},{"location":"getting_started/real_valued.html#mathematical-formulation","title":"Mathematical Formulation","text":"<p>Let \\(\\mathbf{x} = (x_1, x_2)\\) be our decision variables, each constrained to the interval \\([-2, 2]\\). We define the following objectives:</p> \\[ \\begin{aligned} \\min_{\\mathbf{x}} \\quad &amp;f_1(x_1, x_2) = x_1^2 + x_2^2 \\\\ \\min_{\\mathbf{x}} \\quad &amp;f_2(x_1, x_2) = (x_1 - 1)^2 + x_2^2 \\\\ \\text{subject to} \\quad &amp; -2 \\le x_1 \\le 2, \\\\ &amp; -2 \\le x_2 \\le 2. \\end{aligned} \\] <p>Interpretation</p> <ol> <li>\\(f_1\\) measures the distance of \\(\\mathbf{x}\\) from the origin \\((0,0)\\) in the 2D plane.</li> <li>\\(f_2\\) measures the distance of \\(\\mathbf{x}\\) from the point \\((1,0)\\).</li> </ol> <p>Thus, \\(\\mathbf{x}\\) must compromise between being close to \\((0,0)\\) and being close to \\((1,0)\\). There is no single point in \\([-2,2]^2\\) that simultaneously minimizes both distances perfectly (other than at the boundary of these trade-offs), so we end up with a Pareto front rather than a single best solution.</p> RustPython <pre><code>:dep ndarray = \"*\"\n:dep moors = \"0.2.6\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{Array2, Ix2};\nuse moors::{\n    NoConstraints,\n    algorithms::Nsga2Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, SimulatedBinaryCrossover, RandomSamplingFloat},\n    genetic::Population\n};\nuse plotters::prelude::*;\n\n// General: compute two-objective fitness (squared distances).\nfn fitness_fn(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let n = genes.nrows();\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n\n    let x1 = genes.column(0);\n    let x2 = genes.column(1);\n\n    let f1 = &amp;x1.mapv(|v| v.powi(2)) + &amp;x2.mapv(|v| v.powi(2));\n    let f2 = &amp;x1.mapv(|v| (v - 1.0).powi(2)) + &amp;x2.mapv(|v| v.powi(2));\n\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result\n}\n\n// General: run NSGA-II and collect population.\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let mut algorithm = Nsga2Builder::default()\n        .sampler(RandomSamplingFloat::new(-2.0, 2.0))\n        .crossover(SimulatedBinaryCrossover::new(15.0))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-16))\n        .fitness_fn(fitness_fn)\n        .constraints_fn(NoConstraints)\n        .num_vars(2)\n        .population_size(200)\n        .num_offsprings(200)\n        .num_iterations(100)\n        .mutation_rate(0.2)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(42)\n        .build()\n        .unwrap();\n\n    algorithm.run().expect(\"NSGA2 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// General: theoretical Pareto front curve.\nlet n = 200usize;\nlet t: Vec&lt;f64&gt; = (0..n).map(|i| i as f64 / (n as f64 - 1.0)).collect();\nlet f1_theo: Vec&lt;f64&gt; = t.iter().map(|&amp;x| x * x).collect();\nlet f2_theo: Vec&lt;f64&gt; = t.iter().map(|&amp;x| (x - 1.0).powi(2)).collect();\n\n// General: obtained front from the algorithm.\nlet fitness = population.fitness;\nlet f1: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// General: define axes with headroom.\nlet mut x_max = f1.iter().copied().chain(f1_theo.iter().copied()).fold(0.0_f64, f64::max);\nlet mut y_max = f2.iter().copied().chain(f2_theo.iter().copied()).fold(0.0_f64, f64::max);\nx_max = (x_max * 1.05).max(1.0);\ny_max = (y_max * 1.05).max(1.0);\n\n// General: render to in-memory SVG and emit as rich output (no files).\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (800, 600));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"Two-Target Distance Problem \u00b7 Pareto Front\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(0f64..x_max, 0f64..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));\n\n    chart.draw_series(\n        f1.iter().zip(f2.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</code></pre> <p></p> <pre><code>\n</code></pre> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Nsga2,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.typing import TwoDArray\n\n\ndef fitness(genes: TwoDArray) -&gt; TwoDArray:\n    x1 = genes[:, 0]\n    x2 = genes[:, 1]\n    # Objective 1: Distance to (0,0)\n    f1 = x1**2 + x2**2\n    # Objective 2: Distance to (1,0)\n    f2 = (x1 - 1) ** 2 + x2**2\n    # Combine the two objectives into a single array\n    return np.column_stack([f1, f2])\n\n\nalgorithm = Nsga2(\n    sampler=RandomSamplingFloat(min=-2, max=2),\n    crossover=SimulatedBinaryCrossover(distribution_index=15),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=fitness,\n    constraints_fn = Constraints(lower_bound = -2.0, upper_bound = 2.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-16),\n    num_vars=2,\n    population_size=200,\n    num_offsprings=200,\n    num_iterations=100,\n    mutation_rate=0.2,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    seed=42,\n    verbose=False,\n)\n\nalgorithm.run()\npopulation = algorithm.population\n\n# Plot the results\nt = np.linspace(0.0, 1.0, 200)\nf1_theo = t**2\nf2_theo = (t - 1.0) ** 2\n\n\nplt.figure(figsize=(8, 6))\nplt.scatter(f1_theo, f2_theo, marker=\"D\", s=18, label=\"Theoretical Pareto Front\")\nplt.scatter(\n    population.fitness[:, 0],\n    population.fitness[:, 1],\n    c=\"r\",\n    s=8,\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\nplt.xlabel(\"$f_1$\")\nplt.ylabel(\"$f_2$\")\nplt.title(\"Two-Target Distance Problem \u00b7 Pareto Front\")\nplt.grid(True)\nplt.legend()\nplt.show()\n</code></pre> <p></p>"},{"location":"getting_started/python/installation.html","title":"Installation","text":"<p>Make sure your python version is greater than or equal to <code>3.10</code> and then can install pymoors directly from PyPI doing</p> <pre><code>pip install pymoors\n</code></pre>"},{"location":"getting_started/python/knapsack.html","title":"Knapsack","text":"In\u00a0[1]: Copied! <pre>import numpy as np\n\nfrom pymoors import (\n    Nsga2,\n    RandomSamplingBinary,\n    BitFlipMutation,\n    SinglePointBinaryCrossover,\n    ExactDuplicatesCleaner,\n)\nfrom pymoors.typing import TwoDArray\n\n\nPROFITS = np.array([2, 3, 6, 1, 4])\nQUALITIES = np.array([5, 2, 1, 6, 4])\nWEIGHTS = np.array([2, 3, 6, 2, 3])\nCAPACITY = 7\n\n\ndef knapsack_fitness(genes: TwoDArray) -&gt; TwoDArray:\n    # Calculate total profit\n    profit_sum = np.sum(PROFITS * genes, axis=1, keepdims=True)\n    # Calculate total quality\n    quality_sum = np.sum(QUALITIES * genes, axis=1, keepdims=True)\n\n    # We want to maximize profit and quality,\n    # so in pymoors we minimize the negative values\n    f1 = -profit_sum\n    f2 = -quality_sum\n    return np.column_stack([f1, f2])\n\n\ndef knapsack_constraint(genes: TwoDArray) -&gt; TwoDArray:\n    # Calculate total weight\n    weight_sum = np.sum(WEIGHTS * genes, axis=1, keepdims=True)\n    # Inequality constraint: weight_sum &lt;= capacity\n    return weight_sum - CAPACITY\n\n\nalgorithm = Nsga2(\n    sampler=RandomSamplingBinary(),\n    crossover=SinglePointBinaryCrossover(),\n    mutation=BitFlipMutation(gene_mutation_rate=0.5),\n    fitness_fn=knapsack_fitness,\n    constraints_fn=knapsack_constraint,\n    duplicates_cleaner=ExactDuplicatesCleaner(),\n    num_vars=5,\n    population_size=16,\n    num_offsprings=16,\n    num_iterations=10,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    verbose=False,\n)\n\nalgorithm.run()\n</pre> import numpy as np  from pymoors import (     Nsga2,     RandomSamplingBinary,     BitFlipMutation,     SinglePointBinaryCrossover,     ExactDuplicatesCleaner, ) from pymoors.typing import TwoDArray   PROFITS = np.array([2, 3, 6, 1, 4]) QUALITIES = np.array([5, 2, 1, 6, 4]) WEIGHTS = np.array([2, 3, 6, 2, 3]) CAPACITY = 7   def knapsack_fitness(genes: TwoDArray) -&gt; TwoDArray:     # Calculate total profit     profit_sum = np.sum(PROFITS * genes, axis=1, keepdims=True)     # Calculate total quality     quality_sum = np.sum(QUALITIES * genes, axis=1, keepdims=True)      # We want to maximize profit and quality,     # so in pymoors we minimize the negative values     f1 = -profit_sum     f2 = -quality_sum     return np.column_stack([f1, f2])   def knapsack_constraint(genes: TwoDArray) -&gt; TwoDArray:     # Calculate total weight     weight_sum = np.sum(WEIGHTS * genes, axis=1, keepdims=True)     # Inequality constraint: weight_sum &lt;= capacity     return weight_sum - CAPACITY   algorithm = Nsga2(     sampler=RandomSamplingBinary(),     crossover=SinglePointBinaryCrossover(),     mutation=BitFlipMutation(gene_mutation_rate=0.5),     fitness_fn=knapsack_fitness,     constraints_fn=knapsack_constraint,     duplicates_cleaner=ExactDuplicatesCleaner(),     num_vars=5,     population_size=16,     num_offsprings=16,     num_iterations=10,     mutation_rate=0.1,     crossover_rate=0.9,     keep_infeasible=False,     verbose=False, )  algorithm.run() <p>In this small example, the algorithm finds a single solution on the Pareto front: selecting the items (A, D, E), with a profit of 7 and a quality of 15. This means there is no other combination that can match or exceed both objectives without exceeding the knapsack capacity (7).</p> <p>Once the algorithm finishes, it stores a <code>population</code> attribute that contains all the individuals evaluated during the search.</p> In\u00a0[2]: Copied! <pre># repl\npopulation = algorithm.population\n# Get genes\npopulation.genes\n</pre> # repl population = algorithm.population # Get genes population.genes Out[2]: <pre>array([[1., 0., 0., 1., 1.],\n       [1., 1., 0., 1., 0.],\n       [0., 1., 0., 0., 1.],\n       [1., 0., 0., 0., 1.],\n       [1., 0., 0., 1., 0.],\n       [0., 0., 0., 1., 1.],\n       [0., 0., 1., 0., 0.],\n       [1., 1., 0., 0., 0.],\n       [0., 1., 0., 1., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 1., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0.]])</pre> In\u00a0[3]: Copied! <pre># repl\n# Get fitness\npopulation.fitness\n</pre> # repl # Get fitness population.fitness Out[3]: <pre>array([[ -7., -15.],\n       [ -6., -13.],\n       [ -7.,  -6.],\n       [ -6.,  -9.],\n       [ -3., -11.],\n       [ -5., -10.],\n       [ -6.,  -1.],\n       [ -5.,  -7.],\n       [ -4.,  -8.],\n       [ -2.,  -5.],\n       [ -4.,  -4.],\n       [ -1.,  -6.],\n       [ -3.,  -2.],\n       [ -0.,  -0.]])</pre> In\u00a0[4]: Copied! <pre># repl\n# Get constraints\npopulation.constraints\n</pre> # repl # Get constraints population.constraints Out[4]: <pre>array([[ 0.],\n       [ 0.],\n       [-1.],\n       [-2.],\n       [-3.],\n       [-2.],\n       [-1.],\n       [-2.],\n       [-2.],\n       [-5.],\n       [-4.],\n       [-5.],\n       [-4.],\n       [-7.]])</pre> In\u00a0[5]: Copied! <pre># repl\n# Get rank (for Nsga2)\npopulation.rank\n</pre> # repl # Get rank (for Nsga2) population.rank Out[5]: <pre>array([0, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 6], dtype=uint64)</pre> In\u00a0[6]: Copied! <pre># repl\nbest = population.best\nbest\n</pre> # repl best = population.best best Out[6]: <pre>[&lt;pymoors.schemas.Individual at 0x1c6699386e0&gt;]</pre> In\u00a0[7]: Copied! <pre># repl\nbest[0].genes\n</pre> # repl best[0].genes Out[7]: <pre>array([1., 0., 0., 1., 1.])</pre> In\u00a0[8]: Copied! <pre># repl\nbest[0].fitness\n</pre> # repl best[0].fitness Out[8]: <pre>array([ -7., -15.])</pre> <p>\u2139\ufe0f Note \u2013 Population Size and Duplicates</p> <p>Note that although the specified <code>population_size</code> was 16, the final population ended up being 13 individuals, of which 1 had <code>rank = 0</code>. This is because we used the <code>keep_infeasible=False</code> argument, removing any individual that did not satisfy the constraints_fn (in this case, the weight constraint). We also used a duplicate remover called <code>ExactDuplicatesCleaner</code> that eliminates all exact duplicates\u2014meaning whenever <code>genes1 == genes2</code> in every component.</p> <p>\ud83d\udca1 Tip \u2013 Variable Types in pymoors</p> <p>In pymoors, there is no strict enforcement of whether variables are integer, binary, or real. The core Rust implementation works with <code>f64</code> ndarrays. To preserve a specific variable type\u2014binary, integer, or real\u2014you must ensure that the genetic operators themselves maintain it.</p> <p>It is the user's responsibility to choose the appropriate genetic operators for the variable type in question. In the knapsack example, we use binary-style genetic operators, which is why the solutions are arrays of 0 s and 1 s.</p>"},{"location":"getting_started/python/knapsack.html","title":"Knapsack","text":"<pre><code>import numpy as np\n\nfrom pymoors import (\n    Nsga2,\n    RandomSamplingBinary,\n    BitFlipMutation,\n    SinglePointBinaryCrossover,\n    ExactDuplicatesCleaner,\n)\nfrom pymoors.typing import TwoDArray\n\n\nPROFITS = np.array([2, 3, 6, 1, 4])\nQUALITIES = np.array([5, 2, 1, 6, 4])\nWEIGHTS = np.array([2, 3, 6, 2, 3])\nCAPACITY = 7\n\n\ndef knapsack_fitness(genes: TwoDArray) -&gt; TwoDArray:\n    # Calculate total profit\n    profit_sum = np.sum(PROFITS * genes, axis=1, keepdims=True)\n    # Calculate total quality\n    quality_sum = np.sum(QUALITIES * genes, axis=1, keepdims=True)\n\n    # We want to maximize profit and quality,\n    # so in pymoors we minimize the negative values\n    f1 = -profit_sum\n    f2 = -quality_sum\n    return np.column_stack([f1, f2])\n\n\ndef knapsack_constraint(genes: TwoDArray) -&gt; TwoDArray:\n    # Calculate total weight\n    weight_sum = np.sum(WEIGHTS * genes, axis=1, keepdims=True)\n    # Inequality constraint: weight_sum &lt;= capacity\n    return weight_sum - CAPACITY\n\n\nalgorithm = Nsga2(\n    sampler=RandomSamplingBinary(),\n    crossover=SinglePointBinaryCrossover(),\n    mutation=BitFlipMutation(gene_mutation_rate=0.5),\n    fitness_fn=knapsack_fitness,\n    constraints_fn=knapsack_constraint,\n    duplicates_cleaner=ExactDuplicatesCleaner(),\n    num_vars=5,\n    population_size=16,\n    num_offsprings=16,\n    num_iterations=10,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    verbose=False,\n)\n\nalgorithm.run()\n</code></pre> <p>In this small example, the algorithm finds a single solution on the Pareto front: selecting the items (A, D, E), with a profit of 7 and a quality of 15. This means there is no other combination that can match or exceed both objectives without exceeding the knapsack capacity (7).</p> <p>Once the algorithm finishes, it stores a <code>population</code> attribute that contains all the individuals evaluated during the search.</p> <pre><code>&gt;&gt;&gt; population = algorithm.population\n# Get genes\n&gt;&gt;&gt; population.genes\narray([[1., 0., 0., 1., 1.],\n       [1., 1., 0., 1., 0.],\n       [0., 1., 0., 0., 1.],\n       [1., 0., 0., 0., 1.],\n       [1., 0., 0., 1., 0.],\n       [0., 0., 0., 1., 1.],\n       [0., 0., 1., 0., 0.],\n       [1., 1., 0., 0., 0.],\n       [0., 1., 0., 1., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 1., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0.]])\n</code></pre> <pre><code># Get fitness\n&gt;&gt;&gt; population.fitness\narray([[ -7., -15.],\n       [ -6., -13.],\n       [ -7.,  -6.],\n       [ -6.,  -9.],\n       [ -3., -11.],\n       [ -5., -10.],\n       [ -6.,  -1.],\n       [ -5.,  -7.],\n       [ -4.,  -8.],\n       [ -2.,  -5.],\n       [ -4.,  -4.],\n       [ -1.,  -6.],\n       [ -3.,  -2.],\n       [ -0.,  -0.]])\n</code></pre> <pre><code># Get constraints\n&gt;&gt;&gt; population.constraints\narray([[ 0.],\n       [ 0.],\n       [-1.],\n       [-2.],\n       [-3.],\n       [-2.],\n       [-1.],\n       [-2.],\n       [-2.],\n       [-5.],\n       [-4.],\n       [-5.],\n       [-4.],\n       [-7.]])\n</code></pre> <pre><code># Get rank (for Nsga2)\n&gt;&gt;&gt; population.rank\narray([0, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 6], dtype=uint64)\n</code></pre> <pre><code>&gt;&gt;&gt; best = population.best\n&gt;&gt;&gt; best\n[&lt;pymoors.schemas.Individual at 0x1c6699386e0&gt;]\n</code></pre> <pre><code>&gt;&gt;&gt; best[0].genes\narray([1., 0., 0., 1., 1.])\n</code></pre> <pre><code>&gt;&gt;&gt; best[0].fitness\narray([ -7., -15.])\n</code></pre> <p>\u2139\ufe0f Note \u2013 Population Size and Duplicates</p> <p>Note that although the specified <code>population_size</code> was 16, the final population ended up being 13 individuals, of which 1 had <code>rank = 0</code>. This is because we used the <code>keep_infeasible=False</code> argument, removing any individual that did not satisfy the constraints_fn (in this case, the weight constraint). We also used a duplicate remover called <code>ExactDuplicatesCleaner</code> that eliminates all exact duplicates\u2014meaning whenever <code>genes1 == genes2</code> in every component.</p> <p>\ud83d\udca1 Tip \u2013 Variable Types in pymoors</p> <p>In pymoors, there is no strict enforcement of whether variables are integer, binary, or real. The core Rust implementation works with <code>f64</code> ndarrays. To preserve a specific variable type\u2014binary, integer, or real\u2014you must ensure that the genetic operators themselves maintain it.</p> <p>It is the user's responsibility to choose the appropriate genetic operators for the variable type in question. In the knapsack example, we use binary-style genetic operators, which is why the solutions are arrays of 0 s and 1 s.</p>"},{"location":"getting_started/python/quick_start.html","title":"Quick start","text":"<pre><code>import numpy as np\n\nfrom pymoors import (\n    Nsga2,\n    RandomSamplingBinary,\n    BitFlipMutation,\n    SinglePointBinaryCrossover,\n    ExactDuplicatesCleaner,\n)\nfrom pymoors.typing import TwoDArray\n\n\nPROFITS = np.array([2, 3, 6, 1, 4])\nQUALITIES = np.array([5, 2, 1, 6, 4])\nWEIGHTS = np.array([2, 3, 6, 2, 3])\nCAPACITY = 7\n\n\ndef knapsack_fitness(genes: TwoDArray) -&gt; TwoDArray:\n    # Calculate total profit\n    profit_sum = np.sum(PROFITS * genes, axis=1, keepdims=True)\n    # Calculate total quality\n    quality_sum = np.sum(QUALITIES * genes, axis=1, keepdims=True)\n\n    # We want to maximize profit and quality,\n    # so in pymoors we minimize the negative values\n    f1 = -profit_sum\n    f2 = -quality_sum\n    return np.column_stack([f1, f2])\n\n\ndef knapsack_constraint(genes: TwoDArray) -&gt; TwoDArray:\n    # Calculate total weight\n    weight_sum = np.sum(WEIGHTS * genes, axis=1, keepdims=True)\n    # Inequality constraint: weight_sum &lt;= capacity\n    return weight_sum - CAPACITY\n\n\nalgorithm = Nsga2(\n    sampler=RandomSamplingBinary(),\n    crossover=SinglePointBinaryCrossover(),\n    mutation=BitFlipMutation(gene_mutation_rate=0.5),\n    fitness_fn=knapsack_fitness,\n    constraints_fn=knapsack_constraint,\n    duplicates_cleaner=ExactDuplicatesCleaner(),\n    n_vars=5,\n    population_size=32,\n    num_offsprings=32,\n    num_iterations=10,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n)\n\nalgorithm.run()\npop = algorithm.population\n# Get genes\n&gt;&gt;&gt; pop.genes\narray([[1., 0., 0., 1., 1.],\n       [0., 1., 0., 0., 1.],\n       [1., 1., 0., 1., 0.],\n       ...])\n# Get fitness\n&gt;&gt;&gt; pop.fitness\narray([[ -7., -15.],\n       [ -7.,  -6.],\n       [ -6., -13.],\n       ...])\n# Get constraints evaluation\n&gt;&gt;&gt; pop.constraints\narray([[ 0.],\n       [-1.],\n       [ 0.],\n       ...])\n# Get rank\n&gt;&gt;&gt; pop.rank\narray([0, 1, 1, 2, ...], dtype=uint64)\n# Get best individuals\n&gt;&gt;&gt; pop.best\n[&lt;pymoors.schemas.Individual object at 0x...&gt;]\n&gt;&gt;&gt; pop.best[0].genes\narray([1., 0., 0., 1., 1.])\n&gt;&gt;&gt; pop.best[0].fitness\narray([ -7., -15.])\n&gt;&gt;&gt; pop.best[0].constraints\narray([0.])\n</code></pre>"},{"location":"getting_started/python/real_valued.html","title":"Real valued","text":"In\u00a0[5]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Nsga2,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.typing import TwoDArray\n\n\ndef fitness(genes: TwoDArray) -&gt; TwoDArray:\n    x1 = genes[:, 0]\n    x2 = genes[:, 1]\n    # Objective 1: Distance to (0,0)\n    f1 = x1**2 + x2**2\n    # Objective 2: Distance to (1,0)\n    f2 = (x1 - 1) ** 2 + x2**2\n    # Combine the two objectives into a single array\n    return np.column_stack([f1, f2])\n\n\nalgorithm = Nsga2(\n    sampler=RandomSamplingFloat(min=-2, max=2),\n    crossover=SimulatedBinaryCrossover(distribution_index=15),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=fitness,\n    constraints_fn = Constraints(lower_bound = -2.0, upper_bound = 2.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-16),\n    num_vars=2,\n    population_size=200,\n    num_offsprings=200,\n    num_iterations=100,\n    mutation_rate=0.2,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    seed=42,\n    verbose=False,\n)\n\nalgorithm.run()\npopulation = algorithm.population\n\n# Plot the results\nt = np.linspace(0.0, 1.0, 200)\nf1_theo = t**2\nf2_theo = (t - 1.0) ** 2\n\n\nplt.figure(figsize=(8, 6))\nplt.scatter(f1_theo, f2_theo, marker=\"D\", s=18, label=\"Theoretical Pareto Front\")\nplt.scatter(\n    population.fitness[:, 0],\n    population.fitness[:, 1],\n    c=\"r\",\n    s=8,\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\nplt.xlabel(\"$f_1$\")\nplt.ylabel(\"$f_2$\")\nplt.title(\"Two-Target Distance Problem \u00b7 Pareto Front\")\nplt.grid(True)\nplt.legend()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  from pymoors import (     Nsga2,     RandomSamplingFloat,     GaussianMutation,     SimulatedBinaryCrossover,     CloseDuplicatesCleaner,     Constraints ) from pymoors.typing import TwoDArray   def fitness(genes: TwoDArray) -&gt; TwoDArray:     x1 = genes[:, 0]     x2 = genes[:, 1]     # Objective 1: Distance to (0,0)     f1 = x1**2 + x2**2     # Objective 2: Distance to (1,0)     f2 = (x1 - 1) ** 2 + x2**2     # Combine the two objectives into a single array     return np.column_stack([f1, f2])   algorithm = Nsga2(     sampler=RandomSamplingFloat(min=-2, max=2),     crossover=SimulatedBinaryCrossover(distribution_index=15),     mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),     fitness_fn=fitness,     constraints_fn = Constraints(lower_bound = -2.0, upper_bound = 2.0),     duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-16),     num_vars=2,     population_size=200,     num_offsprings=200,     num_iterations=100,     mutation_rate=0.2,     crossover_rate=0.9,     keep_infeasible=False,     seed=42,     verbose=False, )  algorithm.run() population = algorithm.population  # Plot the results t = np.linspace(0.0, 1.0, 200) f1_theo = t**2 f2_theo = (t - 1.0) ** 2   plt.figure(figsize=(8, 6)) plt.scatter(f1_theo, f2_theo, marker=\"D\", s=18, label=\"Theoretical Pareto Front\") plt.scatter(     population.fitness[:, 0],     population.fitness[:, 1],     c=\"r\",     s=8,     marker=\"o\",     label=\"Obtained Front\", ) plt.xlabel(\"$f_1$\") plt.ylabel(\"$f_2$\") plt.title(\"Two-Target Distance Problem \u00b7 Pareto Front\") plt.grid(True) plt.legend() plt.show()"},{"location":"getting_started/python/real_valued.html","title":"Real valued","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Nsga2,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.typing import TwoDArray\n\n\ndef fitness(genes: TwoDArray) -&gt; TwoDArray:\n    x1 = genes[:, 0]\n    x2 = genes[:, 1]\n    # Objective 1: Distance to (0,0)\n    f1 = x1**2 + x2**2\n    # Objective 2: Distance to (1,0)\n    f2 = (x1 - 1) ** 2 + x2**2\n    # Combine the two objectives into a single array\n    return np.column_stack([f1, f2])\n\n\nalgorithm = Nsga2(\n    sampler=RandomSamplingFloat(min=-2, max=2),\n    crossover=SimulatedBinaryCrossover(distribution_index=15),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=fitness,\n    constraints_fn = Constraints(lower_bound = -2.0, upper_bound = 2.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-16),\n    num_vars=2,\n    population_size=200,\n    num_offsprings=200,\n    num_iterations=100,\n    mutation_rate=0.2,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    seed=42,\n    verbose=False,\n)\n\nalgorithm.run()\npopulation = algorithm.population\n\n# Plot the results\nt = np.linspace(0.0, 1.0, 200)\nf1_theo = t**2\nf2_theo = (t - 1.0) ** 2\n\n\nplt.figure(figsize=(8, 6))\nplt.scatter(f1_theo, f2_theo, marker=\"D\", s=18, label=\"Theoretical Pareto Front\")\nplt.scatter(\n    population.fitness[:, 0],\n    population.fitness[:, 1],\n    c=\"r\",\n    s=8,\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\nplt.xlabel(\"$f_1$\")\nplt.ylabel(\"$f_2$\")\nplt.title(\"Two-Target Distance Problem \u00b7 Pareto Front\")\nplt.grid(True)\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"getting_started/rust/installation.html","title":"Installation","text":"<p>Make sure your rust version is greater than or equal to <code>1.76.0</code>, and then you can install moors directly from crates.io doing</p> <pre><code>cargo add moors\n</code></pre>"},{"location":"getting_started/rust/knapsack.html","title":"Knapsack","text":"In\u00a0[18]: Copied! <pre>use ndarray::{Array1, Array2, Axis, stack, Ix1, Ix2};\nuse ordered_float::OrderedFloat;\nuse std::collections::HashSet;\n\nuse moors::{\n    algorithms::{Nsga2, Nsga2Builder},\n    duplicates::ExactDuplicatesCleaner,\n    operators::{BitFlipMutation, RandomSamplingBinary, SinglePointBinaryCrossover},\n    genetic::Population\n};\n\n// problem data\nconst PROFITS: [f64; 5] = [2.0, 3.0, 6.0, 1.0, 4.0];\nconst QUALITIES: [f64; 5] = [5.0, 2.0, 1.0, 6.0, 4.0];\nconst WEIGHTS: [f64; 5] = [2.0, 3.0, 6.0, 2.0, 3.0];\nconst CAPACITY: f64 = 7.0;\n\nfn fitness_knapsack(populationulation_genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    // Calculate total profit\n    let profits_arr = Array1::from_vec(PROFITS.to_vec());\n    let profit_sum = populationulation_genes.dot(&amp;profits_arr);\n\n    // Calculate total quality\n    let qualities_arr = Array1::from_vec(QUALITIES.to_vec());\n    let quality_sum = populationulation_genes.dot(&amp;qualities_arr);\n\n    // We want to maximize profit and quality,\n    // so in moors we minimize the negative values\n    stack(Axis(1), &amp;[(-&amp;profit_sum).view(), (-&amp;quality_sum).view()]).expect(\"stack failed\")\n}\n\nfn constraints_knapsack(populationulation_genes: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    // Calculate total weight\n    let weights_arr = Array1::from_vec(WEIGHTS.to_vec());\n    // Inequality constraint: weight_sum &lt;= capacity\n    populationulation_genes.dot(&amp;weights_arr) - CAPACITY\n}\n\n// NOTE: The clone is only needed for the notebook source of this file. Also, most of the cases\n// you don't need to specify the Population&lt;Ix2, Ix1&gt; signature\nlet population: Population&lt;Ix2, Ix1&gt; = {\n    let mut algorithm = Nsga2Builder::default()\n        .fitness_fn(fitness_knapsack)\n        .constraints_fn(constraints_knapsack)\n        .sampler(RandomSamplingBinary)\n        .crossover(SinglePointBinaryCrossover)\n        .mutation(BitFlipMutation::new(0.5))\n        .duplicates_cleaner(ExactDuplicatesCleaner)\n        .num_vars(5)\n        .population_size(16)\n        .num_offsprings(16)\n        .num_iterations(10)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .build()\n        .unwrap();\n\n    algorithm.run().expect(\"NSGA2 run failed\");\n\n    let population = algorithm.population().expect(\"populationulation should have been initialized\");\n    population.clone()\n};\n</pre> use ndarray::{Array1, Array2, Axis, stack, Ix1, Ix2}; use ordered_float::OrderedFloat; use std::collections::HashSet;  use moors::{     algorithms::{Nsga2, Nsga2Builder},     duplicates::ExactDuplicatesCleaner,     operators::{BitFlipMutation, RandomSamplingBinary, SinglePointBinaryCrossover},     genetic::Population };  // problem data const PROFITS: [f64; 5] = [2.0, 3.0, 6.0, 1.0, 4.0]; const QUALITIES: [f64; 5] = [5.0, 2.0, 1.0, 6.0, 4.0]; const WEIGHTS: [f64; 5] = [2.0, 3.0, 6.0, 2.0, 3.0]; const CAPACITY: f64 = 7.0;  fn fitness_knapsack(populationulation_genes: &amp;Array2) -&gt; Array2 {     // Calculate total profit     let profits_arr = Array1::from_vec(PROFITS.to_vec());     let profit_sum = populationulation_genes.dot(&amp;profits_arr);      // Calculate total quality     let qualities_arr = Array1::from_vec(QUALITIES.to_vec());     let quality_sum = populationulation_genes.dot(&amp;qualities_arr);      // We want to maximize profit and quality,     // so in moors we minimize the negative values     stack(Axis(1), &amp;[(-&amp;profit_sum).view(), (-&amp;quality_sum).view()]).expect(\"stack failed\") }  fn constraints_knapsack(populationulation_genes: &amp;Array2) -&gt; Array1 {     // Calculate total weight     let weights_arr = Array1::from_vec(WEIGHTS.to_vec());     // Inequality constraint: weight_sum &lt;= capacity     populationulation_genes.dot(&amp;weights_arr) - CAPACITY }  // NOTE: The clone is only needed for the notebook source of this file. Also, most of the cases // you don't need to specify the Population signature let population: Population = {     let mut algorithm = Nsga2Builder::default()         .fitness_fn(fitness_knapsack)         .constraints_fn(constraints_knapsack)         .sampler(RandomSamplingBinary)         .crossover(SinglePointBinaryCrossover)         .mutation(BitFlipMutation::new(0.5))         .duplicates_cleaner(ExactDuplicatesCleaner)         .num_vars(5)         .population_size(16)         .num_offsprings(16)         .num_iterations(10)         .mutation_rate(0.1)         .crossover_rate(0.9)         .keep_infeasible(false)         .build()         .unwrap();      algorithm.run().expect(\"NSGA2 run failed\");      let population = algorithm.population().expect(\"populationulation should have been initialized\");     population.clone() }; <pre>Warning: Only 15 offspring were generated out of the desired 16.\n</pre> In\u00a0[19]: Copied! <pre>// repl\n// Get genes\npopulation.genes\n</pre> // repl // Get genes population.genes Out[19]: <pre>[[1.0, 0.0, 0.0, 1.0, 1.0],\n [1.0, 1.0, 0.0, 1.0, 0.0],\n [0.0, 1.0, 0.0, 0.0, 1.0],\n [1.0, 0.0, 0.0, 0.0, 1.0],\n [1.0, 0.0, 0.0, 1.0, 0.0],\n [0.0, 0.0, 0.0, 1.0, 1.0],\n [0.0, 0.0, 1.0, 0.0, 0.0],\n [1.0, 1.0, 0.0, 0.0, 0.0],\n [0.0, 1.0, 0.0, 1.0, 0.0],\n [0.0, 0.0, 0.0, 1.0, 0.0],\n [0.0, 0.0, 0.0, 0.0, 1.0],\n [1.0, 0.0, 0.0, 0.0, 0.0],\n [0.0, 1.0, 0.0, 0.0, 0.0],\n [0.0, 0.0, 0.0, 0.0, 0.0]], shape=[14, 5], strides=[5, 1], layout=Cc (0x5), const ndim=2</pre> In\u00a0[20]: Copied! <pre>// repl\n// Get fitness\npopulation.fitness\n</pre> // repl // Get fitness population.fitness Out[20]: <pre>[[-7.0, -15.0],\n [-6.0, -13.0],\n [-7.0, -6.0],\n [-6.0, -9.0],\n [-3.0, -11.0],\n [-5.0, -10.0],\n [-6.0, -1.0],\n [-5.0, -7.0],\n [-4.0, -8.0],\n [-1.0, -6.0],\n [-4.0, -4.0],\n [-2.0, -5.0],\n [-3.0, -2.0],\n [-0.0, -0.0]], shape=[14, 2], strides=[2, 1], layout=Cc (0x5), const ndim=2</pre> In\u00a0[21]: Copied! <pre>// repl\n// Get constraints\npopulation.constraints\n</pre> // repl // Get constraints population.constraints Out[21]: <pre>[0.0, 0.0, -1.0, -2.0, -3.0, -2.0, -1.0, -2.0, -2.0, -5.0, -4.0, -5.0, -4.0, -7.0], shape=[14], strides=[1], layout=CFcf (0xf), const ndim=1</pre> In\u00a0[22]: Copied! <pre>// repl\n// Get rank (for Nsga2)\npopulation.constraints\n</pre> // repl // Get rank (for Nsga2) population.constraints Out[22]: <pre>[0.0, 0.0, -1.0, -2.0, -3.0, -2.0, -1.0, -2.0, -2.0, -5.0, -4.0, -5.0, -4.0, -7.0], shape=[14], strides=[1], layout=CFcf (0xf), const ndim=1</pre> <p>Note that in this example there is just one individual with rank 0, i.e Pareto optimal. Algorithms in <code>moors</code> store all individuals with rank 0 in a special attribute <code>best</code></p> In\u00a0[24]: Copied! <pre>// repl\nlet best = population.best();\nbest\n</pre> // repl let best = population.best(); best Out[24]: <pre>Population { genes: [[1.0, 0.0, 0.0, 1.0, 1.0]], shape=[1, 5], strides=[5, 1], layout=CFcf (0xf), const ndim=2, fitness: [[-7.0, -15.0]], shape=[1, 2], strides=[2, 1], layout=CFcf (0xf), const ndim=2, constraints: [0.0], shape=[1], strides=[1], layout=CFcf (0xf), const ndim=1, rank: Some([0], shape=[1], strides=[1], layout=CFcf (0xf), const ndim=1), survival_score: Some([inf], shape=[1], strides=[1], layout=CFcf (0xf), const ndim=1), constraint_violation_totals: Some([0.0], shape=[1], strides=[1], layout=CFcf (0xf), const ndim=1) }</pre> In\u00a0[28]: Copied! <pre>// repl\n// Get the best individual (just 1 in this example)\nbest.get(0)\n</pre> // repl // Get the best individual (just 1 in this example) best.get(0) Out[28]: <pre>Individual { genes: [1.0, 0.0, 0.0, 1.0, 1.0], shape=[5], strides=[1], layout=CFcf (0xf), const ndim=1, fitness: [-7.0, -15.0], shape=[2], strides=[1], layout=CFcf (0xf), const ndim=1, constraints: 0.0, shape=[], strides=[], layout=CFcf (0xf), const ndim=0, rank: Some(0), survival_score: Some(inf), constraint_violation_totals: Some(0.0) }</pre>"},{"location":"getting_started/rust/knapsack.html","title":"Knapsack","text":"<pre><code>use ndarray::{Array1, Array2, Axis, stack, Ix1, Ix2};\nuse ordered_float::OrderedFloat;\nuse std::collections::HashSet;\n\nuse moors::{\n    algorithms::{Nsga2, Nsga2Builder},\n    duplicates::ExactDuplicatesCleaner,\n    operators::{BitFlipMutation, RandomSamplingBinary, SinglePointBinaryCrossover},\n    genetic::Population\n};\n\n// problem data\nconst PROFITS: [f64; 5] = [2.0, 3.0, 6.0, 1.0, 4.0];\nconst QUALITIES: [f64; 5] = [5.0, 2.0, 1.0, 6.0, 4.0];\nconst WEIGHTS: [f64; 5] = [2.0, 3.0, 6.0, 2.0, 3.0];\nconst CAPACITY: f64 = 7.0;\n\nfn fitness_knapsack(populationulation_genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    // Calculate total profit\n    let profits_arr = Array1::from_vec(PROFITS.to_vec());\n    let profit_sum = populationulation_genes.dot(&amp;profits_arr);\n\n    // Calculate total quality\n    let qualities_arr = Array1::from_vec(QUALITIES.to_vec());\n    let quality_sum = populationulation_genes.dot(&amp;qualities_arr);\n\n    // We want to maximize profit and quality,\n    // so in moors we minimize the negative values\n    stack(Axis(1), &amp;[(-&amp;profit_sum).view(), (-&amp;quality_sum).view()]).expect(\"stack failed\")\n}\n\nfn constraints_knapsack(populationulation_genes: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    // Calculate total weight\n    let weights_arr = Array1::from_vec(WEIGHTS.to_vec());\n    // Inequality constraint: weight_sum &lt;= capacity\n    populationulation_genes.dot(&amp;weights_arr) - CAPACITY\n}\n\n// NOTE: The clone is only needed for the notebook source of this file. Also, most of the cases\n// you don't need to specify the Population&lt;Ix2, Ix1&gt; signature\nlet population: Population&lt;Ix2, Ix1&gt; = {\n    let mut algorithm = Nsga2Builder::default()\n        .fitness_fn(fitness_knapsack)\n        .constraints_fn(constraints_knapsack)\n        .sampler(RandomSamplingBinary)\n        .crossover(SinglePointBinaryCrossover)\n        .mutation(BitFlipMutation::new(0.5))\n        .duplicates_cleaner(ExactDuplicatesCleaner)\n        .num_vars(5)\n        .population_size(16)\n        .num_offsprings(16)\n        .num_iterations(10)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .build()\n        .unwrap();\n\n    algorithm.run().expect(\"NSGA2 run failed\");\n\n    let population = algorithm.population().expect(\"populationulation should have been initialized\");\n    population.clone()\n};\n</code></pre> <pre><code>Warning: Only 15 offspring were generated out of the desired 16.\n</code></pre> <pre><code>// Get genes\n&gt;&gt;&gt; population.genes\n[[1.0, 0.0, 0.0, 1.0, 1.0],\n [1.0, 1.0, 0.0, 1.0, 0.0],\n [0.0, 1.0, 0.0, 0.0, 1.0],\n [1.0, 0.0, 0.0, 0.0, 1.0],\n [1.0, 0.0, 0.0, 1.0, 0.0],\n [0.0, 0.0, 0.0, 1.0, 1.0],\n [0.0, 0.0, 1.0, 0.0, 0.0],\n [1.0, 1.0, 0.0, 0.0, 0.0],\n [0.0, 1.0, 0.0, 1.0, 0.0],\n [0.0, 0.0, 0.0, 1.0, 0.0],\n [0.0, 0.0, 0.0, 0.0, 1.0],\n [1.0, 0.0, 0.0, 0.0, 0.0],\n [0.0, 1.0, 0.0, 0.0, 0.0],\n [0.0, 0.0, 0.0, 0.0, 0.0]], shape=[14, 5], strides=[5, 1], layout=Cc (0x5), const ndim=2\n</code></pre> <pre><code>// Get fitness\n&gt;&gt;&gt; population.fitness\n[[-7.0, -15.0],\n [-6.0, -13.0],\n [-7.0, -6.0],\n [-6.0, -9.0],\n [-3.0, -11.0],\n [-5.0, -10.0],\n [-6.0, -1.0],\n [-5.0, -7.0],\n [-4.0, -8.0],\n [-1.0, -6.0],\n [-4.0, -4.0],\n [-2.0, -5.0],\n [-3.0, -2.0],\n [-0.0, -0.0]], shape=[14, 2], strides=[2, 1], layout=Cc (0x5), const ndim=2\n</code></pre> <pre><code>// Get constraints\n&gt;&gt;&gt; population.constraints\n[0.0, 0.0, -1.0, -2.0, -3.0, -2.0, -1.0, -2.0, -2.0, -5.0, -4.0, -5.0, -4.0, -7.0], shape=[14], strides=[1], layout=CFcf (0xf), const ndim=1\n</code></pre> <pre><code>// Get rank (for Nsga2)\n&gt;&gt;&gt; population.constraints\n[0.0, 0.0, -1.0, -2.0, -3.0, -2.0, -1.0, -2.0, -2.0, -5.0, -4.0, -5.0, -4.0, -7.0], shape=[14], strides=[1], layout=CFcf (0xf), const ndim=1\n</code></pre> <p>Note that in this example there is just one individual with rank 0, i.e Pareto optimal. Algorithms in <code>moors</code> store all individuals with rank 0 in a special attribute <code>best</code></p> <pre><code>&gt;&gt;&gt; let best = population.best();\n&gt;&gt;&gt; best\nPopulation { genes: [[1.0, 0.0, 0.0, 1.0, 1.0]], shape=[1, 5], strides=[5, 1], layout=CFcf (0xf), const ndim=2, fitness: [[-7.0, -15.0]], shape=[1, 2], strides=[2, 1], layout=CFcf (0xf), const ndim=2, constraints: [0.0], shape=[1], strides=[1], layout=CFcf (0xf), const ndim=1, rank: Some([0], shape=[1], strides=[1], layout=CFcf (0xf), const ndim=1), survival_score: Some([inf], shape=[1], strides=[1], layout=CFcf (0xf), const ndim=1), constraint_violation_totals: Some([0.0], shape=[1], strides=[1], layout=CFcf (0xf), const ndim=1) }\n</code></pre> <pre><code>// Get the best individual (just 1 in this example)\n&gt;&gt;&gt; best.get(0)\nIndividual { genes: [1.0, 0.0, 0.0, 1.0, 1.0], shape=[5], strides=[1], layout=CFcf (0xf), const ndim=1, fitness: [-7.0, -15.0], shape=[2], strides=[1], layout=CFcf (0xf), const ndim=1, constraints: 0.0, shape=[], strides=[], layout=CFcf (0xf), const ndim=0, rank: Some(0), survival_score: Some(inf), constraint_violation_totals: Some(0.0) }\n</code></pre>"},{"location":"getting_started/rust/quick_start.html","title":"Quick start","text":"<pre><code>use ndarray::{Array1, Array2, Axis, stack};\n\nuse moors::{\n    algorithms::{AlgorithmError, Nsga2Builder},\n    duplicates::ExactDuplicatesCleaner,\n    operators::{\n        crossover::SinglePointBinaryCrossover, mutation::BitFlipMutation,\n        sampling::RandomSamplingBinary,\n    },\n};\n\n// problem data\nconst WEIGHTS: [f64; 5] = [12.0, 2.0, 1.0, 4.0, 10.0];\nconst VALUES: [f64; 5] = [4.0, 2.0, 1.0, 5.0, 3.0];\nconst CAPACITY: f64 = 15.0;\n\n/// Compute multi-objective fitness [\u2013total_value, total_weight]\n/// Returns an Array2&lt;f64&gt; of shape (population_size, 2)\nfn fitness_knapsack(population_genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let weights_arr = Array1::from_vec(WEIGHTS.to_vec());\n    let values_arr = Array1::from_vec(VALUES.to_vec());\n\n    let total_values = population_genes.dot(&amp;values_arr);\n    let total_weights = population_genes.dot(&amp;weights_arr);\n\n    // stack two columns: [-total_values, total_weights]\n    stack(Axis(1), &amp;[(-&amp;total_values).view(), total_weights.view()]).expect(\"stack failed\")\n}\n\nfn constraints_knapsack(population_genes: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    let weights_arr = Array1::from_vec(WEIGHTS.to_vec());\n    population_genes.dot(&amp;weights_arr) - CAPACITY\n}\n\nfn main() -&gt; Result&lt;(), AlgorithmError&gt; {\n    // build the NSGA-II algorithm\n    let mut algorithm = Nsga2Builder::default()\n        .fitness_fn(fitness_knapsack)\n        .constraints_fn(constraints_knapsack)\n        .sampler(RandomSamplingBinary::new())\n        .crossover(SinglePointBinaryCrossover::new())\n        .mutation(BitFlipMutation::new(0.5))\n        .duplicates_cleaner(ExactDuplicatesCleaner::new())\n        .num_vars(5)\n        .population_size(100)\n        .crossover_rate(0.9)\n        .mutation_rate(0.1)\n        .num_offsprings(32)\n        .num_iterations(2)\n        .build()?;\n\n    algorithm.run()?;\n    let population = algorithm.population()?;\n    println!(\"Done! Population size: {}\", population.len());\n\n    Ok(())\n}\n</code></pre>"},{"location":"getting_started/rust/real_valued.html","title":"Real valued","text":"In\u00a0[10]: Copied! <pre>:dep ndarray = \"*\"\n:dep moors = \"0.2.6\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{Array2, Ix2};\nuse moors::{\n    NoConstraints,\n    algorithms::Nsga2Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, SimulatedBinaryCrossover, RandomSamplingFloat},\n    genetic::Population\n};\nuse plotters::prelude::*;\n\n// General: compute two-objective fitness (squared distances).\nfn fitness_fn(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let n = genes.nrows();\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n\n    let x1 = genes.column(0);\n    let x2 = genes.column(1);\n\n    let f1 = &amp;x1.mapv(|v| v.powi(2)) + &amp;x2.mapv(|v| v.powi(2));\n    let f2 = &amp;x1.mapv(|v| (v - 1.0).powi(2)) + &amp;x2.mapv(|v| v.powi(2));\n\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result\n}\n\n// General: run NSGA-II and collect population.\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let mut algorithm = Nsga2Builder::default()\n        .sampler(RandomSamplingFloat::new(-2.0, 2.0))\n        .crossover(SimulatedBinaryCrossover::new(15.0))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-16))\n        .fitness_fn(fitness_fn)\n        .constraints_fn(NoConstraints)\n        .num_vars(2)\n        .population_size(200)\n        .num_offsprings(200)\n        .num_iterations(100)\n        .mutation_rate(0.2)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(42)\n        .build()\n        .unwrap();\n\n    algorithm.run().expect(\"NSGA2 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// General: theoretical Pareto front curve.\nlet n = 200usize;\nlet t: Vec&lt;f64&gt; = (0..n).map(|i| i as f64 / (n as f64 - 1.0)).collect();\nlet f1_theo: Vec&lt;f64&gt; = t.iter().map(|&amp;x| x * x).collect();\nlet f2_theo: Vec&lt;f64&gt; = t.iter().map(|&amp;x| (x - 1.0).powi(2)).collect();\n\n// General: obtained front from the algorithm.\nlet fitness = population.fitness;\nlet f1: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// General: define axes with headroom.\nlet mut x_max = f1.iter().copied().chain(f1_theo.iter().copied()).fold(0.0_f64, f64::max);\nlet mut y_max = f2.iter().copied().chain(f2_theo.iter().copied()).fold(0.0_f64, f64::max);\nx_max = (x_max * 1.05).max(1.0);\ny_max = (y_max * 1.05).max(1.0);\n\n// General: render to in-memory SVG and emit as rich output (no files).\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (800, 600));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"Two-Target Distance Problem \u00b7 Pareto Front\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(0f64..x_max, 0f64..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));\n\n    chart.draw_series(\n        f1.iter().zip(f2.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</pre> :dep ndarray = \"*\" :dep moors = \"0.2.6\" :dep plotters = \"0.3.6\"  use ndarray::{Array2, Ix2}; use moors::{     NoConstraints,     algorithms::Nsga2Builder,     duplicates::CloseDuplicatesCleaner,     operators::{GaussianMutation, SimulatedBinaryCrossover, RandomSamplingFloat},     genetic::Population }; use plotters::prelude::*;  // General: compute two-objective fitness (squared distances). fn fitness_fn(genes: &amp;Array2) -&gt; Array2 {     let n = genes.nrows();     let mut result = Array2::::zeros((n, 2));      let x1 = genes.column(0);     let x2 = genes.column(1);      let f1 = &amp;x1.mapv(|v| v.powi(2)) + &amp;x2.mapv(|v| v.powi(2));     let f2 = &amp;x1.mapv(|v| (v - 1.0).powi(2)) + &amp;x2.mapv(|v| v.powi(2));      result.column_mut(0).assign(&amp;f1);     result.column_mut(1).assign(&amp;f2);     result }  // General: run NSGA-II and collect population. let population: Population = {     let mut algorithm = Nsga2Builder::default()         .sampler(RandomSamplingFloat::new(-2.0, 2.0))         .crossover(SimulatedBinaryCrossover::new(15.0))         .mutation(GaussianMutation::new(0.1, 0.01))         .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-16))         .fitness_fn(fitness_fn)         .constraints_fn(NoConstraints)         .num_vars(2)         .population_size(200)         .num_offsprings(200)         .num_iterations(100)         .mutation_rate(0.2)         .crossover_rate(0.9)         .keep_infeasible(false)         .verbose(false)         .seed(42)         .build()         .unwrap();      algorithm.run().expect(\"NSGA2 run failed\");     algorithm.population().unwrap().clone() };  // General: theoretical Pareto front curve. let n = 200usize; let t: Vec = (0..n).map(|i| i as f64 / (n as f64 - 1.0)).collect(); let f1_theo: Vec = t.iter().map(|&amp;x| x * x).collect(); let f2_theo: Vec = t.iter().map(|&amp;x| (x - 1.0).powi(2)).collect();  // General: obtained front from the algorithm. let fitness = population.fitness; let f1: Vec = fitness.column(0).to_vec(); let f2: Vec = fitness.column(1).to_vec();  // General: define axes with headroom. let mut x_max = f1.iter().copied().chain(f1_theo.iter().copied()).fold(0.0_f64, f64::max); let mut y_max = f2.iter().copied().chain(f2_theo.iter().copied()).fold(0.0_f64, f64::max); x_max = (x_max * 1.05).max(1.0); y_max = (y_max * 1.05).max(1.0);  // General: render to in-memory SVG and emit as rich output (no files). let mut svg = String::new(); {     let backend = SVGBackend::with_string(&amp;mut svg, (800, 600));     let root = backend.into_drawing_area();     root.fill(&amp;WHITE).unwrap();      let mut chart = ChartBuilder::on(&amp;root)         .caption(\"Two-Target Distance Problem \u00b7 Pareto Front\", (\"DejaVu Sans\", 22))         .margin(10)         .x_label_area_size(40)         .y_label_area_size(60)         .build_cartesian_2d(0f64..x_max, 0f64..y_max)         .unwrap();      chart.configure_mesh()         .x_desc(\"f1\")         .y_desc(\"f2\")         .axis_desc_style((\"DejaVu Sans\", 14))         .light_line_style(&amp;RGBColor(220, 220, 220))         .draw()         .unwrap();      chart.draw_series(         f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {             Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())         })     ).unwrap()      .label(\"Theoretical Pareto Front\")      .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));      chart.draw_series(         f1.iter().zip(f2.iter()).map(|(&amp;x, &amp;y)| {             Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())         })     ).unwrap()      .label(\"Obtained Front\")      .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));      chart.configure_series_labels()         .border_style(&amp;RGBAColor(0, 0, 0, 0.3))         .background_style(&amp;WHITE.mix(0.9))         .label_font((\"DejaVu Sans\", 13))         .draw()         .unwrap();      root.present().unwrap(); }  println!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);  Out[10]: In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"getting_started/rust/real_valued.html","title":"Real valued","text":"<pre><code>:dep ndarray = \"*\"\n:dep moors = \"0.2.6\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{Array2, Ix2};\nuse moors::{\n    NoConstraints,\n    algorithms::Nsga2Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, SimulatedBinaryCrossover, RandomSamplingFloat},\n    genetic::Population\n};\nuse plotters::prelude::*;\n\n// General: compute two-objective fitness (squared distances).\nfn fitness_fn(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let n = genes.nrows();\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n\n    let x1 = genes.column(0);\n    let x2 = genes.column(1);\n\n    let f1 = &amp;x1.mapv(|v| v.powi(2)) + &amp;x2.mapv(|v| v.powi(2));\n    let f2 = &amp;x1.mapv(|v| (v - 1.0).powi(2)) + &amp;x2.mapv(|v| v.powi(2));\n\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result\n}\n\n// General: run NSGA-II and collect population.\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let mut algorithm = Nsga2Builder::default()\n        .sampler(RandomSamplingFloat::new(-2.0, 2.0))\n        .crossover(SimulatedBinaryCrossover::new(15.0))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-16))\n        .fitness_fn(fitness_fn)\n        .constraints_fn(NoConstraints)\n        .num_vars(2)\n        .population_size(200)\n        .num_offsprings(200)\n        .num_iterations(100)\n        .mutation_rate(0.2)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(42)\n        .build()\n        .unwrap();\n\n    algorithm.run().expect(\"NSGA2 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// General: theoretical Pareto front curve.\nlet n = 200usize;\nlet t: Vec&lt;f64&gt; = (0..n).map(|i| i as f64 / (n as f64 - 1.0)).collect();\nlet f1_theo: Vec&lt;f64&gt; = t.iter().map(|&amp;x| x * x).collect();\nlet f2_theo: Vec&lt;f64&gt; = t.iter().map(|&amp;x| (x - 1.0).powi(2)).collect();\n\n// General: obtained front from the algorithm.\nlet fitness = population.fitness;\nlet f1: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// General: define axes with headroom.\nlet mut x_max = f1.iter().copied().chain(f1_theo.iter().copied()).fold(0.0_f64, f64::max);\nlet mut y_max = f2.iter().copied().chain(f2_theo.iter().copied()).fold(0.0_f64, f64::max);\nx_max = (x_max * 1.05).max(1.0);\ny_max = (y_max * 1.05).max(1.0);\n\n// General: render to in-memory SVG and emit as rich output (no files).\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (800, 600));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"Two-Target Distance Problem \u00b7 Pareto Front\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(0f64..x_max, 0f64..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));\n\n    chart.draw_series(\n        f1.iter().zip(f2.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</code></pre> <pre><code>\n</code></pre>"},{"location":"user_guide/algorithms/agemoea.html","title":"AGE-MOEA","text":"<p>AgeMoea is an adaptive evolutionary algorithm based on non-Euclidean geometry for many-objective optimization. Its main strength lies in discovering the geometry of the first (Pareto) front, enabling the algorithm to capture the intrinsic structure of the solution space and thereby improve both convergence and diversity.</p>"},{"location":"user_guide/algorithms/agemoea.html#key-features","title":"Key Features","text":"<ul> <li> <p>Adaptive Geometry-based Search:   AgeMoea leverages non-Euclidean geometric principles to model the shape and curvature of the first front. This approach allows the algorithm to dynamically adjust its search strategy based on the topology and geometric structure of the optimal solutions.</p> </li> <li> <p>Focus on Pareto Front Geometry:   By emphasizing the geometry of the Pareto front, the algorithm can identify promising regions and ensure a balanced distribution of solutions along the front. This strategy favors the exploration of areas of interest while maintaining diversity.</p> </li> <li> <p>Dynamic Evolutionary Process:   Throughout its evolution, AgeMoea adapts its search parameters based on the geometric information extracted from the current solution set. This adaptive mechanism allows for more efficient navigation in complex search spaces, overcoming the limitations of traditional Euclidean metrics.</p> </li> </ul>"},{"location":"user_guide/algorithms/agemoea.html#algorithm-complexity","title":"Algorithm Complexity","text":"<p>As stated in the referenced paper, the computational complexity of this 2 is: $$ O(M \\times N^2) + O(N^3) $$ where \\(M\\) is the number of objectives and \\(N\\) is the population size. This complexity indicates that the algorithm may not be very efficient for large population sizes, since the \\(O(N^3)\\) term can become computationally prohibitive as \\(N\\) increases.</p>"},{"location":"user_guide/algorithms/agemoea.html#how-the-algorithm-works","title":"How the Algorithm Works","text":"<ul> <li> <p>Non-Euclidean Metrics:   Instead of relying solely on Euclidean distance, AgeMoea employs metrics that capture the true curvature and topology of the Pareto front. This distinction allows the algorithm to differentiate between solutions that are geometrically close in a traditional sense but are significantly different along the front.</p> </li> <li> <p>Geometry-based Selection:   The selection phase prioritizes solutions that best represent the geometric structure of the Pareto front. This ensures a balanced representation of diversity and an accurate depiction of the optimal front's shape.</p> </li> <li> <p>Adaptive Parameter Tuning:   As the algorithm iterates, it dynamically adjusts its parameters based on the detected geometric characteristics, enabling more effective exploration and exploitation of the solution space.</p> </li> </ul>"},{"location":"user_guide/algorithms/agemoea.html#conclusion","title":"Conclusion","text":"<p>AgeMoea introduces an innovative approach to many-objective optimization by incorporating non-Euclidean geometric concepts to uncover and exploit the structure of the Pareto front. While its performance on benchmarks like ZTD1 demonstrates its ability to balance convergence and diversity, the computational complexity of \\(\\(O(M \\times N^2) + O(N^3)\\)\\) can be a limiting factor when handling very large populations.</p>"},{"location":"user_guide/algorithms/agemoea.html#ztd1-problem","title":"ZTD1 Problem","text":"<p>This problem was explained in the RNSGA-II section</p> RustPython <pre><code>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::AgeMoeaBuilder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, RandomSamplingFloat, SimulatedBinaryCrossover},\n    genetic::Population\n};\nuse plotters::prelude::*;\n\n/// Evaluate the ZDT1 objectives in a fully vectorized manner.\nfn evaluate_zdt1(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    // First objective: f1 is simply the first column.\n    let n = genes.nrows();\n    let m = genes.ncols();\n\n    let clamped = genes.mapv(|v| v.clamp(0.0, 1.0));\n    let f1 = clamped.column(0).to_owned();\n\n    // Compute g for each candidate: g = 1 + (9/(n-1)) * sum(x[1:])\n    let tail = clamped.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);\n\n    // Compute the second objective: f2 = g * (1 - sqrt(f1/g))\n    let ratio = &amp;f1 / &amp;g;\n    let f2 = &amp;g * &amp;(1.0 - ratio.mapv(|r| r.sqrt()));\n\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result\n}\n\n// Create constraints using the macro impl_constraints_fn\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\n/// Compute the theoretical Pareto front for ZDT1.\nfn zdt1_theoretical_front() -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let steps = 200;\n    let f1_theo: Vec&lt;f64&gt; = (0..steps)\n        .map(|i| i as f64 / (steps as f64 - 1.0))\n        .collect();\n    let f2_theo: Vec&lt;f64&gt; = f1_theo.iter().map(|&amp;f1| 1.0 - f1.sqrt()).collect();\n    (f1_theo, f2_theo)\n}\n\n// Set up AgeMoea algorithm\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let mut algorithm = AgeMoeaBuilder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(SimulatedBinaryCrossover::new(15.0))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))\n        .fitness_fn(evaluate_zdt1)\n        .constraints_fn(BoundConstraints)\n        .num_vars(30)\n        .population_size(100)\n        .num_offsprings(100)\n        .num_iterations(200)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(42)\n        .build()\n        .expect(\"Failed to build AgeMOEA\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"AgeMOEA run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// Compute the theoretical Pareto front for ZDT1\nlet (f1_theo, f2_theo) = zdt1_theoretical_front();\n\n// Plot the theoretical Pareto front and the obtained front\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    // Compute min/max from actual data\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n\n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n\n    // Add a small margin (5%)\n    let xr = (x_max - x_min);\n    let yr = (y_max - y_min);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"ZDT1 Pareto Front: Theoretical vs Obtained\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    // Plot theoretical front as markers (e.g., diamonds) to show discontinuities.\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));\n\n    // Plot obtained front as red circles.\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\n// Emit as rich output for evcxr\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</code></pre> <p></p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    AgeMoea,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_ztd1(x: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the ZTD1 objectives in a fully vectorized manner.\n    \"\"\"\n    f1 = x[:, 0]\n    g = 1 + 9.0 / (30 - 1) * np.sum(x[:, 1:], axis=1)\n    f2 = g * (1 - np.power((f1 / g), 0.5))\n    return np.column_stack((f1, f2))\n\n\ndef ztd1_theoretical_front():\n    \"\"\"\n    Compute the theoretical Pareto front for ZTD1.\n    \"\"\"\n    f1_theo = np.linspace(0, 1, 200)\n    f2_theo = 1 - np.sqrt(f1_theo)\n    return f1_theo, f2_theo\n\n\n# Set up AgeMoea algorithm\nalgorithm = AgeMoea(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=SimulatedBinaryCrossover(distribution_index=15),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_ztd1,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=30,\n    population_size=100,\n    num_offsprings=100,\n    num_iterations=200,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    verbose=False,\n    seed=42,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\nobtained_fitness = best.fitness\n\n# Compute the theoretical Pareto front for ZTD1\nf1_theo, f2_theo = ztd1_theoretical_front()\n\n# Plot the theoretical Pareto front, obtained front, and reference points\nplt.figure(figsize=(10, 6))\nplt.plot(f1_theo, f2_theo, \"k-\", linewidth=2, label=\"Theoretical Pareto Front\")\nplt.scatter(\n    obtained_fitness[:, 0],\n    obtained_fitness[:, 1],\n    c=\"r\",\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\nplt.xlabel(\"$f_1$\", fontsize=14)\nplt.ylabel(\"$f_2$\", fontsize=14)\nplt.title(\"ZTD1 Pareto Front: Theoretical vs Obtained (RNSGA-II)\", fontsize=16)\nplt.legend()\nplt.grid(True)\nplt.show()\n</code></pre> <p></p>"},{"location":"user_guide/algorithms/ibea.html","title":"IBEA (Hypervolume-Indicator\u2013Based Evolutionary Algorithm)","text":"<p>IBEA is a multi-objective evolutionary algorithm in which selection pressure is driven entirely by a quality indicator rather than Pareto ranking or density estimators. In the hypervolume-based variant (IBEA-H), fitness values derive from pairwise hypervolume loss contributions, which steers the search to converge toward the Pareto-optimal set while maintaining a well-spread approximation according to the hypervolume indicator.</p> <p>Following Zitzler &amp; K\u00fcnzli (2004), fitness is assigned from pairwise indicator values and selection proceeds by iteratively removing the worst individual while updating the fitness of the remaining solutions. Using the hypervolume indicator provides a direct optimization signal aligned with many practical performance measures.</p>"},{"location":"user_guide/algorithms/ibea.html#key-features","title":"Key Features","text":"<ul> <li>Indicator-Based Fitness Assignment:   Instead of nondominated sorting, IBEA computes a fitness value for each individual from pairwise indicator contributions. For IBEA-H, the indicator is derived from hypervolume loss if one solution is removed in favor of another. A common formulation is:</li> </ul> <p>$$   F(x) = \\sum_{y \\neq x} -\\exp\\left( -\\frac{I(y, x)}{\\kappa} \\right),   $$</p> <p>where \\(I(y, x)\\) is a strictly monotone indicator value (here, a function of hypervolume loss when replacing \\(x\\) by \\(y\\)), and \\(\\kappa &gt; 0\\) controls selection pressure.</p> <ul> <li> <p>Environmental Selection by Iterative Deletion:   IBEA forms a candidate set (typically the current population, or parent\u222aoffspring if an elitist pool is used), then repeatedly deletes the worst-metric individual, updating impacted fitness values after each removal, until the target population size is reached. This procedure is elitist by construction, as higher-quality solutions persist.</p> </li> <li> <p>Diversity via the Indicator:   Unlike crowding-distance methods, diversity emerges implicitly because hypervolume rewards sets that cover the Pareto front and expand the dominated volume. Regions that enlarge the dominated space receive higher preference.</p> </li> </ul>"},{"location":"user_guide/algorithms/ibea.html#implementation-in-moo-rs","title":"Implementation in <code>moo-rs</code>","text":"<p>In <code>moo-rs</code>, the IBEA implementation uses the hypervolume indicator as the core quality measure, with an adaptive \\(\\kappa\\) parameter to dynamically adjust selection pressure during evolution. This adaptation helps balance exploration and exploitation across generations.</p>"},{"location":"user_guide/algorithms/ibea.html#normalization-of-objectives","title":"Normalization of Objectives","text":"<p>Before computing hypervolume contributions, all objective values are normalized to [0,1] using the ideal and nadir points:</p> <ul> <li>Ideal point: Best observed value for each objective.</li> <li>Nadir point: Worst observed value for each objective.</li> </ul> <p>This normalization ensures that objectives are comparable and prevents bias toward any single dimension.</p>"},{"location":"user_guide/algorithms/ibea.html#ihd-indicator-based-on-hypervolume","title":"IHD Indicator Based on Hypervolume","text":"<p>The IHD-indicator (Indicator based on Hypervolume Difference) measures the impact of removing or replacing a solution in terms of hypervolume contribution. It is defined as:</p> \\[ IHD(x, y) = \\begin{cases} IH(y) - IH(x), &amp; \\text{if } x \\text{ dominates } y, \\\\ IH(\\{x, y\\}) - IH(x), &amp; \\text{otherwise}. \\end{cases} \\] <p>Where: - \\(IH(S)\\) denotes the hypervolume of a set \\(S\\) with respect to a reference point \\(r\\). - The hypervolume of a singleton \\(\\{x\\}\\) is the Lebesgue measure of the region dominated by \\(\\{x\\}\\) and bounded by \\(\\{r \\}\\).</p>"},{"location":"user_guide/algorithms/ibea.html#interpretation-of-terms","title":"Interpretation of Terms","text":"<ul> <li> <p>IH(x):   The hypervolume of the singleton set \\(\\{x\\}\\). This is the volume of the hyperrectangle formed between the point \\(\\{x\\}\\) and the reference point \\(\\{r\\}\\).   For a minimization problem with \\(m\\) objectives:   $$   IH(x) = \\prod_{i=1}^{m} (r_i - f_i(x)),   $$   where \\(f_i(x)\\) is the \\(i\\)-th objective value of solution \\(x\\), and \\(r_i\\) is the \\(i\\)-th component of the reference point.</p> </li> <li> <p>\\(IH(\\{x, y\\})\\):   The hypervolume of the set containing both \\(\\{x\\}\\) and \\(\\{y\\}\\). This accounts for the union of dominated regions by both points, avoiding double-counting overlapping areas.</p> </li> </ul>"},{"location":"user_guide/algorithms/ibea.html#why-reference-point-matters","title":"Why Reference Point Matters","text":"<p>The reference point \\(r\\) must be worse than all solutions in every objective dimension. If \\(r\\) is too close to the Pareto front, extreme solutions will have tiny hypervolume contributions, which biases selection against them. To avoid this, choose \\(r\\) significantly larger than the normalized range (e.g., \\([2, 2, ..., 2]\\) after normalization to \\([0,1]\\)).</p>"},{"location":"user_guide/algorithms/ibea.html#key-idea","title":"Key Idea:","text":"<ul> <li>If \\(x\\) dominates \\(y\\), the difference \\(IH(y) - IH(x)\\) reflects the loss in dominated space when replacing \\(x\\) with \\(y\\).</li> <li>Otherwise, \\(IH(x, y) - IH(x)\\) measures the additional hypervolume gained by adding \\(y\\) to a set already containing \\(x\\).</li> </ul>"},{"location":"user_guide/algorithms/ibea.html#expo2-problem","title":"EXPO2 Problem","text":"<p>EXPO2 is a two-objective benchmark crafted to produce a smooth, exponentially shaped Pareto front, challenging algorithms to retain good coverage near the extremes where the trade-off is steep.</p> <ul> <li> <p>Decision Variables: \\(\\mathbf{x} = (x_1, \\ldots, x_n)\\), with \\(x_i \\in [0, 1]\\) for all \\(i\\); a common setting is \\(n = 30\\).</p> </li> <li> <p>Objectives (minimization):   Let   $$   g(\\mathbf{x}) = 1 + \\frac{9}{n-1} \\sum_{i=2}^{n} x_i.   $$   Then define   $$   f_1(\\mathbf{x}) = x_1, \\qquad   f_2(\\mathbf{x}) = g(\\mathbf{x})\\, \\exp!\\left(-\\frac{5\\, x_1}{g(\\mathbf{x})}\\right).   $$</p> </li> <li> <p>Pareto-Optimal Front:   Achieved when \\(g(\\mathbf{x}) = 1\\) (i.e., \\(x_2 = \\cdots = x_n = 0\\)), giving   $$   f_2 = \\exp(-5 f_1), \\quad f_1 \\in [0, 1],   $$   which forms a convex, exponentially decaying front.</p> </li> <li> <p>Key Characteristics:</p> </li> <li>Strongly Nonlinear Trade-Off: The front is steep near \\(f_1 \\approx 0\\), stressing exploration of extreme solutions.</li> <li>Continuous and Convex: No discontinuities; good for assessing distribution and hypervolume growth.</li> <li>Scalable Dimensionality: As \\(n\\) increases, linkage via \\(g(\\mathbf{x})\\) raises difficulty by coupling objectives with many variables.</li> </ul> RustPython <pre><code>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{array, Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::IbeaBuilder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{\n        GaussianMutation, RandomSamplingFloat, SimulatedBinaryCrossover,\n        survival::moo::IbeaHyperVolumeSurvivalOperator,\n    },\n    genetic::Population\n};\nuse plotters::prelude::*;\n\n\n// ==============================\n// EXPO2 \u2014 Objective Evaluation\n// ==============================\nfn evaluate_expo2(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    /// EXPO2 (minimization, 2 objectives).\n    ///\n    /// g(x) = 1 + (9/(n-1)) * sum_{i=2..n} x_i\n    /// f1(x) = x1\n    /// f2(x) = g(x) * exp( -5 * x1 / g(x) )\n    ///\n    /// Typical domain: x_i in [0, 1], i=1..n (e.g., n = 30).\n    let n = genes.nrows();\n    let m = genes.ncols();\n    if m &lt; 2 {\n        panic!(\"EXPO2 requires at least 2 decision variables.\");\n    }\n\n    // g(x)\n    let tail = genes.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);\n\n    let f1 = genes.column(0).to_owned();\n    let f2 = g.iter().zip(f1.iter()).map(|(gi, &amp;f1i)| gi * (-5.0 * f1i / gi).exp()).collect::&lt;Vec&lt;_&gt;&gt;();\n\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;Array2::from_shape_vec((n, 1), f2).unwrap().column(0));\n    result\n}\n\n\n// ==========================================\n// Theoretical Front (g=1 =&gt; x2..xn = 0; f2=exp(-5 f1))\n// ==========================================\n// Returns (f1, f2) arrays of the EXPO2 Pareto front:\n//      f1 in [0, 1], f2 = exp(-5 f1)\nfn expo2_theoretical_front(num_points: usize) -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let mut f1_theo = Vec::with_capacity(num_points);\n    let mut f2_theo = Vec::with_capacity(num_points);\n    for i in 0..num_points {\n        let t = if num_points &lt;= 1 { 0.0 } else { i as f64 / (num_points as f64 - 1.0) };\n        f1_theo.push(t);\n        f2_theo.push((-5.0 * t).exp());\n    }\n    (f1_theo, f2_theo)\n}\n\n\n// =============================\n// Algorithm Setup (IBEA-H)\n// =============================\n// Problem dimensionality\n\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let num_vars: usize = 30;\n    // Hypervolume reference point (minimization \u21d2 worse-than-worst)\n    // We put [4.0, 4.0] far from the normalized range [0,1]\n    let hv_reference = array![4.0, 4.0];\n    // kappa controls the selection pressure in IBEA\n    let kappa = 0.05;\n    let survivor = IbeaHyperVolumeSurvivalOperator::new(hv_reference, kappa);\n\n    let mut algorithm = IbeaBuilder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(SimulatedBinaryCrossover::new(15.0))\n        .mutation(GaussianMutation::new(0.1, 0.1))\n        .survivor(survivor)\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-6))\n        .fitness_fn(evaluate_expo2)\n        .constraints_fn(BoundConstraints)\n        .num_vars(num_vars)\n        .population_size(600)\n        .num_offsprings(600)\n        .num_iterations(600)\n        .mutation_rate(0.2)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(1)\n        .build()\n        .expect(\"Failed to build IBEA\");\n\n    // ===============\n    // Run IBEA\n    // ===============\n    algorithm.run().expect(\"IBEA run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Best front (Population)\nlet fitness = population.fitness;\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\nlet (f1_theo, f2_theo) = expo2_theoretical_front(400);\n\n// Plot the theoretical Pareto front, obtained front, and reference points\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n\n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n\n    let xr = (x_max - x_min).max(1e-9);\n    let yr = (y_max - y_min).max(1e-9);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"EXPO2 Pareto Front: Theoretical vs Obtained (IBEA HyperVolume)\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 2, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 4, RGBColor(31, 119, 180).filled()));\n\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</code></pre> <p></p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Ibea,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints,\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\n\n# ==============================\n# EXPO2 \u2014 Objective Evaluation\n# ==============================\ndef evaluate_expo2(x: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    EXPO2 (minimization, 2 objectives).\n\n    g(x) = 1 + (9/(n-1)) * sum_{i=2..n} x_i\n    f1(x) = x1\n    f2(x) = g(x) * exp( -5 * x1 / g(x) )\n\n    Typical domain: x_i in [0, 1], i=1..n (e.g., n = 30).\n    \"\"\"\n    n = x.shape[1]\n    if n &lt; 2:\n        raise ValueError(\"EXPO2 requires at least 2 decision variables.\")\n\n    # g(x)\n    g = 1.0 + (9.0 / (n - 1)) * np.sum(x[:, 1:], axis=1)\n\n    f1 = x[:, 0]\n    f2 = g * np.exp(-5.0 * x[:, 0] / g)\n\n    return np.column_stack((f1, f2))\n\n\n# ==========================================\n# Theoretical Front (g=1 =&gt; x2..xn = 0; f2=exp(-5 f1))\n# ==========================================\ndef expo2_theoretical_front(num_points: int = 200):\n    \"\"\"\n    Returns (f1, f2) arrays of the EXPO2 Pareto front:\n        f1 in [0, 1], f2 = exp(-5 f1)\n    \"\"\"\n    f1 = np.linspace(0.0, 1.0, num_points)\n    f2 = np.exp(-5.0 * f1)\n    return f1, f2\n\n\n# =============================\n# Algorithm Setup (IBEA-H)\n# =============================\n# Problem dimensionality\nNUM_VARS = 30\n\n# Hypervolume reference point (minimization \u21d2 worse-than-worst)\n# We put [6.0, 6.0] far from the normalized range [0,1]\nHV_REFERENCE_POINT = np.array([4.0, 4.0], dtype=float)\n\n# kappa controls the selection pressure in IBEA\nKAPPA = 0.05\n\n\nalgorithm = Ibea(\n    sampler=RandomSamplingFloat(min=0.0, max=1.0),\n    crossover=SimulatedBinaryCrossover(distribution_index=15),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.1),\n    fitness_fn=evaluate_expo2,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-6),\n    num_vars=NUM_VARS,\n    population_size=600,\n    num_offsprings=600,\n    num_iterations=600,\n    mutation_rate=0.2,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    reference_points=HV_REFERENCE_POINT,\n    kappa=KAPPA,\n    verbose=False,\n    seed=1,\n)\n\n# ===============\n# Run IBEA\n# ===============\nalgorithm.run()\n\n# Best front (Population)\nbest: Population = algorithm.population.best_as_population\nobtained = best.fitness  # shape: (num_solutions, 2)\n\nf1_theo, f2_theo = expo2_theoretical_front(num_points=400)\n# Plot the theoretical Pareto front, obtained front, and reference points\nplt.figure(figsize=(10, 6))\nplt.plot(f1_theo, f2_theo, \"k-\", linewidth=2, label=\"Theoretical Pareto Front\")\nplt.scatter(\n    obtained[:, 0],\n    obtained[:, 1],\n    c=\"r\",\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\n\nplt.xlabel(\"$f_1$\", fontsize=14)\nplt.ylabel(\"$f_2$\", fontsize=14)\nplt.title(\"EXPO2 Pareto Front: Theoretical vs Obtained (IBEA HyperVolume)\", fontsize=16)\nplt.legend()\nplt.grid(True)\nplt.show()\n</code></pre> <p></p>"},{"location":"user_guide/algorithms/ibea.html#references","title":"References","text":"<ul> <li>Zitzler, E., &amp; K\u00fcnzli, S. (2004). Indicator-Based Selection in Multiobjective Search. In PPSN VIII (LNCS 3242, pp. 832\u2013842). Springer.</li> <li>Zitzler, E., Thiele, L., Laumanns, M., Fonseca, C. M., &amp; da Fonseca, V. G. (2003). Performance Assessment of Multiobjective Optimizers: An Analysis and Review. TEO/ETH Technical Report 139.   (Introduces the hypervolume indicator as a robust performance measure.)</li> <li>While various IBEA variants exist (e.g., using the additive \\(\\varepsilon\\)-indicator), this document focuses on the hypervolume-based instantiation commonly used in practice.</li> </ul>"},{"location":"user_guide/algorithms/nsga2.html","title":"NSGA-II","text":"<p>NSGA-II is a fast, elitist multiobjective evolutionary algorithm designed to efficiently approximate the Pareto-optimal front. It overcomes several issues found in earlier nondominated sorting approaches by reducing computational complexity, ensuring elitism, and eliminating the need for a sharing parameter.</p>"},{"location":"user_guide/algorithms/nsga2.html#key-features","title":"Key Features","text":"<ul> <li> <p>Fast Nondominated Sorting:   NSGA-II sorts the population based on Pareto dominance with a computational complexity of   \\(O(MN^2)\\), where \\(M\\) is the number of objectives and \\(N\\) is the population size.</p> </li> <li> <p>Elitist Selection:   The algorithm creates a combined pool of parent and offspring populations. From this pool, the best solutions are chosen based on fitness and diversity. This elitist strategy ensures that the best-found solutions are preserved over generations.</p> </li> <li> <p>Crowding Distance for Diversity Maintenance:   To maintain a diverse Pareto front, NSGA-II computes a crowding distance for each individual. For each front, the crowding distance \\(d_i\\) of an individual \\(i\\) is calculated as:</p> </li> </ul> <p>$$   d_i = \\sum_{m=1}^{M} \\frac{f_{m}^{(i+1)} - f_{m}^{(i-1)}}{f_{m}^{\\max} - f_{m}^{\\min}},   $$</p> <p>where:</p> <ul> <li>\\(f_{m}^{(i)}\\) is the value of the \\(m\\)-th objective for the \\(i\\)-th individual (after sorting the individuals according to that objective),</li> <li>\\(f_{m}^{\\max}\\) and \\(f_{m}^{\\min}\\) are the maximum and minimum values of the \\(m\\)-th objective in that front, respectively.</li> </ul> <p>Individuals with a larger crowding distance are in less crowded regions and are preferred when selecting among solutions with the same non-domination rank, thereby promoting diversity across the Pareto front.</p> <ul> <li>Constraint Handling:   When constraints_fn are present, NSGA-II modifies the selection process:</li> <li>Feasible Solutions First: Feasible individuals (those satisfying all constraints_fn) are always preferred over infeasible ones.</li> <li>Ranking: Among feasible solutions, those with a better (i.e., lower) nondominated rank are favored.</li> <li>Crowding Distance: Finally, if individuals share the same rank, the one with a larger crowding distance is selected. This ensures that, within the same rank, solutions from less crowded regions of the objective space are chosen.</li> </ul>"},{"location":"user_guide/algorithms/nsga2.html#zdt3-problem","title":"ZDT3 Problem","text":"<p>ZDT3 is a widely used benchmark in multiobjective optimization, especially for testing evolutionary algorithms. It challenges algorithms with:</p> <ul> <li>Two Conflicting Objectives:</li> <li>\\(f_1(\\mathbf{x}) = x_1\\)</li> <li> <p>\\(f_2(\\mathbf{x}) = g(\\mathbf{x}) \\cdot h(f_1(\\mathbf{x}), g(\\mathbf{x}))\\)</p> </li> <li> <p>Auxiliary Functions:</p> </li> <li>\\(g(\\mathbf{x}) = 1 + \\frac{9}{n-1}\\sum_{i=2}^{n} x_i\\)</li> <li> <p>\\(h(f_1, g) = 1 - \\sqrt{\\frac{f_1}{g}} - \\frac{f_1}{g}\\sin(10\\pi f_1)\\)</p> </li> <li> <p>Key Characteristics:</p> </li> <li>Discontinuous Pareto Front: The optimal solutions are spread over several disconnected segments.</li> <li>Nonconvexity: The Pareto front is nonconvex, making convergence more challenging.</li> <li>Diversity Maintenance: The discontinuities force algorithms to preserve a diverse set of solutions.</li> </ul> <p>Domain: Each decision variable \\(x_i\\) typically belongs to the interval \\([0, 1]\\), and the problem is often considered with \\(n = 30\\) variables.</p> <p>ZDT3 is ideal for evaluating how well an algorithm can balance convergence toward the Pareto-optimal front while maintaining diversity in the presence of a complex, discontinuous solution landscape.</p> RustPython <pre><code>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::Nsga2Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, RandomSamplingFloat, ExponentialCrossover},\n    genetic::Population\n};\nuse plotters::prelude::*;\n\n/// Evaluate the ZDT3 objectives in a fully vectorized manner.\nfn evaluate_zdt3(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    // First objective: f1 is simply the first column.\n    // NOTE: We clamp to [0,1] during evaluation to keep the domain consistent with ZDT3.\n    // This mirrors the Python setup where variables are constrained to [0,1].\n    let n = genes.nrows();\n    let m = genes.ncols();\n\n    let clamped = genes.mapv(|v| v.clamp(0.0, 1.0));\n    let f1 = clamped.column(0).to_owned();\n\n    // Compute g for each candidate: g = 1 + (9/(n-1)) * sum(x[1:])\n    let tail = clamped.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);\n\n    // Compute h for each candidate: h = 1 - sqrt(f1/g) - (f1/g)*sin(10*pi*f1)\n    let ratio = &amp;f1 / &amp;g;\n    let sin_term = f1.mapv(|v| (10.0 * std::f64::consts::PI * v).sin());\n    let h = 1.0 - ratio.mapv(|r| r.sqrt()) - &amp;(&amp;ratio * &amp;sin_term);\n\n    // Compute the second objective: f2 = g * h\n    let f2 = &amp;g * &amp;h;\n\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result\n}\n\n// Create constraints using the macro impl_constraints_fn\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\n\n/// Compute the theoretical Pareto front for ZDT3.\n///\n/// Returns:\n///     f1_theo (np.ndarray): f1 values on the theoretical front.\n///     f2_theo (np.ndarray): Corresponding f2 values.\n///\n/// Instead of using a dense linspace, we sample only a few points per interval to\n/// clearly illustrate the discontinuous nature of the front.\nfn zdt3_theoretical_front() -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    // Define the intervals for f1 where the Pareto front exists\n    let intervals: &amp;[(f64, f64)] = &amp;[\n        (0.0, 0.0830015349),\n        (0.1822287280, 0.2577623634),\n        (0.4093136748, 0.4538828821),\n        (0.6183967944, 0.6525117038),\n        (0.8233317983, 0.85518),\n    ];\n\n    let mut f1_theo: Vec&lt;f64&gt; = Vec::new();\n    let mut f2_theo: Vec&lt;f64&gt; = Vec::new();\n\n    // Use a small number of points per interval (e.g., 20) to highlight the discontinuities.\n    for (start, end) in intervals.iter().copied() {\n        let steps = 20usize;\n        for i in 0..steps {\n            let t = i as f64 / (steps as f64 - 1.0);\n            let f1 = start + t * (end - start);\n            let f2 = 1.0 - f1.sqrt() - f1 * (10.0 * std::f64::consts::PI * f1).sin();\n            f1_theo.push(f1);\n            f2_theo.push(f2);\n        }\n    }\n\n    (f1_theo, f2_theo)\n}\n\n// Set up the NSGA2 algorithm with the above definitions\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let mut algorithm = Nsga2Builder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(ExponentialCrossover::new(0.75))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-5))\n        .fitness_fn(evaluate_zdt3)\n        .constraints_fn(BoundConstraints)\n        .num_vars(30)\n        .population_size(200)\n        .num_offsprings(200)\n        .num_iterations(300)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(42)\n        .build()\n        .expect(\"Failed to build NSGA2\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"NSGA2 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// Compute the theoretical Pareto front for ZDT3\nlet (f1_theo, f2_theo) = zdt3_theoretical_front();\n\n// Plot the theoretical Pareto front and the obtained front\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    // Compute min/max from actual data\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n\n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n\n    // Add a small margin (5%)\n    let xr = (x_max - x_min);\n    let yr = (y_max - y_min);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"ZDT3 Pareto Front: Theoretical vs Obtained\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    // Plot theoretical front as markers (e.g., diamonds) to show discontinuities.\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));\n\n    // Plot obtained front as red circles.\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\n// Emit as rich output for evcxr\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</code></pre> <p></p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Nsga2,\n    RandomSamplingFloat,\n    GaussianMutation,\n    ExponentialCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_zdt3(population: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the ZDT3 objectives in a fully vectorized manner.\n    \"\"\"\n    # First objective: f1 is simply the first column.\n    f1 = population[:, 0]\n    n = population.shape[1]\n    # Compute g for each candidate: g = 1 + (9/(n-1)) * sum(x[1:])\n    g = 1 + (9 / (n - 1)) * np.sum(population[:, 1:], axis=1)\n    # Compute h for each candidate: h = 1 - sqrt(f1/g) - (f1/g)*sin(10*pi*f1)\n    h = 1 - np.sqrt(f1 / g) - (f1 / g) * np.sin(10 * np.pi * f1)\n    # Compute the second objective: f2 = g * h\n    f2 = g * h\n    return np.column_stack((f1, f2))\n\n\ndef zdt3_theoretical_front():\n    \"\"\"\n    Compute the theoretical Pareto front for ZDT3.\n\n    Returns:\n        f1_theo (np.ndarray): f1 values on the theoretical front.\n        f2_theo (np.ndarray): Corresponding f2 values.\n\n    Instead of using a dense linspace, we sample only a few points per interval to\n    clearly illustrate the discontinuous nature of the front.\n    \"\"\"\n    # Define the intervals for f1 where the Pareto front exists\n    intervals = [\n        (0.0, 0.0830015349),\n        (0.1822287280, 0.2577623634),\n        (0.4093136748, 0.4538828821),\n        (0.6183967944, 0.6525117038),\n        (0.8233317983, 0.85518),\n    ]\n\n    f1_theo = np.array([])\n    f2_theo = np.array([])\n\n    # Use a small number of points per interval (e.g., 20) to highlight the discontinuities.\n    for start, end in intervals:\n        f1_vals = np.linspace(start, end, 20)\n        f2_vals = 1 - np.sqrt(f1_vals) - f1_vals * np.sin(10 * np.pi * f1_vals)\n        f1_theo = np.concatenate((f1_theo, f1_vals))\n        f2_theo = np.concatenate((f2_theo, f2_vals))\n\n    return f1_theo, f2_theo\n\n\n# Set up the NSGA2 algorithm with the above definitions\nalgorithm = Nsga2(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=ExponentialCrossover(exponential_crossover_rate=0.75),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_zdt3,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-5),\n    num_vars=30,\n    population_size=200,\n    num_offsprings=200,\n    num_iterations=300,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    verbose=False,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\n\n# Extract the obtained fitness values (each row is [f1, f2])\nobtained_fitness = best.fitness\nf1_found = obtained_fitness[:, 0]\nf2_found = obtained_fitness[:, 1]\n\n# Compute the theoretical Pareto front for ZDT3\nf1_theo, f2_theo = zdt3_theoretical_front()\n\n# Plot the theoretical Pareto front and the obtained front\nplt.figure(figsize=(10, 6))\n# Plot theoretical front as markers (e.g., diamonds) to show discontinuities.\nplt.scatter(\n    f1_theo, f2_theo, marker=\"D\", color=\"blue\", label=\"Theoretical Pareto Front\"\n)\n# Plot obtained front as red circles.\nplt.scatter(f1_found, f2_found, c=\"r\", marker=\"o\", s=10, label=\"Obtained Front\")\nplt.xlabel(\"$f_1$\", fontsize=14)\nplt.ylabel(\"$f_2$\", fontsize=14)\nplt.title(\"ZDT3 Pareto Front: Theoretical vs Obtained\", fontsize=16)\nplt.legend()\nplt.grid(True)\n</code></pre> <p></p>"},{"location":"user_guide/algorithms/nsga3.html","title":"NSGA-III","text":"<p>NSGA-III is a reference point-based evolutionary algorithm that extends the NSGA-II framework to handle multi-objective problems more effectively. In the context of 3-objective optimization, NSGA-III ensures a well-distributed approximation of the Pareto front by incorporating a set of pre-defined reference points to guide the selection process.</p>"},{"location":"user_guide/algorithms/nsga3.html#key-features","title":"Key Features","text":"<ul> <li> <p>Non-Dominated Sorting:   The algorithm classifies the population into different fronts based on Pareto dominance, identifying the non-dominated solutions.</p> </li> <li> <p>Normalization:   Objective values are normalized using the ideal and nadir points to account for differences in scale among objectives.</p> </li> <li> <p>Reference Point Association:   A set of uniformly distributed reference points in the normalized objective space is predefined. Each solution is associated with the reference point to which it has the smallest perpendicular distance, ensuring a uniform spread across the Pareto front.</p> </li> <li> <p>Survival Selection:   When the number of solutions exceeds the desired population size, NSGA-III selects individuals based on their perpendicular distance to the associated reference points, prioritizing those that contribute to both convergence and diversity.</p> </li> </ul>"},{"location":"user_guide/algorithms/nsga3.html#reference-point-association","title":"Reference Point Association","text":"<p>Let \\(\\{\\mathbf{r}^1, \\mathbf{r}^2, \\dots, \\mathbf{r}^R\\}\\) be a set of uniformly distributed reference points in the normalized space, where each \\(\\mathbf{r}^i \\in \\mathbb{R}^3\\). The perpendicular distance from a solution \\(\\mathbf{f}'(\\mathbf{x})\\) to a reference point \\(\\mathbf{r}\\) is calculated by:</p> \\[ d_\\perp\\left(\\mathbf{f}'(\\mathbf{x}), \\mathbf{r}\\right) = \\left\\| \\mathbf{f}'(\\mathbf{x}) - \\left( \\frac{\\mathbf{f}'(\\mathbf{x}) \\cdot \\mathbf{r}}{\\|\\mathbf{r}\\|^2} \\right) \\mathbf{r} \\right\\|. \\] <p>Each solution is associated with the reference point that minimizes this perpendicular distance, guiding the selection process toward a balanced distribution along the Pareto front.</p> <p>Reference points play a crucial role in guiding the search process in both NSGA-III and RNSGA-II, yet they are used in distinct ways.</p>"},{"location":"user_guide/algorithms/nsga3.html#reference-points-in-nsga-iii","title":"Reference Points in NSGA-III","text":"<ul> <li> <p>Association Mechanism:   In NSGA-III, a set of uniformly distributed reference points (or directions) is generated in the normalized objective space. Each solution is associated with the reference point to which it has the smallest perpendicular distance.</p> </li> <li> <p>Niche Preservation:   The environmental selection aims to fill as many niches as possible, ideally selecting one solution per reference point. This approach promotes a uniform spread of solutions along the Pareto front.</p> </li> <li> <p>Population and Reference Points Relationship:   Although it might seem that the number of reference points is analogous to the population size, in practice the number of reference points is determined by the desired granularity (for example, using a parameter such as the number of divisions per objective). Thus, the set of reference points may be smaller or larger than the population size; the key objective is to cover the objective space effectively.</p> </li> </ul>"},{"location":"user_guide/algorithms/nsga3.html#reference-points-in-rnsga-ii","title":"Reference Points in RNSGA-II","text":"<ul> <li> <p>Multiple Associations:   In contrast to NSGA-III, RNSGA-II incorporates reference points during the survival selection phase as an additional criterion. Here, a single reference point can influence the evaluation of multiple solutions. That is, several solutions can be compared based on their proximity to the same reference point.</p> </li> <li> <p>Selection Criteria:   RNSGA-II ranks solutions not only by Pareto dominance and crowding distance but also by their closeness to the predefined reference points. This added metric helps steer the search toward regions of interest as specified by the decision-maker.</p> </li> <li> <p>Focus and Diversity:   While NSGA-III uses reference points primarily to preserve a balanced distribution across the Pareto front (ideally one solution per reference point), RNSGA-II uses them to both maintain diversity and focus the search on promising regions. This means that in RNSGA-II, the same reference point may guide the selection of multiple solutions if they are all near that region.</p> </li> </ul>"},{"location":"user_guide/algorithms/nsga3.html#comparison-summary","title":"Comparison Summary","text":"<ul> <li>Mapping:</li> <li>NSGA-III: Strives for a one-to-one association between solutions and reference points, leading to a well-spread Pareto front.</li> <li> <p>RNSGA-II: Allows multiple solutions to be associated with a single reference point, using proximity as an extra criterion to prioritize solutions.</p> </li> <li> <p>Role in the Algorithm:</p> </li> <li>NSGA-III: Uses reference points to divide the objective space into niches, ensuring uniform coverage.</li> <li> <p>RNSGA-II: Integrates reference point proximity into the ranking mechanism alongside dominance and crowding, thus guiding the search toward specific areas of interest.</p> </li> <li> <p>Population Relation:   While NSGA-III's reference points are designed to cover the objective space and might appear analogous to the population size, their actual number is set by algorithm parameters rather than being inherently equal to the number of solutions. In RNSGA-II, no such one-to-one expectation exists; a reference point can be linked to multiple solutions as needed.</p> </li> </ul> <p>This nuanced difference highlights how NSGA-III and RNSGA-II employ reference points to balance convergence and diversity, each tailoring the mechanism to suit their specific selection strategies.</p>"},{"location":"user_guide/algorithms/nsga3.html#dtlz2-for-3-objectives","title":"DTLZ2 for 3 Objectives","text":"<p>To evaluate NSGA-III in a 3-objective scenario, the DTLZ2 problem is a popular benchmark due to its continuous and convex Pareto front.</p>"},{"location":"user_guide/algorithms/nsga3.html#decision-variables","title":"Decision Variables","text":"<p>Let the decision vector be \\(\\mathbf{x} = (x_1, x_2, \\dots, x_n)\\) with each variable bounded by:</p> \\[ x_i \\in [0, 1], \\quad i = 1, 2, \\dots, n. \\] <p>For a 3-objective version, the number of decision variables is typically set as:</p> \\[ n = 3 - 1 + k, \\] <p>where \\(k\\) is the number of distance-related variables.</p>"},{"location":"user_guide/algorithms/nsga3.html#objective-functions","title":"Objective Functions","text":"<p>DTLZ2 defines an auxiliary function:</p> \\[ g(\\mathbf{x}) = \\sum_{i=3}^{n} (x_i - 0.5)^2. \\] <p>The three objective functions are then given by:</p> \\[ f_1(\\mathbf{x}) = (1 + g(\\mathbf{x})) \\cdot \\cos\\left(\\frac{\\pi}{2} x_1\\right) \\cdot \\cos\\left(\\frac{\\pi}{2} x_2\\right), \\] \\[ f_2(\\mathbf{x}) = (1 + g(\\mathbf{x})) \\cdot \\cos\\left(\\frac{\\pi}{2} x_1\\right) \\cdot \\sin\\left(\\frac{\\pi}{2} x_2\\right), \\] \\[ f_3(\\mathbf{x}) = (1 + g(\\mathbf{x})) \\cdot \\sin\\left(\\frac{\\pi}{2} x_1\\right). \\]"},{"location":"user_guide/algorithms/nsga3.html#pareto-front-characteristics","title":"Pareto Front Characteristics","text":"<p>When \\(g(\\mathbf{x}) = 0\\), the objective functions simplify to:</p> \\[ f_1(\\mathbf{x}) = \\cos\\left(\\frac{\\pi}{2} x_1\\right) \\cdot \\cos\\left(\\frac{\\pi}{2} x_2\\right), \\] \\[ f_2(\\mathbf{x}) = \\cos\\left(\\frac{\\pi}{2} x_1\\right) \\cdot \\sin\\left(\\frac{\\pi}{2} x_2\\right), \\] \\[ f_3(\\mathbf{x}) = \\sin\\left(\\frac{\\pi}{2} x_1\\right). \\] <p>These solutions lie on the surface of a unit hypersphere in the objective space, defined by:</p> \\[ f_1^2(\\mathbf{x}) + f_2^2(\\mathbf{x}) + f_3^2(\\mathbf{x}) = 1. \\] <p>This continuous and convex Pareto front makes DTLZ2 an excellent test case to assess the balance between convergence and diversity in NSGA-III.</p> RustPython <pre><code>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotly = \"*\"\n\nuse ndarray::{Array1, Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::Nsga3Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{\n        GaussianMutation,\n        RandomSamplingFloat,\n        SimulatedBinaryCrossover,\n        Nsga3ReferencePointsSurvival,\n        Nsga3ReferencePoints,\n        DanAndDenisReferencePoints,\n        StructuredReferencePoints\n    },\n    genetic::Population,\n};\n\nuse plotly::{Plot, Scatter3D, Layout, Trace};\nuse plotly::common::{Mode, Marker, Title, MarkerSymbol};\nuse plotly::color::NamedColor;\nuse plotly::layout::{LayoutScene as Scene, Axis as PlotlyAxis};\n\n\n/// Evaluate the DTLZ2 objectives for a 3-objective problem.\n///\n/// The decision vector x has num_vars components. For the Pareto front,\n/// the auxiliary function g(x) is minimized (g(x)=0) by setting the last\n/// num_vars-2 variables to 0.5.\n///\n/// The objectives are computed as:\n///   f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2)\n///   f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2)\n///   f3(x) = (1+g) * sin((pi/2)*x1)\nfn evaluate_dtlz2(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let n = genes.nrows();\n    let pi_over_2 = std::f64::consts::PI / 2.0;\n\n    // Compute the auxiliary function g(x) using variables 3 to num_vars.\n    let tail = genes.slice(s![.., 2..]).to_owned();\n    let g_vec: Array1&lt;f64&gt; = tail.mapv(|v| (v - 0.5).powi(2)).sum_axis(Axis(1));\n\n    // x1, x2\n    let x1 = genes.column(0).to_owned();\n    let x2 = genes.column(1).to_owned();\n\n    // Trig terms\n    let cos_x1 = x1.mapv(|v| (pi_over_2 * v).cos());\n    let cos_x2 = x2.mapv(|v| (pi_over_2 * v).cos());\n    let sin_x1 = x1.mapv(|v| (pi_over_2 * v).sin());\n    let sin_x2 = x2.mapv(|v| (pi_over_2 * v).sin());\n\n    let one_plus_g = g_vec.mapv(|g| 1.0 + g);\n\n    // f1, f2, f3 as Array1\n    let f1 = &amp;one_plus_g * &amp;cos_x1 * &amp;cos_x2;\n    let f2 = &amp;one_plus_g * &amp;cos_x1 * &amp;sin_x2;\n    let f3 = &amp;one_plus_g * &amp;sin_x1;\n\n    // Stack into (n, 3)\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 3));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result.column_mut(2).assign(&amp;f3);\n    result\n}\n\n/// Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives).\n///\n/// For the Pareto-optimal front, g(x) = 0, which implies that the decision variables\n/// x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2:\n///   f1 = cos((pi/2)*x1) * cos((pi/2)*x2)\n///   f2 = cos((pi/2)*x1) * sin((pi/2)*x2)\n///   f3 = sin((pi/2)*x1)\n/// These points lie on a portion of the unit hypersphere in the positive orthant.\nfn dtlz2_theoretical_front(num_points: usize) -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let pi_over_2 = std::f64::consts::PI / 2.0;\n\n    let mut f1_all = Vec::with_capacity(num_points * num_points);\n    let mut f2_all = Vec::with_capacity(num_points * num_points);\n    let mut f3_all = Vec::with_capacity(num_points * num_points);\n\n    for i in 0..num_points {\n        let x1 = if num_points &gt; 1 {\n            i as f64 / (num_points as f64 - 1.0)\n        } else {\n            0.0\n        };\n        for j in 0..num_points {\n            let x2 = if num_points &gt; 1 {\n                j as f64 / (num_points as f64 - 1.0)\n            } else {\n                0.0\n            };\n\n            let f1 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).cos();\n            let f2 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).sin();\n            let f3 = (pi_over_2 * x1).sin();\n\n            f1_all.push(f1);\n            f2_all.push(f2);\n            f3_all.push(f3);\n        }\n    }\n\n    (f1_all, f2_all, f3_all)\n}\n\n// Set up the NSGA-III algorithm for DTLZ2.\n// For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k.\n// Here, we choose k = 10, so num_vars = 2 + 10 = 12.\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\n\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let rp = DanAndDenisReferencePoints::new(100, 3).generate();\n    let nsga3_rp = Nsga3ReferencePoints::new(rp, false);\n    let survivor = Nsga3ReferencePointsSurvival::new(nsga3_rp);\n    let mut algorithm = Nsga3Builder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(SimulatedBinaryCrossover::new(10.0)) // distribution_index = 10\n        .mutation(GaussianMutation::new(0.1, 0.01))     // gene_mutation_rate = 0.1, sigma = 0.01\n        .survivor(survivor)\n        .fitness_fn(evaluate_dtlz2)\n        .constraints_fn(BoundConstraints)\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))\n        .num_vars(12)\n        .population_size(500)\n        .num_offsprings(500)\n        .num_iterations(700)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(1729)\n        .build()\n        .expect(\"Failed to build NSGA3\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"NSGA3 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Define again rp just for plotting\nlet rp_plot: Array2&lt;f64&gt; = DanAndDenisReferencePoints::new(100, 3).generate();\nlet rp_f1: Vec&lt;f64&gt; = rp_plot.column(0).to_vec();\nlet rp_f2: Vec&lt;f64&gt; = rp_plot.column(1).to_vec();\nlet rp_f3: Vec&lt;f64&gt; = rp_plot.column(2).to_vec();\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2, f3])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\nlet f3_found: Vec&lt;f64&gt; = fitness.column(2).to_vec();\n\n// Compute the theoretical Pareto front for DTLZ2 (dense grid on the positive octant of the unit sphere)\nlet (f1_theo, f2_theo, f3_theo) = dtlz2_theoretical_front(50);\n\n// Build Plotly traces for 3D scatter (theoretical vs obtained)\nlet theoretical_trace = Scatter3D::new(f1_theo.clone(), f2_theo.clone(), f3_theo.clone())\n    .mode(Mode::Markers)\n    .name(\"Theoretical Pareto Front\")\n    .marker(Marker::new().size(3).color(NamedColor::Black).opacity(0.5));\n\nlet obtained_trace = Scatter3D::new(f1_found.clone(), f2_found.clone(), f3_found.clone())\n    .mode(Mode::Markers)\n    .name(\"Obtained Front\")\n    .marker(Marker::new().size(5).color(NamedColor::Red));\n\nlet refpoints_trace = Scatter3D::new(rp_f1, rp_f2, rp_f3)\n    .mode(Mode::Markers)\n    .name(\"Reference Points\")\n    .marker(\n        Marker::new()\n            .size(8)\n            .color(NamedColor::Magenta)\n            .symbol(MarkerSymbol::Star)\n    );\n\n// Layout con Title builder y PlotlyAxis (alias para evitar conflicto con ndarray::Axis)\nlet layout: Layout = Layout::new()\n    .width(800)\n    .height(600)\n    .title(Title::from(\"DTLZ2 Pareto Front: Theoretical vs Obtained (NSGA-III)\"))\n    .scene(\n        Scene::new()\n            .x_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;1&lt;/sub&gt;\")))\n            .y_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;2&lt;/sub&gt;\")))\n            .z_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;3&lt;/sub&gt;\")))\n        // .aspect_mode(plotly::layout::scene::AspectMode::Cube) // opcional\n    );\n\n// Compose the plot\nlet mut plot = Plot::new();\nplot.add_trace(theoretical_trace);\nplot.add_trace(obtained_trace);\nplot.add_trace(refpoints_trace);\nplot.set_layout(layout);\n\n// Render as rich HTML for evcxr\nlet html = plot.to_html();\nprintln!(\"EVCXR_BEGIN_CONTENT text/html\\n{}\\nEVCXR_END_CONTENT\", html);\n</code></pre> <p></p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Nsga3,\n    DanAndDenisReferencePoints,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_dtlz2(x: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the DTLZ2 objectives for a 3-objective problem.\n\n    The decision vector x has num_vars components. For the Pareto front,\n    the auxiliary function g(x) is minimized (g(x)=0) by setting the last\n    num_vars-2 variables to 0.5.\n\n    The objectives are computed as:\n      f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2)\n      f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2)\n      f3(x) = (1+g) * sin((pi/2)*x1)\n    \"\"\"\n    # Compute the auxiliary function g(x) using variables 3 to num_vars.\n    g = np.sum((x[:, 2:] - 0.5) ** 2, axis=1)\n    f1 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.cos((np.pi / 2) * x[:, 1])\n    f2 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.sin((np.pi / 2) * x[:, 1])\n    f3 = (1 + g) * np.sin((np.pi / 2) * x[:, 0])\n    return np.column_stack((f1, f2, f3))\n\n\ndef dtlz2_theoretical_front(num_points=50):\n    \"\"\"\n    Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives).\n\n    For the Pareto-optimal front, g(x) = 0, which implies that the decision variables\n    x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2:\n      f1 = cos((pi/2)*x1) * cos((pi/2)*x2)\n      f2 = cos((pi/2)*x1) * sin((pi/2)*x2)\n      f3 = sin((pi/2)*x1)\n    These points lie on a portion of the unit hypersphere in the positive orthant.\n    \"\"\"\n    x1 = np.linspace(0, 1, num_points)\n    x2 = np.linspace(0, 1, num_points)\n    X1, X2 = np.meshgrid(x1, x2)\n    X1_flat = X1.flatten()\n    X2_flat = X2.flatten()\n\n    f1 = np.cos((np.pi / 2) * X1_flat) * np.cos((np.pi / 2) * X2_flat)\n    f2 = np.cos((np.pi / 2) * X1_flat) * np.sin((np.pi / 2) * X2_flat)\n    f3 = np.sin((np.pi / 2) * X1_flat)\n    return f1, f2, f3\n\n\n# Create the reference points using DanAndDenisReferencePoints.\n# This object generates reference points for NSGA-III.\nref_points = DanAndDenisReferencePoints(n_reference_points=100, n_objectives=3)\n\n# Set up the NSGA-III algorithm for DTLZ2.\n# For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k.\n# Here, we choose k = 10, so num_vars = 2 + 10 = 12.\nalgorithm = Nsga3(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=SimulatedBinaryCrossover(distribution_index=10),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_dtlz2,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=12,\n    population_size=500,\n    num_offsprings=500,\n    num_iterations=700,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    reference_points=ref_points,\n    verbose=False,\n    seed=1729,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\nobtained_fitness = best.fitness  # Shape: (num_solutions, 3)\n\n# Compute the theoretical Pareto front for DTLZ2\nf1_theo, f2_theo, f3_theo = dtlz2_theoretical_front(num_points=50)\n\n# Plot the theoretical Pareto front, the obtained front, and the reference points in 3D.\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111, projection=\"3d\")\n\n# Plot the theoretical Pareto front as a scatter of many points.\nax.scatter(\n    f1_theo,\n    f2_theo,\n    f3_theo,\n    c=\"k\",\n    marker=\".\",\n    label=\"Theoretical Pareto Front\",\n    alpha=0.5,\n)\n\n# Plot the obtained Pareto front from the algorithm.\nax.scatter(\n    obtained_fitness[:, 0],\n    obtained_fitness[:, 1],\n    obtained_fitness[:, 2],\n    c=\"r\",\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\n\n# Plot the reference points.\n# Extract the reference points array from the DanAndDenisReferencePoints object.\nref_points_array = ref_points.generate()\nax.scatter(\n    ref_points_array[:, 0],\n    ref_points_array[:, 1],\n    ref_points_array[:, 2],\n    marker=\"*\",\n    s=200,\n    color=\"magenta\",\n    label=\"Reference Points\",\n)\n\nax.set_xlabel(\"$f_1$\", fontsize=14)\nax.set_ylabel(\"$f_2$\", fontsize=14)\nax.set_zlabel(\"$f_3$\", fontsize=14)\nax.set_title(\"DTLZ2 Pareto Front: Theoretical vs Obtained (NSGA-III)\", fontsize=16)\nax.legend()\nplt.show()\n</code></pre> <p></p>"},{"location":"user_guide/algorithms/nsga3.html#das-and-dennis-procedure-for-generating-reference-points","title":"Das and Dennis Procedure for Generating Reference Points","text":"<p>The Das and Dennis procedure is a systematic method for generating a uniformly distributed set of reference points on the unit simplex in the objective space. This technique is widely used in multi-objective optimization algorithms, such as NSGA-III, to guide the search process by ensuring balanced coverage of the Pareto front.</p>"},{"location":"user_guide/algorithms/nsga3.html#steps-of-the-procedure","title":"Steps of the Procedure","text":"<ol> <li> <p>Define the Number of Objectives and Divisions:    For a problem with \\(M\\) objectives, choose a parameter \\(H\\) (sometimes denoted as \\(p\\)) which represents the number of divisions along each axis of the objective space. This parameter \\( H \\) determines the granularity of the generated reference points.</p> </li> <li> <p>Generate Integer Combinations:    Generate all combinations of non-negative integers \\((a_1, a_2, \\dots, a_M)\\) that satisfy:    $$    a_1 + a_2 + \\cdots + a_M = H.    $$    Each combination represents a unique way of partitioning the total number of divisions among the objectives.</p> </li> <li> <p>Map to the Simplex:    Each integer combination is then mapped to a reference point on the unit simplex using:    $$    \\mathbf{r} = \\left(\\frac{a_1}{H}, \\frac{a_2}{H}, \\dots, \\frac{a_M}{H}\\right).    $$    Since the components of \\(\\mathbf{r}\\) sum to 1, every point lies on the unit simplex, ensuring a uniform distribution across the objective space.</p> </li> </ol>"},{"location":"user_guide/algorithms/nsga3.html#characteristics-and-comparison","title":"Characteristics and Comparison","text":"<ul> <li> <p>Uniformity:   The procedure guarantees that the generated reference points are uniformly distributed over the simplex. This uniformity is critical for effectively exploring all regions of the Pareto front.</p> </li> <li> <p>Relation to Population:   In NSGA-III, each solution is associated with the nearest reference point based on a perpendicular distance metric. Although the number of reference points is not strictly equal to the population size, they are designed to cover the objective space in such a way that promotes diver</p> </li> </ul>"},{"location":"user_guide/algorithms/revea.html","title":"REVEA","text":"<p>REVEA (Reference Vector Guided Evolutionary Algorithm) is a many-objective evolutionary algorithm designed to efficiently approximate the Pareto front by dynamically adapting a set of reference vectors. By guiding the search with these vectors, REVEA maintains a balance between convergence toward optimality and diversity across the objective space.</p>"},{"location":"user_guide/algorithms/revea.html#key-features","title":"Key Features","text":"<ul> <li> <p>Dynamic Reference Vectors:   REVEA starts with an initial set of reference vectors and periodically updates them using the current population\u2019s extreme objective values (the ideal and nadir points). This update mechanism ensures that the reference vectors remain aligned with the evolving search space.</p> </li> <li> <p>Angle Penalized Distance (APD):   A core component of REVEA is the Angle Penalized Distance metric, which combines the angular deviation (denoted by \\(\\theta\\), the angle between a solution and its associated reference vector) with a scaling factor that adapts over generations. In essence, APD favors solutions that are both close in direction to the reference vector and robust in magnitude.</p> </li> <li> <p>Reference Vector Association:   Each solution is associated with the reference vector with which it has the highest cosine similarity. This association partitions the population into niches, promoting a uniform spread of solutions along the Pareto front.</p> </li> <li> <p>Adaptive Selection:   In the survival selection phase, REVEA selects, from each niche, the solution with the smallest APD. This elitist approach helps ensure that all regions of the objective space are well represented in the next generation.</p> </li> </ul>"},{"location":"user_guide/algorithms/revea.html#reference-vector-association-and-apd","title":"Reference Vector Association and APD","text":""},{"location":"user_guide/algorithms/revea.html#association-mechanism","title":"Association Mechanism","text":"<p>Let \\({\\mathbf{v}_1^t, \\mathbf{v}_2^t, \\dots, \\mathbf{v}_N^t}\\) be the reference vector set at generation \\(t\\). For each solution \\(\\mathbf{f}(\\mathbf{x})\\), the cosine similarity with each reference vector is computed. The solution is then assigned to the reference vector for which the angular difference (i.e. the angle \\(\\theta\\) between them) is minimized.</p>"},{"location":"user_guide/algorithms/revea.html#angle-penalized-distance-apd","title":"Angle Penalized Distance (APD)","text":"<p>For a solution \\(\\mathbf{f}_i\\) associated with reference vector \\(\\mathbf{v}_j^t\\), the Angle Penalized Distance is given by:</p> \\[ \\text{APD}_{ij} = \\Bigl( 1 + M \\Bigl(\\frac{t}{t_{\\max}}\\Bigr)^\\alpha \\cdot \\frac{\\theta_{ij}}{\\gamma_j} \\Bigr) \\cdot \\|\\mathbf{f}_i\\| \\] <p>where: - \\(M\\) is the number of objectives, - \\(t\\) is the current generation and \\(t_{\\max}\\) is the maximum number of generations, - \\(\\alpha\\) is a control parameter, - \\(\\gamma_j\\) is a scaling factor for the \\(j\\)-th reference vector (often computed as the minimum inner product between \\(\\mathbf{v}_j^t\\) and the other reference vectors), - \\(\\theta_{ij}\\) is the angle between the solution \\(\\mathbf{f}_i\\) and the reference vector \\(\\mathbf{v}_j^t\\), and - \\(\\|\\mathbf{f}_i\\|\\) is the norm of the (possibly translated) objective vector of the solution.</p> <p>Brief Interpretation of APD: The APD metric measures how well a solution aligns with its associated reference vector. A lower APD indicates that the solution is not only close in angle (small \\(\\theta_{ij}\\)) to the reference direction, reflecting good convergence, but also has a desirable magnitude. The term \\(M\\Bigl(\\frac{t}{t_{\\max}}\\Bigr)^\\alpha\\) gradually increases the penalty on angular deviation over generations, thus promoting diversity in the early stages and fine convergence later on.</p>"},{"location":"user_guide/algorithms/revea.html#reference-vector-update","title":"Reference Vector Update","text":"<p>At a predefined frequency \\(fr\\), the reference vectors are updated to better reflect the current objective landscape. Given the ideal point \\(z_{\\min}\\) and the nadir point \\(z_{\\max}\\) of the current population, the updated reference vector \\(\\mathbf{v}_i^{t+1}\\) is computed as:</p> \\[ \\mathbf{v}_i^{t+1} = \\frac{\\mathbf{v}_i^0 \\circ (z_{\\max} - z_{\\min})}{\\|\\mathbf{v}_i^0 \\circ (z_{\\max} - z_{\\min})\\|} \\] <p>where: - \\(\\mathbf{v}_i^0\\) is the initial reference vector, - \\(\\circ\\) denotes the element-wise (Hadamard) product.</p>"},{"location":"user_guide/algorithms/revea.html#selection-process","title":"Selection Process","text":"<ul> <li> <p>Niche Formation:   Each solution is assigned to a niche based on its closest reference vector (i.e., the one with the smallest angle \\(\\theta\\)).</p> </li> <li> <p>Elitist Survival:   Within each niche, the solution with the smallest APD is selected to continue to the next generation, ensuring that all regions of the objective space contribute to the evolving Pareto front.</p> </li> <li> <p>Dynamic Adaptation:   By periodically updating the reference vectors based on the current population\u2019s extreme values, REVEA maintains effective guidance even as the search space shifts over time.</p> </li> </ul>"},{"location":"user_guide/algorithms/revea.html#summary","title":"Summary","text":"<p>REVEA leverages dynamic reference vector adaptation and the innovative Angle Penalized Distance metric to balance convergence and diversity in many-objective optimization. By continuously realigning its reference vectors with the evolving objective landscape and selecting solutions that are both close in angle (small \\(\\theta\\)) and robust in performance, REVEA offers an effective strategy for tackling complex multi-objective problems.</p> RustPython <pre><code>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotly = \"*\"\n\nuse ndarray::{Array1, Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::ReveaBuilder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{\n        GaussianMutation,\n        RandomSamplingFloat,\n        SimulatedBinaryCrossover,\n        DanAndDenisReferencePoints,\n        StructuredReferencePoints,\n        ReveaReferencePointsSurvival\n    },\n    genetic::Population,\n};\n\nuse plotly::{Plot, Scatter3D, Layout, Trace};\nuse plotly::common::{Mode, Marker, Title, MarkerSymbol};\nuse plotly::color::NamedColor;\nuse plotly::layout::{LayoutScene as Scene, Axis as PlotlyAxis};\n\n\n/// Evaluate the DTLZ2 objectives for a 3-objective problem.\n///\n/// The decision vector x has num_vars components. For the Pareto front,\n/// the auxiliary function g(x) is minimized (g(x)=0) by setting the last\n/// num_vars-2 variables to 0.5.\n///\n/// The objectives are computed as:\n///   f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2)\n///   f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2)\n///   f3(x) = (1+g) * sin((pi/2)*x1)\nfn evaluate_dtlz2(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let n = genes.nrows();\n    let pi_over_2 = std::f64::consts::PI / 2.0;\n\n    // Compute the auxiliary function g(x) using variables 3 to num_vars.\n    let tail = genes.slice(s![.., 2..]).to_owned();\n    let g_vec: Array1&lt;f64&gt; = tail.mapv(|v| (v - 0.5).powi(2)).sum_axis(Axis(1));\n\n    // x1, x2\n    let x1 = genes.column(0).to_owned();\n    let x2 = genes.column(1).to_owned();\n\n    // Trig terms\n    let cos_x1 = x1.mapv(|v| (pi_over_2 * v).cos());\n    let cos_x2 = x2.mapv(|v| (pi_over_2 * v).cos());\n    let sin_x1 = x1.mapv(|v| (pi_over_2 * v).sin());\n    let sin_x2 = x2.mapv(|v| (pi_over_2 * v).sin());\n\n    let one_plus_g = g_vec.mapv(|g| 1.0 + g);\n\n    // f1, f2, f3 as Array1\n    let f1 = &amp;one_plus_g * &amp;cos_x1 * &amp;cos_x2;\n    let f2 = &amp;one_plus_g * &amp;cos_x1 * &amp;sin_x2;\n    let f3 = &amp;one_plus_g * &amp;sin_x1;\n\n    // Stack into (n, 3)\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 3));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result.column_mut(2).assign(&amp;f3);\n    result\n}\n\n/// Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives).\n///\n/// For the Pareto-optimal front, g(x) = 0, which implies that the decision variables\n/// x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2:\n///   f1 = cos((pi/2)*x1) * cos((pi/2)*x2)\n///   f2 = cos((pi/2)*x1) * sin((pi/2)*x2)\n///   f3 = sin((pi/2)*x1)\n/// These points lie on a portion of the unit hypersphere in the positive orthant.\nfn dtlz2_theoretical_front(num_points: usize) -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let pi_over_2 = std::f64::consts::PI / 2.0;\n\n    let mut f1_all = Vec::with_capacity(num_points * num_points);\n    let mut f2_all = Vec::with_capacity(num_points * num_points);\n    let mut f3_all = Vec::with_capacity(num_points * num_points);\n\n    for i in 0..num_points {\n        let x1 = if num_points &gt; 1 {\n            i as f64 / (num_points as f64 - 1.0)\n        } else {\n            0.0\n        };\n        for j in 0..num_points {\n            let x2 = if num_points &gt; 1 {\n                j as f64 / (num_points as f64 - 1.0)\n            } else {\n                0.0\n            };\n\n            let f1 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).cos();\n            let f2 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).sin();\n            let f3 = (pi_over_2 * x1).sin();\n\n            f1_all.push(f1);\n            f2_all.push(f2);\n            f3_all.push(f3);\n        }\n    }\n\n    (f1_all, f2_all, f3_all)\n}\n\n// Set up the REVEA algorithm for DTLZ2.\n// For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k.\n// Here, we choose k = 10, so num_vars = 2 + 10 = 12.\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let num_iterations = 600;\n    let rp = DanAndDenisReferencePoints::new(101, 3).generate();\n    let alpha = 2.5;\n    let frequency = 0.2;\n    let survivor = ReveaReferencePointsSurvival::new(rp, alpha, frequency, num_iterations);\n\n    let mut algorithm = ReveaBuilder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(SimulatedBinaryCrossover::new(10.0)) // distribution_index = 10\n        .mutation(GaussianMutation::new(0.1, 0.01))     // gene_mutation_rate = 0.1, sigma = 0.01\n        .survivor(survivor)\n        .fitness_fn(evaluate_dtlz2)\n        .constraints_fn(BoundConstraints)\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))\n        .num_vars(12)\n        .population_size(200)\n        .num_offsprings(200)\n        .num_iterations(num_iterations)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(1729)\n        .build()\n        .expect(\"Failed to build REVEA\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"REVEA run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Define again rp just for plotting\nlet rp_plot: Array2&lt;f64&gt; = DanAndDenisReferencePoints::new(100, 3).generate();\nlet rp_f1: Vec&lt;f64&gt; = rp_plot.column(0).to_vec();\nlet rp_f2: Vec&lt;f64&gt; = rp_plot.column(1).to_vec();\nlet rp_f3: Vec&lt;f64&gt; = rp_plot.column(2).to_vec();\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2, f3])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\nlet f3_found: Vec&lt;f64&gt; = fitness.column(2).to_vec();\n\n// Compute the theoretical Pareto front for DTLZ2 (dense grid on the positive octant of the unit sphere)\nlet (f1_theo, f2_theo, f3_theo) = dtlz2_theoretical_front(50);\n\n// Build Plotly traces for 3D scatter (theoretical vs obtained)\nlet theoretical_trace = Scatter3D::new(f1_theo.clone(), f2_theo.clone(), f3_theo.clone())\n    .mode(Mode::Markers)\n    .name(\"Theoretical Pareto Front\")\n    .marker(Marker::new().size(3).color(NamedColor::Black).opacity(0.5));\n\nlet obtained_trace = Scatter3D::new(f1_found.clone(), f2_found.clone(), f3_found.clone())\n    .mode(Mode::Markers)\n    .name(\"Obtained Front (REVEA)\")\n    .marker(Marker::new().size(5).color(NamedColor::Red));\n\nlet refpoints_trace = Scatter3D::new(rp_f1, rp_f2, rp_f3)\n    .mode(Mode::Markers)\n    .name(\"Reference Points\")\n    .marker(\n        Marker::new()\n            .size(8)\n            .color(NamedColor::Magenta)\n            .symbol(MarkerSymbol::Star)\n    );\n\n// Layout con Title builder y PlotlyAxis (alias para evitar conflicto con ndarray::Axis)\nlet layout: Layout = Layout::new()\n    .width(800)\n    .height(600)\n    .title(Title::from(\"DTLZ2 Pareto Front: Theoretical vs Obtained (REVEA)\"))\n    .scene(\n        Scene::new()\n            .x_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;1&lt;/sub&gt;\")))\n            .y_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;2&lt;/sub&gt;\")))\n            .z_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;3&lt;/sub&gt;\")))\n        // .aspect_mode(plotly::layout::scene::AspectMode::Cube) // optional\n    );\n\n// Compose the plot\nlet mut plot = Plot::new();\nplot.add_trace(theoretical_trace);\nplot.add_trace(obtained_trace);\nplot.add_trace(refpoints_trace);\nplot.set_layout(layout);\n\n// Render as rich HTML for evcxr\nlet html = plot.to_html();\nprintln!(\"EVCXR_BEGIN_CONTENT text/html\\n{}\\nEVCXR_END_CONTENT\", html);\n</code></pre> <p></p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Revea,\n    DanAndDenisReferencePoints,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_dtlz2(x: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the DTLZ2 objectives for a 3-objective problem.\n\n    The decision vector x has num_vars components. For the Pareto front,\n    the auxiliary function g(x) is minimized (g(x)=0) by setting the last\n    num_vars-2 variables to 0.5.\n\n    The objectives are computed as:\n      f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2)\n      f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2)\n      f3(x) = (1+g) * sin((pi/2)*x1)\n    \"\"\"\n    # Compute the auxiliary function g(x) using variables 3 to num_vars.\n    g = np.sum((x[:, 2:] - 0.5) ** 2, axis=1)\n    f1 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.cos((np.pi / 2) * x[:, 1])\n    f2 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.sin((np.pi / 2) * x[:, 1])\n    f3 = (1 + g) * np.sin((np.pi / 2) * x[:, 0])\n    return np.column_stack((f1, f2, f3))\n\n\ndef dtlz2_theoretical_front(num_points=50):\n    \"\"\"\n    Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives).\n\n    For the Pareto-optimal front, g(x) = 0, which implies that the decision variables\n    x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2:\n      f1 = cos((pi/2)*x1) * cos((pi/2)*x2)\n      f2 = cos((pi/2)*x1) * sin((pi/2)*x2)\n      f3 = sin((pi/2)*x1)\n    These points lie on a portion of the unit hypersphere in the positive orthant.\n    \"\"\"\n    x1 = np.linspace(0, 1, num_points)\n    x2 = np.linspace(0, 1, num_points)\n    X1, X2 = np.meshgrid(x1, x2)\n    X1_flat = X1.flatten()\n    X2_flat = X2.flatten()\n\n    f1 = np.cos((np.pi / 2) * X1_flat) * np.cos((np.pi / 2) * X2_flat)\n    f2 = np.cos((np.pi / 2) * X1_flat) * np.sin((np.pi / 2) * X2_flat)\n    f3 = np.sin((np.pi / 2) * X1_flat)\n    return f1, f2, f3\n\n\n# Create the reference points using DanAndDenisReferencePoints.\n# This object generates reference points for NSGA-III.\nref_points = DanAndDenisReferencePoints(n_reference_points=100, n_objectives=3).generate()\n\n# Set up the REVEA algorithm for DTLZ2.\n# For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k.\n# Here, we choose k = 10, so num_vars = 2 + 10 = 12.\nalgorithm = Revea(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=SimulatedBinaryCrossover(distribution_index=10),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_dtlz2,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=12,\n    population_size=100,\n    num_offsprings=100,\n    num_iterations=250,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    reference_points=ref_points,\n    verbose=False,\n    alpha=2.0,\n    seed=1729,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\nobtained_fitness = best.fitness  # Shape: (num_solutions, 3)\n\n# Compute the theoretical Pareto front for DTLZ2\nf1_theo, f2_theo, f3_theo = dtlz2_theoretical_front(num_points=50)\n\n# Plot the theoretical Pareto front, the obtained front, and the reference points in 3D.\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111, projection=\"3d\")\n\n# Plot the theoretical Pareto front as a scatter of many points.\nax.scatter(\n    f1_theo,\n    f2_theo,\n    f3_theo,\n    c=\"k\",\n    marker=\".\",\n    label=\"Theoretical Pareto Front\",\n    alpha=0.5,\n)\n\n# Plot the obtained Pareto front from the algorithm.\nax.scatter(\n    obtained_fitness[:, 0],\n    obtained_fitness[:, 1],\n    obtained_fitness[:, 2],\n    c=\"r\",\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\n\n# Plot the reference points.\nax.scatter(\n    ref_points[:, 0],\n    ref_points[:, 1],\n    ref_points[:, 2],\n    marker=\"*\",\n    s=200,\n    color=\"magenta\",\n    label=\"Reference Points\",\n)\n\nax.set_xlabel(\"$f_1$\", fontsize=14)\nax.set_ylabel(\"$f_2$\", fontsize=14)\nax.set_zlabel(\"$f_3$\", fontsize=14)\nax.set_title(\"DTLZ2 Pareto Front: Theoretical vs Obtained (REVEA)\", fontsize=16)\nax.legend()\nplt.show()\n</code></pre> <p></p>"},{"location":"user_guide/algorithms/rnsga2.html","title":"RNSGA-II","text":"<p>RNSGA-II is an advanced, elitist multiobjective evolutionary algorithm that extends NSGA-II by incorporating reference points to guide the search toward regions of interest specified by the decision-maker. This modification is introduced in the survival selection phase, where the algorithm not only considers Pareto dominance and crowding distance but also evaluates the proximity of each solution to predefined reference points.</p>"},{"location":"user_guide/algorithms/rnsga2.html#key-features","title":"Key Features","text":"<ul> <li> <p>Fast Nondominated Sorting:   RNSGA-II sorts the population based on Pareto dominance with a computational complexity of   \\(O(MN^2)\\), where \\(M\\) is the number of objectives and \\(N\\) is the population size.</p> </li> <li> <p>Elitist Selection with Reference Points:   The algorithm forms a combined pool of parent and offspring populations. From this pool, the best solutions are selected not only based on fitness and diversity but also on their proximity to the reference points. This ensures that solutions closer to the preferred regions have a higher chance of survival.</p> </li> <li> <p>Crowding Distance for Diversity Maintenance:   To maintain a diverse Pareto front, RNSGA-II computes the crowding distance for each individual. In addition, it assesses each solution\u2019s distance from the reference points.</p> </li> </ul> <p>Individuals with a larger crowding distance or those nearer to the reference points are favored, thus promoting diversity while also focusing the search in regions of interest.</p> <ul> <li>Modified Survival Selection:   The survival selection process in RNSGA-II is enhanced by:</li> <li>Reference Point Proximity: Evaluating how close each solution is to the predefined reference points.</li> <li> <p>Combined Ranking: First ranking solutions by Pareto dominance, then by crowding distance, and finally giving extra priority to those closer to the reference points.     This approach effectively balances convergence toward the Pareto-optimal front with targeted exploration of preferred regions.</p> </li> <li> <p>Constraint Handling:   When constraints_fn are present, feasible solutions are always favored. Among these, solutions with a better (i.e., lower) nondomination rank are preferred, and if ties occur, those with a higher crowding distance and closer to the reference points are selected.</p> </li> </ul>"},{"location":"user_guide/algorithms/rnsga2.html#ztd1-problem","title":"ZTD1 Problem","text":"<p>The ZTD1 problem is commonly used as a benchmark problem to evaluate multiobjective optimization algorithms that incorporate reference points. It challenges the algorithm with:</p> <ul> <li>Two Conflicting Objectives:</li> <li>\\(f_1(\\mathbf{x}) = x_1\\)</li> <li> <p>\\(f_2(\\mathbf{x}) = g(\\mathbf{x}) \\cdot h(f_1(\\mathbf{x}), g(\\mathbf{x}))\\)</p> </li> <li> <p>Auxiliary Functions:</p> </li> <li>\\(g(\\mathbf{x}) = 1 + \\frac{9}{n-1}\\sum_{i=2}^{n} x_i\\)</li> <li> <p>\\(h(f_1, g) = 1 - \\sqrt{\\frac{f_1}{g}}\\)</p> </li> <li> <p>Key Characteristics:</p> </li> <li>Continuous and Convex Pareto Front:     Unlike problems with discontinuous fronts, ZTD1 features a continuous and convex Pareto front. This facilitates convergence while still posing a challenge in maintaining solution diversity.</li> <li>Incorporation of Reference Points:     The use of reference points in RNSGA-II directs the search toward specific regions of the Pareto front, ensuring that the obtained solutions align with the decision-maker\u2019s preferences.</li> </ul> <p>Domain: Each decision variable \\(x_i\\) is typically within the interval \\([0, 1]\\), and the problem is commonly defined with \\(n = 30\\) variables.</p> RustPython <pre><code>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{s, array, Array2, Axis, Ix2};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::Rnsga2Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, RandomSamplingFloat, ExponentialCrossover, Rnsga2ReferencePointsSurvival},\n    genetic::Population,\n};\nuse plotters::prelude::*\n\n/// Evaluate the ZTD1 objectives in a fully vectorized manner.\nfn evaluate_ztd1(x: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let n = x.nrows();\n    let m = x.ncols();\n\n    // clamp to [0,1] to mirror the Python domain constraints\n    let clamped = x.mapv(|v| v.clamp(0.0, 1.0));\n\n    let f1 = clamped.column(0).to_owned();\n    let tail = clamped.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + 9.0 / ((m as f64) - 1.0) * s);\n    let ratio = &amp;f1 / &amp;g;\n    let f2 = &amp;g * (1.0 - ratio.mapv(|r| r.sqrt()));\n\n    let mut out = Array2::&lt;f64&gt;::zeros((n, 2));\n    out.column_mut(0).assign(&amp;f1);\n    out.column_mut(1).assign(&amp;f2);\n    out\n}\n\n/// Compute the theoretical Pareto front for ZTD1.\nfn ztd1_theoretical_front() -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let mut f1_theo = Vec::with_capacity(200);\n    let mut f2_theo = Vec::with_capacity(200);\n    for i in 0..200 {\n        let v = i as f64 / 199.0;\n        f1_theo.push(v);\n        f2_theo.push(1.0 - v.sqrt());\n    }\n    (f1_theo, f2_theo)\n}\n\n// Create constraints using the macro impl_constraints_fn\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\n\n\n// Set up RNSGA-II algorithm with epsilon = 0.005\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    // Define two reference points (for example, points on the Pareto front)\n    let rp: Array2&lt;f64&gt; = array![[0.5, 0.2], [0.1, 0.6]];\n    let epsilon = 0.005;\n    let survivor = Rnsga2ReferencePointsSurvival::new(rp, epsilon);\n    let mut algorithm = Rnsga2Builder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(ExponentialCrossover::new(0.75))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .survivor(survivor)\n        .fitness_fn(evaluate_ztd1)\n        .constraints_fn(BoundConstraints)\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))\n        .num_vars(30)\n        .population_size(50)\n        .num_offsprings(50)\n        .num_iterations(700)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(1729)\n        .build()\n        .expect(\"Failed to build RNSGA-II\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"RNSGA2 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Compute the theoretical Pareto front for ZTD1\nlet (f1_theo, f2_theo) = ztd1_theoretical_front();\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// Compute the theoretical Pareto front for ZTD1\nlet (f1_theo, f2_theo) = ztd1_theoretical_front();\n\n// Plot the theoretical Pareto front, obtained front, and reference points\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 600));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    let grid_color = RGBColor(220, 220, 220);\n\n    // Build axis ranges with headroom including reference points\n    let reference_points: Vec&lt;[f64; 2]&gt; = vec![[0.5, 0.2], [0.1, 0.6]];\n\n    // Compute min/max from actual data\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n\n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n\n    // Add a small margin (5%)\n    let xr = (x_max - x_min);\n    let yr = (y_max - y_min);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"ZDT1 Pareto Front: Theoretical vs Obtained (R-NSGA-II)\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")                      // plt.xlabel(\"$f_1$\")\n        .y_desc(\"f2\")                      // plt.ylabel(\"$f_2$\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;grid_color)     // plt.grid(True)\n        .draw()\n        .unwrap();\n\n    // Theoretical Pareto Front (black solid line, linewidth=2)\n    chart.draw_series(LineSeries::new(\n        f1_theo.iter().cloned().zip(f2_theo.iter().cloned()),\n        ShapeStyle {\n            color: BLACK.to_rgba(),\n            filled: false,\n            stroke_width: 2,\n        },\n    )).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| PathElement::new(vec![(x - 10, y), (x + 10, y)], &amp;BLACK));\n\n    // Obtained Front (red circles)\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 4, RGBColor(255, 0, 0).filled()));\n\n    // Reference Points\n    chart.draw_series(\n        reference_points.iter().map(|p| {\n            TriangleMarker::new((p[0], p[1]), 8, MAGENTA.filled())\n        })\n    ).unwrap()\n     .label(\"Reference Points\")\n     .legend(|(x, y)| TriangleMarker::new((x, y), 8, MAGENTA.filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;BLACK.mix(0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\n// Emit as rich output for evcxr\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</code></pre> <p></p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Rnsga2,\n    RandomSamplingFloat,\n    GaussianMutation,\n    ExponentialCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_ztd1(x: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the ZTD1 objectives in a fully vectorized manner.\n    \"\"\"\n    f1 = x[:, 0]\n    g = 1 + 9.0 / (30 - 1) * np.sum(x[:, 1:], axis=1)\n    f2 = g * (1 - np.power((f1 / g), 0.5))\n    return np.column_stack((f1, f2))\n\n\ndef ztd1_theoretical_front():\n    \"\"\"\n    Compute the theoretical Pareto front for ZTD1.\n    \"\"\"\n    f1_theo = np.linspace(0, 1, 200)\n    f2_theo = 1 - np.sqrt(f1_theo)\n    return f1_theo, f2_theo\n\n\n# Define two reference points (for example, points on the Pareto front)\nreference_points = np.array([[0.5, 0.2], [0.1, 0.6]])\n\n# Set up RNSGA-II algorithm with epsilon = 0.01\nalgorithm = Rnsga2(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=ExponentialCrossover(exponential_crossover_rate=0.75),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_ztd1,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=30,\n    population_size=50,\n    num_offsprings=50,\n    num_iterations=700,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    reference_points=reference_points,\n    verbose=False,\n    epsilon=0.005,\n    seed=1729,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\nobtained_fitness = best.fitness\n\n# Compute the theoretical Pareto front for ZTD1\nf1_theo, f2_theo = ztd1_theoretical_front()\n\n# Plot the theoretical Pareto front, obtained front, and reference points\nplt.figure(figsize=(10, 6))\nplt.plot(f1_theo, f2_theo, \"k-\", linewidth=2, label=\"Theoretical Pareto Front\")\nplt.scatter(\n    obtained_fitness[:, 0],\n    obtained_fitness[:, 1],\n    c=\"r\",\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\nplt.scatter(\n    [pt[0] for pt in reference_points],\n    [pt[1] for pt in reference_points],\n    marker=\"*\",\n    s=200,\n    color=\"magenta\",\n    label=\"Reference Points\",\n)\nplt.xlabel(\"$f_1$\", fontsize=14)\nplt.ylabel(\"$f_2$\", fontsize=14)\nplt.title(\"ZTD1 Pareto Front: Theoretical vs Obtained (RNSGA-II)\", fontsize=16)\nplt.legend()\nplt.grid(True)\nplt.show()\n</code></pre> <p></p>"},{"location":"user_guide/algorithms/spea2.html","title":"SPEA-II","text":"<p>SPEA-II is an elitist multi\u2010objective evolutionary algorithm that, unlike NSGA-II, does not use Pareto fronts. Instead, at each generation it splits the combined parents + offspring set into non-dominated and dominated individuals and maintains a separate archive of elites.</p>"},{"location":"user_guide/algorithms/spea2.html#key-features","title":"Key Features","text":"<ul> <li>Strength &amp; Raw Fitness</li> <li>Strength of individual \\(i\\):      \\(\\(S(i) = \\bigl|\\{\\,j \\in P \\cup A \\mid i \\text{ dominates } j\\}\\bigr|\\)\\)      where \\(P\\) is the current population (size \\(N\\)) and \\(A\\) the elite archive.</li> <li> <p>Raw fitness of \\(i\\):      $$R(i) = \\sum_{\\substack{j \\in P \\cup A\\j \\text{ dominates } i}} S(j)\\,. $$</p> </li> <li> <p>Density Estimation   For tie-breaking among equal \\(R(i)\\), compute   \\(\\(D(i) = \\frac{1}{\\sigma_i^k + 2},\\)\\)   where \\(\\sigma_i^k\\) is the distance to the \\(k\\)-th nearest neighbor in objective space. Typically \\(k = \\lfloor\\sqrt{N + A_{\\max}}\\rfloor\\).</p> </li> <li> <p>Elitist Archive</p> </li> <li>Fixed size \\(A_{\\max}\\) (often set equal to \\(N\\)).</li> <li> <p>Each generation:</p> <ol> <li>Form \\(Q = P \\cup A\\).</li> <li>Extract all non-dominated from \\(Q\\) \u2192 provisional \\(A'\\).</li> <li>If \\(|A'| &gt; A_{\\max}\\), truncate by iteratively removing the individual with the smallest \\(D(i)\\) until \\(|A'| = A_{\\max}\\).</li> <li>If \\(|A'| &lt; A_{\\max}\\), fill up with the best dominated individuals from \\(Q\\setminus A'\\) in ascending order of \\(F(i)=R(i)+D(i)\\).</li> </ol> </li> <li> <p>Environmental Selection for Mating</p> </li> <li>Parents are selected only from the updated archive \\(A_{t+1}\\) (size \\(A_{\\max}\\)) by binary\u2010tournament on \\(F(i)=R(i)+D(i)\\).</li> <li> <p>Generate exactly \\(N\\) offspring (so offspring count = population size).</p> </li> <li> <p>Survival of Population</p> </li> <li> <p>Population replacement is generational: after mating, the new population \\(P_{t+1}\\) consists solely of the \\(N\\) offspring (no mixing with \\(P_t\\)).</p> </li> <li> <p>Constraint Handling   For constrained problems:</p> </li> <li>Feasible solutions always outrank infeasible ones in both archive update and tournament.</li> <li>In ties raw fitness \\(R(i)\\) is heavily penalized.</li> <li>Density \\(D(i)\\) is computed only within the feasible set to preserve feasible diversity.</li> </ul>"},{"location":"user_guide/algorithms/spea2.html#implementation-in-moo-rs","title":"Implementation in moo-rs","text":"<p>In pymoors the algorithm does not maintain a separate set A \u2014 instead, P_t itself serves as the elite archive of best individuals. Each iteration proceeds as follows:</p> <ol> <li> <p>Offspring generation    An offspring set \\(O_t\\) of size O is produced by binary-tournament selection on \\(P_t\\) using the composite fitness    \\(F(i) = R(i) + D(i)\\).</p> </li> <li> <p>Combine parents and offspring    The union \\(Q = P_t \u222a O_t\\) is formed.</p> </li> <li> <p>Compute metrics    For every individual in \\(Q\\), compute:</p> </li> <li>Strength \\(S(i)\\)</li> <li>Raw fitness \\(R(i)\\)</li> <li> <p>Density \\(D(i)\\)</p> </li> <li> <p>Build new population/archive    Extract all non-dominated individuals from \\(Q\\).</p> </li> <li>If \\(\\text{|non-dominated|} &gt; N\\), remove those with smallest \\(D(i)\\) one by one until exactly \\(N\\) remain.</li> <li> <p>If \\(\\text{|non-dominated|} &lt; N\\), fill up with the best dominated individuals sorted by increasing \\(F(i)\\) until the total is \\(N\\).</p> </li> <li> <p>Advance to next generation    The selected \\(N\\) individuals become \\(P_{t+1}\\), which also functions as the archive for the next iteration.</p> </li> </ol> <p>This design lets the population evolve generation by generation while concurrently acting as the elite memory, without any additional archive structure.</p>"},{"location":"user_guide/algorithms/spea2.html#zdt6-problem","title":"ZDT6 Problem","text":"<p>ZDT6 is a challenging two-objective benchmark that tests an algorithm\u2019s ability to handle highly non-linear, multi-modal behavior and a non-uniform Pareto front.</p> <ul> <li>Two Conflicting Objectives:</li> <li>\\(f_{1}(\\mathbf{x}) = 1 - \\exp\\bigl(-4\\,x_{1}\\bigr)\\,\\bigl[\\sin\\bigl(6\\pi\\,x_{1}\\bigr)\\bigr]^{6}\\)</li> <li> <p>\\(f_{2}(\\mathbf{x}) = g(\\mathbf{x})\\,h\\bigl(f_{1}(\\mathbf{x}),\\,g(\\mathbf{x})\\bigr)\\)</p> </li> <li> <p>Auxiliary Functions:</p> </li> <li>\\(g(\\mathbf{x}) = 1 + 9\\,\\dfrac{\\sum_{i=2}^{n} x_{i}}{n - 1}\\)</li> <li> <p>\\(h\\bigl(f_{1}, g\\bigr) = 1 - \\bigl(\\tfrac{f_{1}}{g}\\bigr)^{2}\\)</p> </li> <li> <p>Key Characteristics:</p> </li> <li>Multi-modal front shape: \\(f_{1}\\) has many local optima due to the \\(\\sin^{6}(6\\pi\\,x_{1})\\) term, making convergence difficult.</li> <li>Non-uniform Pareto front: Optimal solutions concentrate in a narrow region of the objective space, challenging diversity preservation.</li> <li>Biased distribution: Pareto-optimal \\(x_{1}\\) values are skewed toward the middle of the decision range.</li> <li> <p>Non-convexity: The \\(h\\) function introduces strong curvature, requiring careful balance between convergence and spread.</p> </li> <li> <p>Domain:   Each decision variable \\(x_{i}\\in[0,1]\\), typically with \\(n=30\\).</p> </li> </ul> <p>ZDT6 is ideal for evaluating how well an algorithm balances exploration of multiple local optima in \\(f_{1}\\) with exploitation toward a concentrated, non-uniform Pareto front.</p> RustPython <pre><code>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::Spea2Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, RandomSamplingFloat, ExponentialCrossover},\n    genetic::Population\n};\n\nuse plotters::prelude::*;\n\n/// Evaluate the ZDT6 objectives in a fully vectorized manner.\nfn evaluate_zdt6(population: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let n = population.nrows();\n    let m = population.ncols();\n\n    let x1 = population.column(0).to_owned();\n    // g = 1 + (9/(n-1)) * sum(x[1:])\n    let tail = population.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);\n\n    // f1 = 1 - exp(-4*x1) * sin^6(6*pi*x1)\n    let sin6 = x1.mapv(|v| (6.0 * std::f64::consts::PI * v).sin().powi(6));\n    let f1 = x1.mapv(|v| 1.0) - x1.mapv(|v| (-4.0 * v).exp()) * sin6;\n\n    // h = 1 - (f1/g)^2\n    let ratio = &amp;f1 / &amp;g;\n    let h = ratio.mapv(|r| 1.0 - r.powi(2));\n\n    // f2 = g * h\n    let f2 = &amp;g * &amp;h;\n\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result\n}\n\n/// Compute the theoretical Pareto front for ZDT6.\nfn zdt6_theoretical_front(num_points: usize) -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let mut f1: Vec&lt;f64&gt; = Vec::with_capacity(num_points);\n    let mut f2: Vec&lt;f64&gt; = Vec::with_capacity(num_points);\n\n    for i in 0..num_points {\n        let x1 = if num_points &gt; 1 {\n            i as f64 / (num_points as f64 - 1.0)\n        } else {\n            0.0\n        };\n        let f1_i = 1.0 - (-4.0 * x1).exp() * (6.0 * std::f64::consts::PI * x1).sin().powi(6);\n        // when g = 1 \u2192 f2 = 1 - f1^2\n        let f2_i = 1.0 - f1_i.powi(2);\n        f1.push(f1_i);\n        f2.push(f2_i);\n    }\n\n    (f1, f2)\n}\n\n// Set up the SPEA2 algorithm for ZDT6\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let mut algorithm = Spea2Builder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(ExponentialCrossover::new(0.75))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))\n        .fitness_fn(evaluate_zdt6)\n        .constraints_fn(BoundConstraints)\n        .num_vars(30)\n        .population_size(200)\n        .num_offsprings(200)\n        .num_iterations(500)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .seed(42)\n        .verbose(false)\n        .build()\n        .expect(\"Failed to build SPEA2\");\n\n    // Run SPEA2 on ZDT6\n    algorithm.run().expect(\"SPEA2 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// Compute the theoretical Pareto front for ZDT6\nlet (f1_theo, f2_theo) = zdt6_theoretical_front(1000);\n\n// Plot the theoretical Pareto front and the obtained front\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    // Compute min/max from actual data\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n\n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n\n    // Add a small margin (5%)\n    let xr = (x_max - x_min).max(1e-9);\n    let yr = (y_max - y_min).max(1e-9);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"ZDT6 Pareto Front: Theoretical vs Obtained (SPEA2)\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    // Plot theoretical front as blue markers.\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));\n\n    // Plot obtained front as red circles.\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\n// Emit as rich output for evcxr\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</code></pre> <p></p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Spea2,\n    RandomSamplingFloat,\n    GaussianMutation,\n    ExponentialCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\n\ndef evaluate_zdt6(population: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the ZDT6 objectives in a fully vectorized manner.\n    \"\"\"\n    x1 = population[:, 0]\n    n = population.shape[1]\n    # g = 1 + (9/(n-1)) * sum(x[1:])\n    g = 1 + (9 / (n - 1)) * np.sum(population[:, 1:], axis=1)\n    # f1 = 1 - exp(-4*x1) * sin^6(6*pi*x1)\n    f1 = 1 - np.exp(-4 * x1) * np.sin(6 * np.pi * x1) ** 6\n    # h = 1 - (f1/g)^2\n    h = 1 - (f1 / g) ** 2\n    # f2 = g * h\n    f2 = g * h\n    return np.column_stack((f1, f2))\n\n\ndef zdt6_theoretical_front(num_points=1000):\n    \"\"\"\n    Compute the theoretical Pareto front for ZDT6.\n    \"\"\"\n    x1 = np.linspace(0, 1, num_points)\n    f1 = 1 - np.exp(-4 * x1) * np.sin(6 * np.pi * x1) ** 6\n    # when g = 1 \u2192 f2 = 1 - f1^2\n    f2 = 1 - f1**2\n    return f1, f2\n\n\n# Set up the SPEA2 algorithm for ZDT6\nalgorithm = Spea2(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=ExponentialCrossover(exponential_crossover_rate=0.75),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_zdt6,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=30,\n    population_size=200,\n    num_offsprings=200,\n    num_iterations=500,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    seed=42,\n    verbose=False,\n)\n\n# Run SPEA2 on ZDT6\nalgorithm.run()\n\n# Extract the obtained Pareto front\nbest: Population = algorithm.population.best_as_population\nobtained_fitness = best.fitness\nf1_found = obtained_fitness[:, 0]\nf2_found = obtained_fitness[:, 1]\n\n# Compute the theoretical front\nf1_theo, f2_theo = zdt6_theoretical_front()\n\n# Plot theoretical vs obtained\nplt.figure(figsize=(10, 6))\nplt.scatter(f1_theo, f2_theo, marker=\"D\", label=\"Theoretical Pareto Front\")\nplt.scatter(f1_found, f2_found, c=\"r\", marker=\"o\", s=10, label=\"Obtained Front\")\nplt.xlabel(\"$f_1$\")\nplt.ylabel(\"$f_2$\")\nplt.title(\"ZDT6 Pareto Front: Theoretical vs Obtained\")\nplt.legend()\nplt.grid(True)\nplt.show()\n</code></pre> <p></p>"},{"location":"user_guide/algorithms/custom/custom.html","title":"Custom Defined Algorithms","text":"RustPython <p>In the introduction, an example with a pre-set genetic algorithm was shown, the famous <code>NSGA-II</code>; in that particular algorithm, the selection and survival operators were fixed at RankAndScoringSelection and Nsga2RankCrowdingSurvival respectively, hence the user can only vary the <code>sampling</code>, <code>mutation</code>, <code>crossover</code>, and duplicates cleaner operators. In <code>moors</code>, there is the possibility to build your own genetic algorithms, meaning the user can generate the respective <code>selection</code> and <code>survival</code> operators.</p> <p>The way to define a custom algorithm</p> <pre><code>use crate::{\n    algorithms::{AlgorithmBuilder, AlgorithmError},\n    duplicates::NoDuplicatesCleaner,\n    genetic::{Individual, Population},\n    helpers::dimension::{D01, D12, Dimension},\n    operators::{DuelResult, SelectionOperator, SurvivalOperator},\n    // Bring your concrete sampling/crossover/mutation and fitness here:\n    operators::{CrossoverOperator, MutationOperator, SamplingOperator},\n    random::RandomGenerator,\n};\n\n/// ----------------\n/// Custom Selection\n/// ----------------\n#[derive(Clone, Debug)]\npub struct MyCustomSelection;\n\nimpl SelectionOperator for MyCustomSelection\n{\n    type FDim = ndarray::Ix2; // If your algorithm is 1D use type FDim = ndarray::Ix1;\n\n    /// Tournament between 2 individuals.\n    fn tournament_duel&lt;'a, ConstrDim&gt;(\n        &amp;self,\n        p1: &amp;Individual&lt;'a, &lt;Self::FDim as Dimension&gt;::Smaller, ConstrDim&gt;,\n        p2: &amp;Individual&lt;'a, &lt;Self::FDim as Dimension&gt;::Smaller, ConstrDim&gt;,\n        rng: &amp;mut impl RandomGenerator,\n    ) -&gt; DuelResult\n    where\n        &lt;Self::FDim as Dimension&gt;::Smaller: D01,\n        ConstrDim: D01,\n    {\n        todo!(\"return a DuelResult according to your policy\")\n    }\n}\n\n/// ---------------\n/// Custom Survival\n/// ---------------\n#[derive(Clone, Debug)]\npub struct MyCustomSurvival;\n\nimpl SurvivalOperator for MyCustomSurvival\n{\n    type FDim = ndarray::Ix2; // If your algorithm is 1D use type FDim = ndarray::Ix1;\n\n    fn operate&lt;ConstrDim&gt;(\n        &amp;mut self,\n        population: Population&lt;Self::FDim, ConstrDim&gt;,\n        num_survive: usize,\n        rng: &amp;mut impl RandomGenerator,\n    ) -&gt; Population&lt;Self::FDim, ConstrDim&gt;\n    where\n        ConstrDim: D12,\n    {\n        todo!(\"return the reduced population with exactly `num_survive` survivors\")\n    }\n}\n\n/// ------------------------------\n/// Using the custom operators in the builder\n/// ------------------------------\nfn main() -&gt; Result&lt;(), AlgorithmError&gt; {\n    let custom_ga = AlgorithmBuilder::default()\n        // Provide your concrete operators and functions below:\n        .sampler(/* your SamplingOperator */)\n        .selector(MyCustomSelection)\n        .survivor(MyCustomSurvival)\n        .crossover(/* your CrossoverOperator */)\n        .mutation(/* your MutationOperator */)\n        .duplicates_cleaner(/* your DuplicatesCleaner */)\n        .fitness_fn(/* your fitness */)\n        .constraints_fn(/* your constraints */)\n        .num_vars(/* number of decision variables */)\n        .population_size(/* \u03bc */)\n        .num_offsprings(/* \u03bb */)\n        .num_iterations(/* iterations */)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(true)\n        .build()?;\n\n    custom_ga.run()?;\n\n    Ok(())\n}\n</code></pre> <p>Info</p> <p>You have noticed that we use <code>type FDim = ndarray::Ix2</code> or <code>type FDim = ndarray::Ix1</code> in the definition of the <code>survival</code> and <code>selection</code> operators. These are associated types that must match the array type returned by your fitness function, which can be 1D for single-objective algorithms or 2D for multi-objective ones.</p> <p>This feature is not supported yet, will be implemented once User-defined selection/survival operators are implemented: See this issue for more information.</p>"},{"location":"user_guide/algorithms/custom/python-custom.html","title":"Python custom","text":"<p>This feature is not supported yet, will be implemented once User-defined selection/survival operators are implemented: See this issue for more information.</p>"},{"location":"user_guide/algorithms/custom/rust-custom.html","title":"Rust custom","text":"<p>In the introduction, an example with a pre-set genetic algorithm was shown, the famous <code>NSGA-II</code>; in that particular algorithm, the selection and survival operators were fixed at RankAndScoringSelection and Nsga2RankCrowdingSurvival respectively, hence the user can only vary the <code>sampling</code>, <code>mutation</code>, <code>crossover</code>, and duplicates cleaner operators. In <code>moors</code>, there is the possibility to build your own genetic algorithms, meaning the user can generate the respective <code>selection</code> and <code>survival</code> operators.</p> <p>The way to define a custom algorithm</p> <pre><code>use crate::{\n    algorithms::{AlgorithmBuilder, AlgorithmError},\n    duplicates::NoDuplicatesCleaner,\n    genetic::{Individual, Population},\n    helpers::dimension::{D01, D12, Dimension},\n    operators::{DuelResult, SelectionOperator, SurvivalOperator},\n    // Bring your concrete sampling/crossover/mutation and fitness here:\n    operators::{CrossoverOperator, MutationOperator, SamplingOperator},\n    random::RandomGenerator,\n};\n\n/// ----------------\n/// Custom Selection\n/// ----------------\n#[derive(Clone, Debug)]\npub struct MyCustomSelection;\n\nimpl SelectionOperator for MyCustomSelection\n{\n    type FDim = ndarray::Ix2; // If your algorithm is 1D use type FDim = ndarray::Ix1;\n\n    /// Tournament between 2 individuals.\n    fn tournament_duel&lt;'a, ConstrDim&gt;(\n        &amp;self,\n        p1: &amp;Individual&lt;'a, &lt;Self::FDim as Dimension&gt;::Smaller, ConstrDim&gt;,\n        p2: &amp;Individual&lt;'a, &lt;Self::FDim as Dimension&gt;::Smaller, ConstrDim&gt;,\n        rng: &amp;mut impl RandomGenerator,\n    ) -&gt; DuelResult\n    where\n        &lt;Self::FDim as Dimension&gt;::Smaller: D01,\n        ConstrDim: D01,\n    {\n        todo!(\"return a DuelResult according to your policy\")\n    }\n}\n\n/// ---------------\n/// Custom Survival\n/// ---------------\n#[derive(Clone, Debug)]\npub struct MyCustomSurvival;\n\nimpl SurvivalOperator for MyCustomSurvival\n{\n    type FDim = ndarray::Ix2; // If your algorithm is 1D use type FDim = ndarray::Ix1;\n\n    fn operate&lt;ConstrDim&gt;(\n        &amp;mut self,\n        population: Population&lt;Self::FDim, ConstrDim&gt;,\n        num_survive: usize,\n        rng: &amp;mut impl RandomGenerator,\n    ) -&gt; Population&lt;Self::FDim, ConstrDim&gt;\n    where\n        ConstrDim: D12,\n    {\n        todo!(\"return the reduced population with exactly `num_survive` survivors\")\n    }\n}\n\n/// ------------------------------\n/// Using the custom operators in the builder\n/// ------------------------------\nfn main() -&gt; Result&lt;(), AlgorithmError&gt; {\n    let custom_ga = AlgorithmBuilder::default()\n        // Provide your concrete operators and functions below:\n        .sampler(/* your SamplingOperator */)\n        .selector(MyCustomSelection)\n        .survivor(MyCustomSurvival)\n        .crossover(/* your CrossoverOperator */)\n        .mutation(/* your MutationOperator */)\n        .duplicates_cleaner(/* your DuplicatesCleaner */)\n        .fitness_fn(/* your fitness */)\n        .constraints_fn(/* your constraints */)\n        .num_vars(/* number of decision variables */)\n        .population_size(/* \u03bc */)\n        .num_offsprings(/* \u03bb */)\n        .num_iterations(/* iterations */)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(true)\n        .build()?;\n\n    custom_ga.run()?;\n\n    Ok(())\n}\n</code></pre> <p>Info</p> <p>You have noticed that we use <code>type FDim = ndarray::Ix2</code> or <code>type FDim = ndarray::Ix1</code> in the definition of the <code>survival</code> and <code>selection</code> operators. These are associated types that must match the array type returned by your fitness function, which can be 1D for single-objective algorithms or 2D for multi-objective ones.</p>"},{"location":"user_guide/algorithms/introduction/introduction.html","title":"Algorithms","text":"<p>Genetic algorithms are the core of the entire project; very briefly, an algorithm can be defined in the following steps</p> <p>Initialize: create a population <code>P</code> of <code>\u03bc</code> random valid solutions. - Evaluate: compute fitness for each individual. - Selection: pick parents biased to higher fitness (e.g., tournament or rank). - Mating: recombine parents to make offspring (crossover). - Mutation: randomly perturb offspring (small, bounded changes). - Evaluate offspring: compute their fitness and constraints (if given). - Survival: build next generation of size <code>\u03bc</code>   - <code>(\u03bc+\u03bb)</code> elitist: keep best from parents \u222a offspring   - <code>(\u03bc,\u03bb)</code> generational: keep best offspring only - Stop: when max generations/time reached or no improvement.</p> <p>Genetic Algorithm</p> <pre><code># Pseudo code of a genetic algorithm\nP = init(\u03bc); evaluate(P)\nrepeat:\n    parents = select(P)\n    children = mutate(crossover(parents))\n    evaluate(children)\n    P = survive(P, children, \u03bc)   # (\u03bc+\u03bb) or (\u03bc,\u03bb)\nuntil stop\n</code></pre>"},{"location":"user_guide/algorithms/introduction/introduction.html#mathematical-formulation-of-a-multi-objective-optimization-problem-with-constraints","title":"Mathematical Formulation of a Multi-Objective Optimization Problem with Constraints","text":"<p>Consider the following optimization problem</p> \\[ \\begin{aligned} \\min_{x_1, x_2} \\quad &amp; f_1(x_1,x_2) = x_1^2 + x_2^2 \\\\ \\min_{x_1, x_2} \\quad &amp; f_2(x_1,x_2) = (x_1-1)^2 + x_2^2 \\\\ \\text{subject to} \\quad &amp; x_1 + x_2 \\leq 1, \\\\ &amp; x_1 \\geq 0,\\quad x_2 \\geq 0. \\end{aligned} \\] RustPython <p>In <code>moors</code>, the algorithms are implemented as structs with a set of useful attributes. These attributes include the final population and the optimal or best set of individuals found during the optimization process.</p> <p>For example, after running an algorithm like NSGA2, you can access: - Final Population: The complete set of individuals from the last generation. - Optimum Set: Typically, the best individuals (e.g., those with rank 0) that form the current approximation of the Pareto front.</p> <pre><code>use ndarray::{Axis, Array1, Array2, stack};\nuse moors::{\n    algorithms::{MultiObjectiveAlgorithmError, Nsga2Builder},\n    duplicates::CloseDuplicatesCleaner,\n    operators::{RandomSamplingFloat, SimulatedBinaryCrossover, GaussianMutation}\n};\n\n/// Define the fitness function\nfn fitness(population_genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let x1 = population_genes.column(0);\n    let x2 = population_genes.column(1);\n\n    let f1 = &amp;x1 * &amp;x1 + &amp;x2 * &amp;x2;\n    let f2 = (&amp;x1 - 1.0).mapv(|v| v * v) + &amp;x2 * &amp;x2;\n\n    stack(Axis(1), &amp;[f1.view(), f2.view()]).unwrap()\n}\n\n///  Define the constraints function\nfn constraints_fn(population_genes: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    let x1 = population_genes.column(0);\n    let x2 = population_genes.column(1);\n    x1 + x2 - 1.0\n}\n\nfn main() -&gt; Result&lt;(), MultiObjectiveAlgorithmError&gt; {\n    let sampler   = RandomSamplingFloat::new(0.0, 1.0);\n    let crossover = SimulatedBinaryCrossover::new(5.0);\n    let mutation  = GaussianMutation::new(0.1, 0.01);\n    let cleaner   = CloseDuplicatesCleaner::new(1e-8);\n\n    // Build NSGA-II with the same hyperparameters\n    let mut algo = Nsga2Builder::default()\n        .fitness_fn(fitness)\n        .constraints_fn(constraints)\n        .sampler(sampler)\n        .crossover(crossover)\n        .mutation(mutation)\n        .duplicates_cleaner(cleaner)\n        .num_vars(2)\n        .num_objectives(2)\n        .num_constraints(1)\n        .population_size(200)\n        .num_offsprings(200)\n        .num_iterations(200)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .build()?;\n\n    // Run\n    algo.run()?;\n\n    // Access the final population if needed\n    let population_genes = algo.population()?;\n    println!(\"Done. Final population size: {}\", population_genes.len());\n\n    Ok(())\n}\n</code></pre> <p>In <code>pymoors</code>, the algorithms are implemented as classes that are exposed on the Python side with a set of useful attributes. These attributes include the final population and the optimal or best set of individuals found during the optimization process.</p> <p>For example, after running an algorithm like NSGA2, you can access: - Final Population: The complete set of individuals from the last generation. - Optimum Set: Typically, the best individuals (e.g., those with rank 0) that form the current approximation of the Pareto front.</p> <p>This design abstracts away the complexities of the underlying Rust implementation and provides an intuitive, Pythonic interface for setting up, executing, and analyzing multi-objective optimization problems.</p> <pre><code>import numpy as np\nfrom pymoors import (\n    Nsga2,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.typing import OneDArray, TwoDArray\n\n\n# Define the fitness function\ndef fitness(population_genes: TwoDArray) -&gt; TwoDArray:\n    x1 = population_genes[:, 0]\n    x2 = population_genes[:, 1]\n    # Objective 1: f1(x1,x2) = x1^2 + x2^2\n    f1 = x1**2 + x2**2\n    # Objective 2: f2(x1,x2) = (x1-1)^2 + x2**2\n    f2 = (x1 - 1) ** 2 + x2**2\n    return np.column_stack([f1, f2])\n\n\n# Define the constraints_fn function\ndef constraints_fn(population_genes: TwoDArray) -&gt; OneDArray:\n    x1 = population_genes[:, 0]\n    x2 = population_genes[:, 1]\n    # Constraint 1: x1 + x2 &lt;= 1\n    g1 = x1 + x2 - 1\n    # Convert to 2D array\n    return g1\n\n# Wrap the constraints in the special class and pass lower/upper bounds\nconstraints = Constraints(ineq = [constraints_fn], lower_bound = 0.0, upper_bound = 1.0)\n\n\n# Set up the NSGA2 algorithm with the above definitions\nalgorithm = Nsga2(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=SimulatedBinaryCrossover(distribution_index=5),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness=fitness,\n    num_objectives=2,\n    constraints_fn=constraints,\n    num_constraints=1,\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=2,\n    population_size=200,\n    num_offsprings=200,\n    num_iterations=200,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    lower_bound=0,\n    verbose=False,\n)\n\n# Run the algorithm\nalgorithm.run()\n</code></pre>"},{"location":"user_guide/algorithms/introduction/python-introduction.html","title":"Python introduction","text":"<p>In <code>pymoors</code>, the algorithms are implemented as classes that are exposed on the Python side with a set of useful attributes. These attributes include the final population and the optimal or best set of individuals found during the optimization process.</p> <p>For example, after running an algorithm like NSGA2, you can access: - Final Population: The complete set of individuals from the last generation. - Optimum Set: Typically, the best individuals (e.g., those with rank 0) that form the current approximation of the Pareto front.</p> <p>This design abstracts away the complexities of the underlying Rust implementation and provides an intuitive, Pythonic interface for setting up, executing, and analyzing multi-objective optimization problems.</p> <pre><code>import numpy as np\nfrom pymoors import (\n    Nsga2,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.typing import OneDArray, TwoDArray\n\n\n# Define the fitness function\ndef fitness(population_genes: TwoDArray) -&gt; TwoDArray:\n    x1 = population_genes[:, 0]\n    x2 = population_genes[:, 1]\n    # Objective 1: f1(x1,x2) = x1^2 + x2^2\n    f1 = x1**2 + x2**2\n    # Objective 2: f2(x1,x2) = (x1-1)^2 + x2**2\n    f2 = (x1 - 1) ** 2 + x2**2\n    return np.column_stack([f1, f2])\n\n\n# Define the constraints_fn function\ndef constraints_fn(population_genes: TwoDArray) -&gt; OneDArray:\n    x1 = population_genes[:, 0]\n    x2 = population_genes[:, 1]\n    # Constraint 1: x1 + x2 &lt;= 1\n    g1 = x1 + x2 - 1\n    # Convert to 2D array\n    return g1\n\n# Wrap the constraints in the special class and pass lower/upper bounds\nconstraints = Constraints(ineq = [constraints_fn], lower_bound = 0.0, upper_bound = 1.0)\n\n\n# Set up the NSGA2 algorithm with the above definitions\nalgorithm = Nsga2(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=SimulatedBinaryCrossover(distribution_index=5),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness=fitness,\n    num_objectives=2,\n    constraints_fn=constraints,\n    num_constraints=1,\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=2,\n    population_size=200,\n    num_offsprings=200,\n    num_iterations=200,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    lower_bound=0,\n    verbose=False,\n)\n\n# Run the algorithm\nalgorithm.run()\n</code></pre>"},{"location":"user_guide/algorithms/introduction/rust-introduction.html","title":"Rust introduction","text":"<p>In <code>moors</code>, the algorithms are implemented as structs with a set of useful attributes. These attributes include the final population and the optimal or best set of individuals found during the optimization process.</p> <p>For example, after running an algorithm like NSGA2, you can access: - Final Population: The complete set of individuals from the last generation. - Optimum Set: Typically, the best individuals (e.g., those with rank 0) that form the current approximation of the Pareto front.</p> <pre><code>use ndarray::{Axis, Array1, Array2, stack};\nuse moors::{\n    algorithms::{MultiObjectiveAlgorithmError, Nsga2Builder},\n    duplicates::CloseDuplicatesCleaner,\n    operators::{RandomSamplingFloat, SimulatedBinaryCrossover, GaussianMutation}\n};\n\n/// Define the fitness function\nfn fitness(population_genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let x1 = population_genes.column(0);\n    let x2 = population_genes.column(1);\n\n    let f1 = &amp;x1 * &amp;x1 + &amp;x2 * &amp;x2;\n    let f2 = (&amp;x1 - 1.0).mapv(|v| v * v) + &amp;x2 * &amp;x2;\n\n    stack(Axis(1), &amp;[f1.view(), f2.view()]).unwrap()\n}\n\n///  Define the constraints function\nfn constraints_fn(population_genes: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    let x1 = population_genes.column(0);\n    let x2 = population_genes.column(1);\n    x1 + x2 - 1.0\n}\n\nfn main() -&gt; Result&lt;(), MultiObjectiveAlgorithmError&gt; {\n    let sampler   = RandomSamplingFloat::new(0.0, 1.0);\n    let crossover = SimulatedBinaryCrossover::new(5.0);\n    let mutation  = GaussianMutation::new(0.1, 0.01);\n    let cleaner   = CloseDuplicatesCleaner::new(1e-8);\n\n    // Build NSGA-II with the same hyperparameters\n    let mut algo = Nsga2Builder::default()\n        .fitness_fn(fitness)\n        .constraints_fn(constraints)\n        .sampler(sampler)\n        .crossover(crossover)\n        .mutation(mutation)\n        .duplicates_cleaner(cleaner)\n        .num_vars(2)\n        .num_objectives(2)\n        .num_constraints(1)\n        .population_size(200)\n        .num_offsprings(200)\n        .num_iterations(200)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .build()?;\n\n    // Run\n    algo.run()?;\n\n    // Access the final population if needed\n    let population_genes = algo.population()?;\n    println!(\"Done. Final population size: {}\", population_genes.len());\n\n    Ok(())\n}\n</code></pre>"},{"location":"user_guide/algorithms/python/agemoea.html","title":"Agemoea","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    AgeMoea,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_ztd1(x: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the ZTD1 objectives in a fully vectorized manner.\n    \"\"\"\n    f1 = x[:, 0]\n    g = 1 + 9.0 / (30 - 1) * np.sum(x[:, 1:], axis=1)\n    f2 = g * (1 - np.power((f1 / g), 0.5))\n    return np.column_stack((f1, f2))\n\n\ndef ztd1_theoretical_front():\n    \"\"\"\n    Compute the theoretical Pareto front for ZTD1.\n    \"\"\"\n    f1_theo = np.linspace(0, 1, 200)\n    f2_theo = 1 - np.sqrt(f1_theo)\n    return f1_theo, f2_theo\n\n\n# Set up AgeMoea algorithm\nalgorithm = AgeMoea(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=SimulatedBinaryCrossover(distribution_index=15),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_ztd1,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=30,\n    population_size=100,\n    num_offsprings=100,\n    num_iterations=200,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    verbose=False,\n    seed=42,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\nobtained_fitness = best.fitness\n\n# Compute the theoretical Pareto front for ZTD1\nf1_theo, f2_theo = ztd1_theoretical_front()\n\n# Plot the theoretical Pareto front, obtained front, and reference points\nplt.figure(figsize=(10, 6))\nplt.plot(f1_theo, f2_theo, \"k-\", linewidth=2, label=\"Theoretical Pareto Front\")\nplt.scatter(\n    obtained_fitness[:, 0],\n    obtained_fitness[:, 1],\n    c=\"r\",\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\nplt.xlabel(\"$f_1$\", fontsize=14)\nplt.ylabel(\"$f_2$\", fontsize=14)\nplt.title(\"ZTD1 Pareto Front: Theoretical vs Obtained (RNSGA-II)\", fontsize=16)\nplt.legend()\nplt.grid(True)\nplt.show()\n</code></pre>"},{"location":"user_guide/algorithms/python/ibea.html","title":"Ibea","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Ibea,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints,\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\n\n# ==============================\n# EXPO2 \u2014 Objective Evaluation\n# ==============================\ndef evaluate_expo2(x: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    EXPO2 (minimization, 2 objectives).\n\n    g(x) = 1 + (9/(n-1)) * sum_{i=2..n} x_i\n    f1(x) = x1\n    f2(x) = g(x) * exp( -5 * x1 / g(x) )\n\n    Typical domain: x_i in [0, 1], i=1..n (e.g., n = 30).\n    \"\"\"\n    n = x.shape[1]\n    if n &lt; 2:\n        raise ValueError(\"EXPO2 requires at least 2 decision variables.\")\n\n    # g(x)\n    g = 1.0 + (9.0 / (n - 1)) * np.sum(x[:, 1:], axis=1)\n\n    f1 = x[:, 0]\n    f2 = g * np.exp(-5.0 * x[:, 0] / g)\n\n    return np.column_stack((f1, f2))\n\n\n# ==========================================\n# Theoretical Front (g=1 =&gt; x2..xn = 0; f2=exp(-5 f1))\n# ==========================================\ndef expo2_theoretical_front(num_points: int = 200):\n    \"\"\"\n    Returns (f1, f2) arrays of the EXPO2 Pareto front:\n        f1 in [0, 1], f2 = exp(-5 f1)\n    \"\"\"\n    f1 = np.linspace(0.0, 1.0, num_points)\n    f2 = np.exp(-5.0 * f1)\n    return f1, f2\n\n\n# =============================\n# Algorithm Setup (IBEA-H)\n# =============================\n# Problem dimensionality\nNUM_VARS = 30\n\n# Hypervolume reference point (minimization \u21d2 worse-than-worst)\n# We put [6.0, 6.0] far from the normalized range [0,1]\nHV_REFERENCE_POINT = np.array([4.0, 4.0], dtype=float)\n\n# kappa controls the selection pressure in IBEA\nKAPPA = 0.05\n\n\nalgorithm = Ibea(\n    sampler=RandomSamplingFloat(min=0.0, max=1.0),\n    crossover=SimulatedBinaryCrossover(distribution_index=15),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.1),\n    fitness_fn=evaluate_expo2,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-6),\n    num_vars=NUM_VARS,\n    population_size=600,\n    num_offsprings=600,\n    num_iterations=600,\n    mutation_rate=0.2,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    reference_points=HV_REFERENCE_POINT,\n    kappa=KAPPA,\n    verbose=False,\n    seed=1,\n)\n\n# ===============\n# Run IBEA\n# ===============\nalgorithm.run()\n\n# Best front (Population)\nbest: Population = algorithm.population.best_as_population\nobtained = best.fitness  # shape: (num_solutions, 2)\n\nf1_theo, f2_theo = expo2_theoretical_front(num_points=400)\n# Plot the theoretical Pareto front, obtained front, and reference points\nplt.figure(figsize=(10, 6))\nplt.plot(f1_theo, f2_theo, \"k-\", linewidth=2, label=\"Theoretical Pareto Front\")\nplt.scatter(\n    obtained[:, 0],\n    obtained[:, 1],\n    c=\"r\",\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\n\nplt.xlabel(\"$f_1$\", fontsize=14)\nplt.ylabel(\"$f_2$\", fontsize=14)\nplt.title(\"EXPO2 Pareto Front: Theoretical vs Obtained (IBEA HyperVolume)\", fontsize=16)\nplt.legend()\nplt.grid(True)\nplt.show()\n</code></pre>"},{"location":"user_guide/algorithms/python/nsga2.html","title":"Nsga2","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Nsga2,\n    RandomSamplingFloat,\n    GaussianMutation,\n    ExponentialCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_zdt3(population: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the ZDT3 objectives in a fully vectorized manner.\n    \"\"\"\n    # First objective: f1 is simply the first column.\n    f1 = population[:, 0]\n    n = population.shape[1]\n    # Compute g for each candidate: g = 1 + (9/(n-1)) * sum(x[1:])\n    g = 1 + (9 / (n - 1)) * np.sum(population[:, 1:], axis=1)\n    # Compute h for each candidate: h = 1 - sqrt(f1/g) - (f1/g)*sin(10*pi*f1)\n    h = 1 - np.sqrt(f1 / g) - (f1 / g) * np.sin(10 * np.pi * f1)\n    # Compute the second objective: f2 = g * h\n    f2 = g * h\n    return np.column_stack((f1, f2))\n\n\ndef zdt3_theoretical_front():\n    \"\"\"\n    Compute the theoretical Pareto front for ZDT3.\n\n    Returns:\n        f1_theo (np.ndarray): f1 values on the theoretical front.\n        f2_theo (np.ndarray): Corresponding f2 values.\n\n    Instead of using a dense linspace, we sample only a few points per interval to\n    clearly illustrate the discontinuous nature of the front.\n    \"\"\"\n    # Define the intervals for f1 where the Pareto front exists\n    intervals = [\n        (0.0, 0.0830015349),\n        (0.1822287280, 0.2577623634),\n        (0.4093136748, 0.4538828821),\n        (0.6183967944, 0.6525117038),\n        (0.8233317983, 0.85518),\n    ]\n\n    f1_theo = np.array([])\n    f2_theo = np.array([])\n\n    # Use a small number of points per interval (e.g., 20) to highlight the discontinuities.\n    for start, end in intervals:\n        f1_vals = np.linspace(start, end, 20)\n        f2_vals = 1 - np.sqrt(f1_vals) - f1_vals * np.sin(10 * np.pi * f1_vals)\n        f1_theo = np.concatenate((f1_theo, f1_vals))\n        f2_theo = np.concatenate((f2_theo, f2_vals))\n\n    return f1_theo, f2_theo\n\n\n# Set up the NSGA2 algorithm with the above definitions\nalgorithm = Nsga2(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=ExponentialCrossover(exponential_crossover_rate=0.75),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_zdt3,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-5),\n    num_vars=30,\n    population_size=200,\n    num_offsprings=200,\n    num_iterations=300,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    verbose=False,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\n\n# Extract the obtained fitness values (each row is [f1, f2])\nobtained_fitness = best.fitness\nf1_found = obtained_fitness[:, 0]\nf2_found = obtained_fitness[:, 1]\n\n# Compute the theoretical Pareto front for ZDT3\nf1_theo, f2_theo = zdt3_theoretical_front()\n\n# Plot the theoretical Pareto front and the obtained front\nplt.figure(figsize=(10, 6))\n# Plot theoretical front as markers (e.g., diamonds) to show discontinuities.\nplt.scatter(\n    f1_theo, f2_theo, marker=\"D\", color=\"blue\", label=\"Theoretical Pareto Front\"\n)\n# Plot obtained front as red circles.\nplt.scatter(f1_found, f2_found, c=\"r\", marker=\"o\", s=10, label=\"Obtained Front\")\nplt.xlabel(\"$f_1$\", fontsize=14)\nplt.ylabel(\"$f_2$\", fontsize=14)\nplt.title(\"ZDT3 Pareto Front: Theoretical vs Obtained\", fontsize=16)\nplt.legend()\nplt.grid(True)\n</code></pre>"},{"location":"user_guide/algorithms/python/nsga3.html","title":"Nsga3","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Nsga3,\n    DanAndDenisReferencePoints,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_dtlz2(x: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the DTLZ2 objectives for a 3-objective problem.\n\n    The decision vector x has num_vars components. For the Pareto front,\n    the auxiliary function g(x) is minimized (g(x)=0) by setting the last\n    num_vars-2 variables to 0.5.\n\n    The objectives are computed as:\n      f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2)\n      f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2)\n      f3(x) = (1+g) * sin((pi/2)*x1)\n    \"\"\"\n    # Compute the auxiliary function g(x) using variables 3 to num_vars.\n    g = np.sum((x[:, 2:] - 0.5) ** 2, axis=1)\n    f1 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.cos((np.pi / 2) * x[:, 1])\n    f2 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.sin((np.pi / 2) * x[:, 1])\n    f3 = (1 + g) * np.sin((np.pi / 2) * x[:, 0])\n    return np.column_stack((f1, f2, f3))\n\n\ndef dtlz2_theoretical_front(num_points=50):\n    \"\"\"\n    Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives).\n\n    For the Pareto-optimal front, g(x) = 0, which implies that the decision variables\n    x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2:\n      f1 = cos((pi/2)*x1) * cos((pi/2)*x2)\n      f2 = cos((pi/2)*x1) * sin((pi/2)*x2)\n      f3 = sin((pi/2)*x1)\n    These points lie on a portion of the unit hypersphere in the positive orthant.\n    \"\"\"\n    x1 = np.linspace(0, 1, num_points)\n    x2 = np.linspace(0, 1, num_points)\n    X1, X2 = np.meshgrid(x1, x2)\n    X1_flat = X1.flatten()\n    X2_flat = X2.flatten()\n\n    f1 = np.cos((np.pi / 2) * X1_flat) * np.cos((np.pi / 2) * X2_flat)\n    f2 = np.cos((np.pi / 2) * X1_flat) * np.sin((np.pi / 2) * X2_flat)\n    f3 = np.sin((np.pi / 2) * X1_flat)\n    return f1, f2, f3\n\n\n# Create the reference points using DanAndDenisReferencePoints.\n# This object generates reference points for NSGA-III.\nref_points = DanAndDenisReferencePoints(n_reference_points=100, n_objectives=3)\n\n# Set up the NSGA-III algorithm for DTLZ2.\n# For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k.\n# Here, we choose k = 10, so num_vars = 2 + 10 = 12.\nalgorithm = Nsga3(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=SimulatedBinaryCrossover(distribution_index=10),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_dtlz2,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=12,\n    population_size=500,\n    num_offsprings=500,\n    num_iterations=700,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    reference_points=ref_points,\n    verbose=False,\n    seed=1729,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\nobtained_fitness = best.fitness  # Shape: (num_solutions, 3)\n\n# Compute the theoretical Pareto front for DTLZ2\nf1_theo, f2_theo, f3_theo = dtlz2_theoretical_front(num_points=50)\n\n# Plot the theoretical Pareto front, the obtained front, and the reference points in 3D.\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111, projection=\"3d\")\n\n# Plot the theoretical Pareto front as a scatter of many points.\nax.scatter(\n    f1_theo,\n    f2_theo,\n    f3_theo,\n    c=\"k\",\n    marker=\".\",\n    label=\"Theoretical Pareto Front\",\n    alpha=0.5,\n)\n\n# Plot the obtained Pareto front from the algorithm.\nax.scatter(\n    obtained_fitness[:, 0],\n    obtained_fitness[:, 1],\n    obtained_fitness[:, 2],\n    c=\"r\",\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\n\n# Plot the reference points.\n# Extract the reference points array from the DanAndDenisReferencePoints object.\nref_points_array = ref_points.generate()\nax.scatter(\n    ref_points_array[:, 0],\n    ref_points_array[:, 1],\n    ref_points_array[:, 2],\n    marker=\"*\",\n    s=200,\n    color=\"magenta\",\n    label=\"Reference Points\",\n)\n\nax.set_xlabel(\"$f_1$\", fontsize=14)\nax.set_ylabel(\"$f_2$\", fontsize=14)\nax.set_zlabel(\"$f_3$\", fontsize=14)\nax.set_title(\"DTLZ2 Pareto Front: Theoretical vs Obtained (NSGA-III)\", fontsize=16)\nax.legend()\nplt.show()\n</code></pre>"},{"location":"user_guide/algorithms/python/revea.html","title":"Revea","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Revea,\n    DanAndDenisReferencePoints,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_dtlz2(x: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the DTLZ2 objectives for a 3-objective problem.\n\n    The decision vector x has num_vars components. For the Pareto front,\n    the auxiliary function g(x) is minimized (g(x)=0) by setting the last\n    num_vars-2 variables to 0.5.\n\n    The objectives are computed as:\n      f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2)\n      f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2)\n      f3(x) = (1+g) * sin((pi/2)*x1)\n    \"\"\"\n    # Compute the auxiliary function g(x) using variables 3 to num_vars.\n    g = np.sum((x[:, 2:] - 0.5) ** 2, axis=1)\n    f1 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.cos((np.pi / 2) * x[:, 1])\n    f2 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.sin((np.pi / 2) * x[:, 1])\n    f3 = (1 + g) * np.sin((np.pi / 2) * x[:, 0])\n    return np.column_stack((f1, f2, f3))\n\n\ndef dtlz2_theoretical_front(num_points=50):\n    \"\"\"\n    Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives).\n\n    For the Pareto-optimal front, g(x) = 0, which implies that the decision variables\n    x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2:\n      f1 = cos((pi/2)*x1) * cos((pi/2)*x2)\n      f2 = cos((pi/2)*x1) * sin((pi/2)*x2)\n      f3 = sin((pi/2)*x1)\n    These points lie on a portion of the unit hypersphere in the positive orthant.\n    \"\"\"\n    x1 = np.linspace(0, 1, num_points)\n    x2 = np.linspace(0, 1, num_points)\n    X1, X2 = np.meshgrid(x1, x2)\n    X1_flat = X1.flatten()\n    X2_flat = X2.flatten()\n\n    f1 = np.cos((np.pi / 2) * X1_flat) * np.cos((np.pi / 2) * X2_flat)\n    f2 = np.cos((np.pi / 2) * X1_flat) * np.sin((np.pi / 2) * X2_flat)\n    f3 = np.sin((np.pi / 2) * X1_flat)\n    return f1, f2, f3\n\n\n# Create the reference points using DanAndDenisReferencePoints.\n# This object generates reference points for NSGA-III.\nref_points = DanAndDenisReferencePoints(n_reference_points=100, n_objectives=3).generate()\n\n# Set up the REVEA algorithm for DTLZ2.\n# For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k.\n# Here, we choose k = 10, so num_vars = 2 + 10 = 12.\nalgorithm = Revea(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=SimulatedBinaryCrossover(distribution_index=10),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_dtlz2,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=12,\n    population_size=100,\n    num_offsprings=100,\n    num_iterations=250,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    reference_points=ref_points,\n    verbose=False,\n    alpha=2.0,\n    seed=1729,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\nobtained_fitness = best.fitness  # Shape: (num_solutions, 3)\n\n# Compute the theoretical Pareto front for DTLZ2\nf1_theo, f2_theo, f3_theo = dtlz2_theoretical_front(num_points=50)\n\n# Plot the theoretical Pareto front, the obtained front, and the reference points in 3D.\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111, projection=\"3d\")\n\n# Plot the theoretical Pareto front as a scatter of many points.\nax.scatter(\n    f1_theo,\n    f2_theo,\n    f3_theo,\n    c=\"k\",\n    marker=\".\",\n    label=\"Theoretical Pareto Front\",\n    alpha=0.5,\n)\n\n# Plot the obtained Pareto front from the algorithm.\nax.scatter(\n    obtained_fitness[:, 0],\n    obtained_fitness[:, 1],\n    obtained_fitness[:, 2],\n    c=\"r\",\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\n\n# Plot the reference points.\nax.scatter(\n    ref_points[:, 0],\n    ref_points[:, 1],\n    ref_points[:, 2],\n    marker=\"*\",\n    s=200,\n    color=\"magenta\",\n    label=\"Reference Points\",\n)\n\nax.set_xlabel(\"$f_1$\", fontsize=14)\nax.set_ylabel(\"$f_2$\", fontsize=14)\nax.set_zlabel(\"$f_3$\", fontsize=14)\nax.set_title(\"DTLZ2 Pareto Front: Theoretical vs Obtained (REVEA)\", fontsize=16)\nax.legend()\nplt.show()\n</code></pre>"},{"location":"user_guide/algorithms/python/rnsga2.html","title":"Rnsga2","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Rnsga2,\n    RandomSamplingFloat,\n    GaussianMutation,\n    ExponentialCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_ztd1(x: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the ZTD1 objectives in a fully vectorized manner.\n    \"\"\"\n    f1 = x[:, 0]\n    g = 1 + 9.0 / (30 - 1) * np.sum(x[:, 1:], axis=1)\n    f2 = g * (1 - np.power((f1 / g), 0.5))\n    return np.column_stack((f1, f2))\n\n\ndef ztd1_theoretical_front():\n    \"\"\"\n    Compute the theoretical Pareto front for ZTD1.\n    \"\"\"\n    f1_theo = np.linspace(0, 1, 200)\n    f2_theo = 1 - np.sqrt(f1_theo)\n    return f1_theo, f2_theo\n\n\n# Define two reference points (for example, points on the Pareto front)\nreference_points = np.array([[0.5, 0.2], [0.1, 0.6]])\n\n# Set up RNSGA-II algorithm with epsilon = 0.01\nalgorithm = Rnsga2(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=ExponentialCrossover(exponential_crossover_rate=0.75),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_ztd1,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=30,\n    population_size=50,\n    num_offsprings=50,\n    num_iterations=700,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    reference_points=reference_points,\n    verbose=False,\n    epsilon=0.005,\n    seed=1729,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\nobtained_fitness = best.fitness\n\n# Compute the theoretical Pareto front for ZTD1\nf1_theo, f2_theo = ztd1_theoretical_front()\n\n# Plot the theoretical Pareto front, obtained front, and reference points\nplt.figure(figsize=(10, 6))\nplt.plot(f1_theo, f2_theo, \"k-\", linewidth=2, label=\"Theoretical Pareto Front\")\nplt.scatter(\n    obtained_fitness[:, 0],\n    obtained_fitness[:, 1],\n    c=\"r\",\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\nplt.scatter(\n    [pt[0] for pt in reference_points],\n    [pt[1] for pt in reference_points],\n    marker=\"*\",\n    s=200,\n    color=\"magenta\",\n    label=\"Reference Points\",\n)\nplt.xlabel(\"$f_1$\", fontsize=14)\nplt.ylabel(\"$f_2$\", fontsize=14)\nplt.title(\"ZTD1 Pareto Front: Theoretical vs Obtained (RNSGA-II)\", fontsize=16)\nplt.legend()\nplt.grid(True)\nplt.show()\n</code></pre>"},{"location":"user_guide/algorithms/python/spea2.html","title":"Spea2","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Spea2,\n    RandomSamplingFloat,\n    GaussianMutation,\n    ExponentialCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\n\ndef evaluate_zdt6(population: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the ZDT6 objectives in a fully vectorized manner.\n    \"\"\"\n    x1 = population[:, 0]\n    n = population.shape[1]\n    # g = 1 + (9/(n-1)) * sum(x[1:])\n    g = 1 + (9 / (n - 1)) * np.sum(population[:, 1:], axis=1)\n    # f1 = 1 - exp(-4*x1) * sin^6(6*pi*x1)\n    f1 = 1 - np.exp(-4 * x1) * np.sin(6 * np.pi * x1) ** 6\n    # h = 1 - (f1/g)^2\n    h = 1 - (f1 / g) ** 2\n    # f2 = g * h\n    f2 = g * h\n    return np.column_stack((f1, f2))\n\n\ndef zdt6_theoretical_front(num_points=1000):\n    \"\"\"\n    Compute the theoretical Pareto front for ZDT6.\n    \"\"\"\n    x1 = np.linspace(0, 1, num_points)\n    f1 = 1 - np.exp(-4 * x1) * np.sin(6 * np.pi * x1) ** 6\n    # when g = 1 \u2192 f2 = 1 - f1^2\n    f2 = 1 - f1**2\n    return f1, f2\n\n\n# Set up the SPEA2 algorithm for ZDT6\nalgorithm = Spea2(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=ExponentialCrossover(exponential_crossover_rate=0.75),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_zdt6,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=30,\n    population_size=200,\n    num_offsprings=200,\n    num_iterations=500,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    seed=42,\n    verbose=False,\n)\n\n# Run SPEA2 on ZDT6\nalgorithm.run()\n\n# Extract the obtained Pareto front\nbest: Population = algorithm.population.best_as_population\nobtained_fitness = best.fitness\nf1_found = obtained_fitness[:, 0]\nf2_found = obtained_fitness[:, 1]\n\n# Compute the theoretical front\nf1_theo, f2_theo = zdt6_theoretical_front()\n\n# Plot theoretical vs obtained\nplt.figure(figsize=(10, 6))\nplt.scatter(f1_theo, f2_theo, marker=\"D\", label=\"Theoretical Pareto Front\")\nplt.scatter(f1_found, f2_found, c=\"r\", marker=\"o\", s=10, label=\"Obtained Front\")\nplt.xlabel(\"$f_1$\")\nplt.ylabel(\"$f_2$\")\nplt.title(\"ZDT6 Pareto Front: Theoretical vs Obtained\")\nplt.legend()\nplt.grid(True)\nplt.show()\n</code></pre>"},{"location":"user_guide/algorithms/python/notebooks/agemoea.html","title":"Agemoea","text":"In\u00a0[10]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    AgeMoea,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_ztd1(x: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the ZTD1 objectives in a fully vectorized manner.\n    \"\"\"\n    f1 = x[:, 0]\n    g = 1 + 9.0 / (30 - 1) * np.sum(x[:, 1:], axis=1)\n    f2 = g * (1 - np.power((f1 / g), 0.5))\n    return np.column_stack((f1, f2))\n\n\ndef ztd1_theoretical_front():\n    \"\"\"\n    Compute the theoretical Pareto front for ZTD1.\n    \"\"\"\n    f1_theo = np.linspace(0, 1, 200)\n    f2_theo = 1 - np.sqrt(f1_theo)\n    return f1_theo, f2_theo\n\n\n# Set up AgeMoea algorithm\nalgorithm = AgeMoea(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=SimulatedBinaryCrossover(distribution_index=15),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_ztd1,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=30,\n    population_size=100,\n    num_offsprings=100,\n    num_iterations=200,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    verbose=False,\n    seed=42,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\nobtained_fitness = best.fitness\n\n# Compute the theoretical Pareto front for ZTD1\nf1_theo, f2_theo = ztd1_theoretical_front()\n\n# Plot the theoretical Pareto front, obtained front, and reference points\nplt.figure(figsize=(10, 6))\nplt.plot(f1_theo, f2_theo, \"k-\", linewidth=2, label=\"Theoretical Pareto Front\")\nplt.scatter(\n    obtained_fitness[:, 0],\n    obtained_fitness[:, 1],\n    c=\"r\",\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\nplt.xlabel(\"$f_1$\", fontsize=14)\nplt.ylabel(\"$f_2$\", fontsize=14)\nplt.title(\"ZTD1 Pareto Front: Theoretical vs Obtained (RNSGA-II)\", fontsize=16)\nplt.legend()\nplt.grid(True)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  from pymoors import (     AgeMoea,     RandomSamplingFloat,     GaussianMutation,     SimulatedBinaryCrossover,     CloseDuplicatesCleaner,     Constraints ) from pymoors.schemas import Population from pymoors.typing import TwoDArray  np.seterr(invalid=\"ignore\")   def evaluate_ztd1(x: TwoDArray) -&gt; TwoDArray:     \"\"\"     Evaluate the ZTD1 objectives in a fully vectorized manner.     \"\"\"     f1 = x[:, 0]     g = 1 + 9.0 / (30 - 1) * np.sum(x[:, 1:], axis=1)     f2 = g * (1 - np.power((f1 / g), 0.5))     return np.column_stack((f1, f2))   def ztd1_theoretical_front():     \"\"\"     Compute the theoretical Pareto front for ZTD1.     \"\"\"     f1_theo = np.linspace(0, 1, 200)     f2_theo = 1 - np.sqrt(f1_theo)     return f1_theo, f2_theo   # Set up AgeMoea algorithm algorithm = AgeMoea(     sampler=RandomSamplingFloat(min=0, max=1),     crossover=SimulatedBinaryCrossover(distribution_index=15),     mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),     fitness_fn=evaluate_ztd1,     constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),     duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),     num_vars=30,     population_size=100,     num_offsprings=100,     num_iterations=200,     mutation_rate=0.1,     crossover_rate=0.9,     keep_infeasible=False,     verbose=False,     seed=42, )  # Run the algorithm algorithm.run()  # Get the best Pareto front obtained (as a Population instance) best: Population = algorithm.population.best_as_population obtained_fitness = best.fitness  # Compute the theoretical Pareto front for ZTD1 f1_theo, f2_theo = ztd1_theoretical_front()  # Plot the theoretical Pareto front, obtained front, and reference points plt.figure(figsize=(10, 6)) plt.plot(f1_theo, f2_theo, \"k-\", linewidth=2, label=\"Theoretical Pareto Front\") plt.scatter(     obtained_fitness[:, 0],     obtained_fitness[:, 1],     c=\"r\",     marker=\"o\",     label=\"Obtained Front\", ) plt.xlabel(\"$f_1$\", fontsize=14) plt.ylabel(\"$f_2$\", fontsize=14) plt.title(\"ZTD1 Pareto Front: Theoretical vs Obtained (RNSGA-II)\", fontsize=16) plt.legend() plt.grid(True) plt.show()"},{"location":"user_guide/algorithms/python/notebooks/ibea.html","title":"Ibea","text":"In\u00a0[12]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Ibea,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints,\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\n\n# ==============================\n# EXPO2 \u2014 Objective Evaluation\n# ==============================\ndef evaluate_expo2(x: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    EXPO2 (minimization, 2 objectives).\n\n    g(x) = 1 + (9/(n-1)) * sum_{i=2..n} x_i\n    f1(x) = x1\n    f2(x) = g(x) * exp( -5 * x1 / g(x) )\n\n    Typical domain: x_i in [0, 1], i=1..n (e.g., n = 30).\n    \"\"\"\n    n = x.shape[1]\n    if n &lt; 2:\n        raise ValueError(\"EXPO2 requires at least 2 decision variables.\")\n\n    # g(x)\n    g = 1.0 + (9.0 / (n - 1)) * np.sum(x[:, 1:], axis=1)\n\n    f1 = x[:, 0]\n    f2 = g * np.exp(-5.0 * x[:, 0] / g)\n\n    return np.column_stack((f1, f2))\n\n\n# ==========================================\n# Theoretical Front (g=1 =&gt; x2..xn = 0; f2=exp(-5 f1))\n# ==========================================\ndef expo2_theoretical_front(num_points: int = 200):\n    \"\"\"\n    Returns (f1, f2) arrays of the EXPO2 Pareto front:\n        f1 in [0, 1], f2 = exp(-5 f1)\n    \"\"\"\n    f1 = np.linspace(0.0, 1.0, num_points)\n    f2 = np.exp(-5.0 * f1)\n    return f1, f2\n\n\n# =============================\n# Algorithm Setup (IBEA-H)\n# =============================\n# Problem dimensionality\nNUM_VARS = 30\n\n# Hypervolume reference point (minimization \u21d2 worse-than-worst)\n# We put [6.0, 6.0] far from the normalized range [0,1]\nHV_REFERENCE_POINT = np.array([4.0, 4.0], dtype=float)\n\n# kappa controls the selection pressure in IBEA\nKAPPA = 0.05\n\n\nalgorithm = Ibea(\n    sampler=RandomSamplingFloat(min=0.0, max=1.0),\n    crossover=SimulatedBinaryCrossover(distribution_index=15),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.1),\n    fitness_fn=evaluate_expo2,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-6),\n    num_vars=NUM_VARS,\n    population_size=600,\n    num_offsprings=600,\n    num_iterations=600,\n    mutation_rate=0.2,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    reference_points=HV_REFERENCE_POINT,\n    kappa=KAPPA,\n    verbose=False,\n    seed=1,\n)\n\n# ===============\n# Run IBEA\n# ===============\nalgorithm.run()\n\n# Best front (Population)\nbest: Population = algorithm.population.best_as_population\nobtained = best.fitness  # shape: (num_solutions, 2)\n\nf1_theo, f2_theo = expo2_theoretical_front(num_points=400)\n# Plot the theoretical Pareto front, obtained front, and reference points\nplt.figure(figsize=(10, 6))\nplt.plot(f1_theo, f2_theo, \"k-\", linewidth=2, label=\"Theoretical Pareto Front\")\nplt.scatter(\n    obtained[:, 0],\n    obtained[:, 1],\n    c=\"r\",\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\n\nplt.xlabel(\"$f_1$\", fontsize=14)\nplt.ylabel(\"$f_2$\", fontsize=14)\nplt.title(\"EXPO2 Pareto Front: Theoretical vs Obtained (IBEA HyperVolume)\", fontsize=16)\nplt.legend()\nplt.grid(True)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  from pymoors import (     Ibea,     RandomSamplingFloat,     GaussianMutation,     SimulatedBinaryCrossover,     CloseDuplicatesCleaner,     Constraints, ) from pymoors.schemas import Population from pymoors.typing import TwoDArray   # ============================== # EXPO2 \u2014 Objective Evaluation # ============================== def evaluate_expo2(x: TwoDArray) -&gt; TwoDArray:     \"\"\"     EXPO2 (minimization, 2 objectives).      g(x) = 1 + (9/(n-1)) * sum_{i=2..n} x_i     f1(x) = x1     f2(x) = g(x) * exp( -5 * x1 / g(x) )      Typical domain: x_i in [0, 1], i=1..n (e.g., n = 30).     \"\"\"     n = x.shape[1]     if n &lt; 2:         raise ValueError(\"EXPO2 requires at least 2 decision variables.\")      # g(x)     g = 1.0 + (9.0 / (n - 1)) * np.sum(x[:, 1:], axis=1)      f1 = x[:, 0]     f2 = g * np.exp(-5.0 * x[:, 0] / g)      return np.column_stack((f1, f2))   # ========================================== # Theoretical Front (g=1 =&gt; x2..xn = 0; f2=exp(-5 f1)) # ========================================== def expo2_theoretical_front(num_points: int = 200):     \"\"\"     Returns (f1, f2) arrays of the EXPO2 Pareto front:         f1 in [0, 1], f2 = exp(-5 f1)     \"\"\"     f1 = np.linspace(0.0, 1.0, num_points)     f2 = np.exp(-5.0 * f1)     return f1, f2   # ============================= # Algorithm Setup (IBEA-H) # ============================= # Problem dimensionality NUM_VARS = 30  # Hypervolume reference point (minimization \u21d2 worse-than-worst) # We put [6.0, 6.0] far from the normalized range [0,1] HV_REFERENCE_POINT = np.array([4.0, 4.0], dtype=float)  # kappa controls the selection pressure in IBEA KAPPA = 0.05   algorithm = Ibea(     sampler=RandomSamplingFloat(min=0.0, max=1.0),     crossover=SimulatedBinaryCrossover(distribution_index=15),     mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.1),     fitness_fn=evaluate_expo2,     constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),     duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-6),     num_vars=NUM_VARS,     population_size=600,     num_offsprings=600,     num_iterations=600,     mutation_rate=0.2,     crossover_rate=0.9,     keep_infeasible=False,     reference_points=HV_REFERENCE_POINT,     kappa=KAPPA,     verbose=False,     seed=1, )  # =============== # Run IBEA # =============== algorithm.run()  # Best front (Population) best: Population = algorithm.population.best_as_population obtained = best.fitness  # shape: (num_solutions, 2)  f1_theo, f2_theo = expo2_theoretical_front(num_points=400) # Plot the theoretical Pareto front, obtained front, and reference points plt.figure(figsize=(10, 6)) plt.plot(f1_theo, f2_theo, \"k-\", linewidth=2, label=\"Theoretical Pareto Front\") plt.scatter(     obtained[:, 0],     obtained[:, 1],     c=\"r\",     marker=\"o\",     label=\"Obtained Front\", )  plt.xlabel(\"$f_1$\", fontsize=14) plt.ylabel(\"$f_2$\", fontsize=14) plt.title(\"EXPO2 Pareto Front: Theoretical vs Obtained (IBEA HyperVolume)\", fontsize=16) plt.legend() plt.grid(True) plt.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"user_guide/algorithms/python/notebooks/nsga2.html","title":"Nsga2","text":"In\u00a0[2]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Nsga2,\n    RandomSamplingFloat,\n    GaussianMutation,\n    ExponentialCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_zdt3(population: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the ZDT3 objectives in a fully vectorized manner.\n    \"\"\"\n    # First objective: f1 is simply the first column.\n    f1 = population[:, 0]\n    n = population.shape[1]\n    # Compute g for each candidate: g = 1 + (9/(n-1)) * sum(x[1:])\n    g = 1 + (9 / (n - 1)) * np.sum(population[:, 1:], axis=1)\n    # Compute h for each candidate: h = 1 - sqrt(f1/g) - (f1/g)*sin(10*pi*f1)\n    h = 1 - np.sqrt(f1 / g) - (f1 / g) * np.sin(10 * np.pi * f1)\n    # Compute the second objective: f2 = g * h\n    f2 = g * h\n    return np.column_stack((f1, f2))\n\n\ndef zdt3_theoretical_front():\n    \"\"\"\n    Compute the theoretical Pareto front for ZDT3.\n\n    Returns:\n        f1_theo (np.ndarray): f1 values on the theoretical front.\n        f2_theo (np.ndarray): Corresponding f2 values.\n\n    Instead of using a dense linspace, we sample only a few points per interval to\n    clearly illustrate the discontinuous nature of the front.\n    \"\"\"\n    # Define the intervals for f1 where the Pareto front exists\n    intervals = [\n        (0.0, 0.0830015349),\n        (0.1822287280, 0.2577623634),\n        (0.4093136748, 0.4538828821),\n        (0.6183967944, 0.6525117038),\n        (0.8233317983, 0.85518),\n    ]\n\n    f1_theo = np.array([])\n    f2_theo = np.array([])\n\n    # Use a small number of points per interval (e.g., 20) to highlight the discontinuities.\n    for start, end in intervals:\n        f1_vals = np.linspace(start, end, 20)\n        f2_vals = 1 - np.sqrt(f1_vals) - f1_vals * np.sin(10 * np.pi * f1_vals)\n        f1_theo = np.concatenate((f1_theo, f1_vals))\n        f2_theo = np.concatenate((f2_theo, f2_vals))\n\n    return f1_theo, f2_theo\n\n\n# Set up the NSGA2 algorithm with the above definitions\nalgorithm = Nsga2(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=ExponentialCrossover(exponential_crossover_rate=0.75),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_zdt3,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-5),\n    num_vars=30,\n    population_size=200,\n    num_offsprings=200,\n    num_iterations=300,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    verbose=False,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\n\n# Extract the obtained fitness values (each row is [f1, f2])\nobtained_fitness = best.fitness\nf1_found = obtained_fitness[:, 0]\nf2_found = obtained_fitness[:, 1]\n\n# Compute the theoretical Pareto front for ZDT3\nf1_theo, f2_theo = zdt3_theoretical_front()\n\n# Plot the theoretical Pareto front and the obtained front\nplt.figure(figsize=(10, 6))\n# Plot theoretical front as markers (e.g., diamonds) to show discontinuities.\nplt.scatter(\n    f1_theo, f2_theo, marker=\"D\", color=\"blue\", label=\"Theoretical Pareto Front\"\n)\n# Plot obtained front as red circles.\nplt.scatter(f1_found, f2_found, c=\"r\", marker=\"o\", s=10, label=\"Obtained Front\")\nplt.xlabel(\"$f_1$\", fontsize=14)\nplt.ylabel(\"$f_2$\", fontsize=14)\nplt.title(\"ZDT3 Pareto Front: Theoretical vs Obtained\", fontsize=16)\nplt.legend()\nplt.grid(True)\n</pre> import numpy as np import matplotlib.pyplot as plt  from pymoors import (     Nsga2,     RandomSamplingFloat,     GaussianMutation,     ExponentialCrossover,     CloseDuplicatesCleaner,     Constraints ) from pymoors.schemas import Population from pymoors.typing import TwoDArray  np.seterr(invalid=\"ignore\")   def evaluate_zdt3(population: TwoDArray) -&gt; TwoDArray:     \"\"\"     Evaluate the ZDT3 objectives in a fully vectorized manner.     \"\"\"     # First objective: f1 is simply the first column.     f1 = population[:, 0]     n = population.shape[1]     # Compute g for each candidate: g = 1 + (9/(n-1)) * sum(x[1:])     g = 1 + (9 / (n - 1)) * np.sum(population[:, 1:], axis=1)     # Compute h for each candidate: h = 1 - sqrt(f1/g) - (f1/g)*sin(10*pi*f1)     h = 1 - np.sqrt(f1 / g) - (f1 / g) * np.sin(10 * np.pi * f1)     # Compute the second objective: f2 = g * h     f2 = g * h     return np.column_stack((f1, f2))   def zdt3_theoretical_front():     \"\"\"     Compute the theoretical Pareto front for ZDT3.      Returns:         f1_theo (np.ndarray): f1 values on the theoretical front.         f2_theo (np.ndarray): Corresponding f2 values.      Instead of using a dense linspace, we sample only a few points per interval to     clearly illustrate the discontinuous nature of the front.     \"\"\"     # Define the intervals for f1 where the Pareto front exists     intervals = [         (0.0, 0.0830015349),         (0.1822287280, 0.2577623634),         (0.4093136748, 0.4538828821),         (0.6183967944, 0.6525117038),         (0.8233317983, 0.85518),     ]      f1_theo = np.array([])     f2_theo = np.array([])      # Use a small number of points per interval (e.g., 20) to highlight the discontinuities.     for start, end in intervals:         f1_vals = np.linspace(start, end, 20)         f2_vals = 1 - np.sqrt(f1_vals) - f1_vals * np.sin(10 * np.pi * f1_vals)         f1_theo = np.concatenate((f1_theo, f1_vals))         f2_theo = np.concatenate((f2_theo, f2_vals))      return f1_theo, f2_theo   # Set up the NSGA2 algorithm with the above definitions algorithm = Nsga2(     sampler=RandomSamplingFloat(min=0, max=1),     crossover=ExponentialCrossover(exponential_crossover_rate=0.75),     mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),     fitness_fn=evaluate_zdt3,     constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),     duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-5),     num_vars=30,     population_size=200,     num_offsprings=200,     num_iterations=300,     mutation_rate=0.1,     crossover_rate=0.9,     keep_infeasible=False,     verbose=False, )  # Run the algorithm algorithm.run()  # Get the best Pareto front obtained (as a Population instance) best: Population = algorithm.population.best_as_population  # Extract the obtained fitness values (each row is [f1, f2]) obtained_fitness = best.fitness f1_found = obtained_fitness[:, 0] f2_found = obtained_fitness[:, 1]  # Compute the theoretical Pareto front for ZDT3 f1_theo, f2_theo = zdt3_theoretical_front()  # Plot the theoretical Pareto front and the obtained front plt.figure(figsize=(10, 6)) # Plot theoretical front as markers (e.g., diamonds) to show discontinuities. plt.scatter(     f1_theo, f2_theo, marker=\"D\", color=\"blue\", label=\"Theoretical Pareto Front\" ) # Plot obtained front as red circles. plt.scatter(f1_found, f2_found, c=\"r\", marker=\"o\", s=10, label=\"Obtained Front\") plt.xlabel(\"$f_1$\", fontsize=14) plt.ylabel(\"$f_2$\", fontsize=14) plt.title(\"ZDT3 Pareto Front: Theoretical vs Obtained\", fontsize=16) plt.legend() plt.grid(True)"},{"location":"user_guide/algorithms/python/notebooks/nsga3.html","title":"Nsga3","text":"In\u00a0[2]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Nsga3,\n    DanAndDenisReferencePoints,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_dtlz2(x: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the DTLZ2 objectives for a 3-objective problem.\n\n    The decision vector x has num_vars components. For the Pareto front,\n    the auxiliary function g(x) is minimized (g(x)=0) by setting the last\n    num_vars-2 variables to 0.5.\n\n    The objectives are computed as:\n      f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2)\n      f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2)\n      f3(x) = (1+g) * sin((pi/2)*x1)\n    \"\"\"\n    # Compute the auxiliary function g(x) using variables 3 to num_vars.\n    g = np.sum((x[:, 2:] - 0.5) ** 2, axis=1)\n    f1 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.cos((np.pi / 2) * x[:, 1])\n    f2 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.sin((np.pi / 2) * x[:, 1])\n    f3 = (1 + g) * np.sin((np.pi / 2) * x[:, 0])\n    return np.column_stack((f1, f2, f3))\n\n\ndef dtlz2_theoretical_front(num_points=50):\n    \"\"\"\n    Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives).\n\n    For the Pareto-optimal front, g(x) = 0, which implies that the decision variables\n    x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2:\n      f1 = cos((pi/2)*x1) * cos((pi/2)*x2)\n      f2 = cos((pi/2)*x1) * sin((pi/2)*x2)\n      f3 = sin((pi/2)*x1)\n    These points lie on a portion of the unit hypersphere in the positive orthant.\n    \"\"\"\n    x1 = np.linspace(0, 1, num_points)\n    x2 = np.linspace(0, 1, num_points)\n    X1, X2 = np.meshgrid(x1, x2)\n    X1_flat = X1.flatten()\n    X2_flat = X2.flatten()\n\n    f1 = np.cos((np.pi / 2) * X1_flat) * np.cos((np.pi / 2) * X2_flat)\n    f2 = np.cos((np.pi / 2) * X1_flat) * np.sin((np.pi / 2) * X2_flat)\n    f3 = np.sin((np.pi / 2) * X1_flat)\n    return f1, f2, f3\n\n\n# Create the reference points using DanAndDenisReferencePoints.\n# This object generates reference points for NSGA-III.\nref_points = DanAndDenisReferencePoints(n_reference_points=100, n_objectives=3)\n\n# Set up the NSGA-III algorithm for DTLZ2.\n# For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k.\n# Here, we choose k = 10, so num_vars = 2 + 10 = 12.\nalgorithm = Nsga3(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=SimulatedBinaryCrossover(distribution_index=10),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_dtlz2,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=12,\n    population_size=500,\n    num_offsprings=500,\n    num_iterations=700,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    reference_points=ref_points,\n    verbose=False,\n    seed=1729,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\nobtained_fitness = best.fitness  # Shape: (num_solutions, 3)\n\n# Compute the theoretical Pareto front for DTLZ2\nf1_theo, f2_theo, f3_theo = dtlz2_theoretical_front(num_points=50)\n\n# Plot the theoretical Pareto front, the obtained front, and the reference points in 3D.\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111, projection=\"3d\")\n\n# Plot the theoretical Pareto front as a scatter of many points.\nax.scatter(\n    f1_theo,\n    f2_theo,\n    f3_theo,\n    c=\"k\",\n    marker=\".\",\n    label=\"Theoretical Pareto Front\",\n    alpha=0.5,\n)\n\n# Plot the obtained Pareto front from the algorithm.\nax.scatter(\n    obtained_fitness[:, 0],\n    obtained_fitness[:, 1],\n    obtained_fitness[:, 2],\n    c=\"r\",\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\n\n# Plot the reference points.\n# Extract the reference points array from the DanAndDenisReferencePoints object.\nref_points_array = ref_points.generate()\nax.scatter(\n    ref_points_array[:, 0],\n    ref_points_array[:, 1],\n    ref_points_array[:, 2],\n    marker=\"*\",\n    s=200,\n    color=\"magenta\",\n    label=\"Reference Points\",\n)\n\nax.set_xlabel(\"$f_1$\", fontsize=14)\nax.set_ylabel(\"$f_2$\", fontsize=14)\nax.set_zlabel(\"$f_3$\", fontsize=14)\nax.set_title(\"DTLZ2 Pareto Front: Theoretical vs Obtained (NSGA-III)\", fontsize=16)\nax.legend()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  from pymoors import (     Nsga3,     DanAndDenisReferencePoints,     RandomSamplingFloat,     GaussianMutation,     SimulatedBinaryCrossover,     CloseDuplicatesCleaner,     Constraints ) from pymoors.schemas import Population from pymoors.typing import TwoDArray  np.seterr(invalid=\"ignore\")   def evaluate_dtlz2(x: TwoDArray) -&gt; TwoDArray:     \"\"\"     Evaluate the DTLZ2 objectives for a 3-objective problem.      The decision vector x has num_vars components. For the Pareto front,     the auxiliary function g(x) is minimized (g(x)=0) by setting the last     num_vars-2 variables to 0.5.      The objectives are computed as:       f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2)       f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2)       f3(x) = (1+g) * sin((pi/2)*x1)     \"\"\"     # Compute the auxiliary function g(x) using variables 3 to num_vars.     g = np.sum((x[:, 2:] - 0.5) ** 2, axis=1)     f1 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.cos((np.pi / 2) * x[:, 1])     f2 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.sin((np.pi / 2) * x[:, 1])     f3 = (1 + g) * np.sin((np.pi / 2) * x[:, 0])     return np.column_stack((f1, f2, f3))   def dtlz2_theoretical_front(num_points=50):     \"\"\"     Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives).      For the Pareto-optimal front, g(x) = 0, which implies that the decision variables     x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2:       f1 = cos((pi/2)*x1) * cos((pi/2)*x2)       f2 = cos((pi/2)*x1) * sin((pi/2)*x2)       f3 = sin((pi/2)*x1)     These points lie on a portion of the unit hypersphere in the positive orthant.     \"\"\"     x1 = np.linspace(0, 1, num_points)     x2 = np.linspace(0, 1, num_points)     X1, X2 = np.meshgrid(x1, x2)     X1_flat = X1.flatten()     X2_flat = X2.flatten()      f1 = np.cos((np.pi / 2) * X1_flat) * np.cos((np.pi / 2) * X2_flat)     f2 = np.cos((np.pi / 2) * X1_flat) * np.sin((np.pi / 2) * X2_flat)     f3 = np.sin((np.pi / 2) * X1_flat)     return f1, f2, f3   # Create the reference points using DanAndDenisReferencePoints. # This object generates reference points for NSGA-III. ref_points = DanAndDenisReferencePoints(n_reference_points=100, n_objectives=3)  # Set up the NSGA-III algorithm for DTLZ2. # For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k. # Here, we choose k = 10, so num_vars = 2 + 10 = 12. algorithm = Nsga3(     sampler=RandomSamplingFloat(min=0, max=1),     crossover=SimulatedBinaryCrossover(distribution_index=10),     mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),     fitness_fn=evaluate_dtlz2,     constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),     duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),     num_vars=12,     population_size=500,     num_offsprings=500,     num_iterations=700,     mutation_rate=0.1,     crossover_rate=0.9,     keep_infeasible=False,     reference_points=ref_points,     verbose=False,     seed=1729, )  # Run the algorithm algorithm.run()  # Get the best Pareto front obtained (as a Population instance) best: Population = algorithm.population.best_as_population obtained_fitness = best.fitness  # Shape: (num_solutions, 3)  # Compute the theoretical Pareto front for DTLZ2 f1_theo, f2_theo, f3_theo = dtlz2_theoretical_front(num_points=50)  # Plot the theoretical Pareto front, the obtained front, and the reference points in 3D. fig = plt.figure(figsize=(10, 8)) ax = fig.add_subplot(111, projection=\"3d\")  # Plot the theoretical Pareto front as a scatter of many points. ax.scatter(     f1_theo,     f2_theo,     f3_theo,     c=\"k\",     marker=\".\",     label=\"Theoretical Pareto Front\",     alpha=0.5, )  # Plot the obtained Pareto front from the algorithm. ax.scatter(     obtained_fitness[:, 0],     obtained_fitness[:, 1],     obtained_fitness[:, 2],     c=\"r\",     marker=\"o\",     label=\"Obtained Front\", )  # Plot the reference points. # Extract the reference points array from the DanAndDenisReferencePoints object. ref_points_array = ref_points.generate() ax.scatter(     ref_points_array[:, 0],     ref_points_array[:, 1],     ref_points_array[:, 2],     marker=\"*\",     s=200,     color=\"magenta\",     label=\"Reference Points\", )  ax.set_xlabel(\"$f_1$\", fontsize=14) ax.set_ylabel(\"$f_2$\", fontsize=14) ax.set_zlabel(\"$f_3$\", fontsize=14) ax.set_title(\"DTLZ2 Pareto Front: Theoretical vs Obtained (NSGA-III)\", fontsize=16) ax.legend() plt.show()"},{"location":"user_guide/algorithms/python/notebooks/revea.html","title":"Revea","text":"In\u00a0[2]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Revea,\n    DanAndDenisReferencePoints,\n    RandomSamplingFloat,\n    GaussianMutation,\n    SimulatedBinaryCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_dtlz2(x: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the DTLZ2 objectives for a 3-objective problem.\n\n    The decision vector x has num_vars components. For the Pareto front,\n    the auxiliary function g(x) is minimized (g(x)=0) by setting the last\n    num_vars-2 variables to 0.5.\n\n    The objectives are computed as:\n      f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2)\n      f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2)\n      f3(x) = (1+g) * sin((pi/2)*x1)\n    \"\"\"\n    # Compute the auxiliary function g(x) using variables 3 to num_vars.\n    g = np.sum((x[:, 2:] - 0.5) ** 2, axis=1)\n    f1 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.cos((np.pi / 2) * x[:, 1])\n    f2 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.sin((np.pi / 2) * x[:, 1])\n    f3 = (1 + g) * np.sin((np.pi / 2) * x[:, 0])\n    return np.column_stack((f1, f2, f3))\n\n\ndef dtlz2_theoretical_front(num_points=50):\n    \"\"\"\n    Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives).\n\n    For the Pareto-optimal front, g(x) = 0, which implies that the decision variables\n    x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2:\n      f1 = cos((pi/2)*x1) * cos((pi/2)*x2)\n      f2 = cos((pi/2)*x1) * sin((pi/2)*x2)\n      f3 = sin((pi/2)*x1)\n    These points lie on a portion of the unit hypersphere in the positive orthant.\n    \"\"\"\n    x1 = np.linspace(0, 1, num_points)\n    x2 = np.linspace(0, 1, num_points)\n    X1, X2 = np.meshgrid(x1, x2)\n    X1_flat = X1.flatten()\n    X2_flat = X2.flatten()\n\n    f1 = np.cos((np.pi / 2) * X1_flat) * np.cos((np.pi / 2) * X2_flat)\n    f2 = np.cos((np.pi / 2) * X1_flat) * np.sin((np.pi / 2) * X2_flat)\n    f3 = np.sin((np.pi / 2) * X1_flat)\n    return f1, f2, f3\n\n\n# Create the reference points using DanAndDenisReferencePoints.\n# This object generates reference points for NSGA-III.\nref_points = DanAndDenisReferencePoints(n_reference_points=100, n_objectives=3).generate()\n\n# Set up the REVEA algorithm for DTLZ2.\n# For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k.\n# Here, we choose k = 10, so num_vars = 2 + 10 = 12.\nalgorithm = Revea(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=SimulatedBinaryCrossover(distribution_index=10),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_dtlz2,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=12,\n    population_size=200,\n    num_offsprings=200,\n    num_iterations=600,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    reference_points=ref_points,\n    verbose=False,\n    alpha=2.5,\n    frequency=0.2,\n    seed=1729,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\nobtained_fitness = best.fitness  # Shape: (num_solutions, 3)\n\n# Compute the theoretical Pareto front for DTLZ2\nf1_theo, f2_theo, f3_theo = dtlz2_theoretical_front(num_points=50)\n\n# Plot the theoretical Pareto front, the obtained front, and the reference points in 3D.\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111, projection=\"3d\")\n\n# Plot the theoretical Pareto front as a scatter of many points.\nax.scatter(\n    f1_theo,\n    f2_theo,\n    f3_theo,\n    c=\"k\",\n    marker=\".\",\n    label=\"Theoretical Pareto Front\",\n    alpha=0.5,\n)\n\n# Plot the obtained Pareto front from the algorithm.\nax.scatter(\n    obtained_fitness[:, 0],\n    obtained_fitness[:, 1],\n    obtained_fitness[:, 2],\n    c=\"r\",\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\n\n# Plot the reference points.\nax.scatter(\n    ref_points[:, 0],\n    ref_points[:, 1],\n    ref_points[:, 2],\n    marker=\"*\",\n    s=200,\n    color=\"magenta\",\n    label=\"Reference Points\",\n)\n\nax.set_xlabel(\"$f_1$\", fontsize=14)\nax.set_ylabel(\"$f_2$\", fontsize=14)\nax.set_zlabel(\"$f_3$\", fontsize=14)\nax.set_title(\"DTLZ2 Pareto Front: Theoretical vs Obtained (REVEA)\", fontsize=16)\nax.legend()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  from pymoors import (     Revea,     DanAndDenisReferencePoints,     RandomSamplingFloat,     GaussianMutation,     SimulatedBinaryCrossover,     CloseDuplicatesCleaner,     Constraints ) from pymoors.schemas import Population from pymoors.typing import TwoDArray  np.seterr(invalid=\"ignore\")   def evaluate_dtlz2(x: TwoDArray) -&gt; TwoDArray:     \"\"\"     Evaluate the DTLZ2 objectives for a 3-objective problem.      The decision vector x has num_vars components. For the Pareto front,     the auxiliary function g(x) is minimized (g(x)=0) by setting the last     num_vars-2 variables to 0.5.      The objectives are computed as:       f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2)       f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2)       f3(x) = (1+g) * sin((pi/2)*x1)     \"\"\"     # Compute the auxiliary function g(x) using variables 3 to num_vars.     g = np.sum((x[:, 2:] - 0.5) ** 2, axis=1)     f1 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.cos((np.pi / 2) * x[:, 1])     f2 = (1 + g) * np.cos((np.pi / 2) * x[:, 0]) * np.sin((np.pi / 2) * x[:, 1])     f3 = (1 + g) * np.sin((np.pi / 2) * x[:, 0])     return np.column_stack((f1, f2, f3))   def dtlz2_theoretical_front(num_points=50):     \"\"\"     Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives).      For the Pareto-optimal front, g(x) = 0, which implies that the decision variables     x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2:       f1 = cos((pi/2)*x1) * cos((pi/2)*x2)       f2 = cos((pi/2)*x1) * sin((pi/2)*x2)       f3 = sin((pi/2)*x1)     These points lie on a portion of the unit hypersphere in the positive orthant.     \"\"\"     x1 = np.linspace(0, 1, num_points)     x2 = np.linspace(0, 1, num_points)     X1, X2 = np.meshgrid(x1, x2)     X1_flat = X1.flatten()     X2_flat = X2.flatten()      f1 = np.cos((np.pi / 2) * X1_flat) * np.cos((np.pi / 2) * X2_flat)     f2 = np.cos((np.pi / 2) * X1_flat) * np.sin((np.pi / 2) * X2_flat)     f3 = np.sin((np.pi / 2) * X1_flat)     return f1, f2, f3   # Create the reference points using DanAndDenisReferencePoints. # This object generates reference points for NSGA-III. ref_points = DanAndDenisReferencePoints(n_reference_points=100, n_objectives=3).generate()  # Set up the REVEA algorithm for DTLZ2. # For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k. # Here, we choose k = 10, so num_vars = 2 + 10 = 12. algorithm = Revea(     sampler=RandomSamplingFloat(min=0, max=1),     crossover=SimulatedBinaryCrossover(distribution_index=10),     mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),     fitness_fn=evaluate_dtlz2,     constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),     duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),     num_vars=12,     population_size=200,     num_offsprings=200,     num_iterations=600,     mutation_rate=0.1,     crossover_rate=0.9,     keep_infeasible=False,     reference_points=ref_points,     verbose=False,     alpha=2.5,     frequency=0.2,     seed=1729, )  # Run the algorithm algorithm.run()  # Get the best Pareto front obtained (as a Population instance) best: Population = algorithm.population.best_as_population obtained_fitness = best.fitness  # Shape: (num_solutions, 3)  # Compute the theoretical Pareto front for DTLZ2 f1_theo, f2_theo, f3_theo = dtlz2_theoretical_front(num_points=50)  # Plot the theoretical Pareto front, the obtained front, and the reference points in 3D. fig = plt.figure(figsize=(10, 8)) ax = fig.add_subplot(111, projection=\"3d\")  # Plot the theoretical Pareto front as a scatter of many points. ax.scatter(     f1_theo,     f2_theo,     f3_theo,     c=\"k\",     marker=\".\",     label=\"Theoretical Pareto Front\",     alpha=0.5, )  # Plot the obtained Pareto front from the algorithm. ax.scatter(     obtained_fitness[:, 0],     obtained_fitness[:, 1],     obtained_fitness[:, 2],     c=\"r\",     marker=\"o\",     label=\"Obtained Front\", )  # Plot the reference points. ax.scatter(     ref_points[:, 0],     ref_points[:, 1],     ref_points[:, 2],     marker=\"*\",     s=200,     color=\"magenta\",     label=\"Reference Points\", )  ax.set_xlabel(\"$f_1$\", fontsize=14) ax.set_ylabel(\"$f_2$\", fontsize=14) ax.set_zlabel(\"$f_3$\", fontsize=14) ax.set_title(\"DTLZ2 Pareto Front: Theoretical vs Obtained (REVEA)\", fontsize=16) ax.legend() plt.show()"},{"location":"user_guide/algorithms/python/notebooks/rnsga2.html","title":"Rnsga2","text":"In\u00a0[29]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Rnsga2,\n    RandomSamplingFloat,\n    GaussianMutation,\n    ExponentialCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\nnp.seterr(invalid=\"ignore\")\n\n\ndef evaluate_ztd1(x: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the ZTD1 objectives in a fully vectorized manner.\n    \"\"\"\n    f1 = x[:, 0]\n    g = 1 + 9.0 / (30 - 1) * np.sum(x[:, 1:], axis=1)\n    f2 = g * (1 - np.power((f1 / g), 0.5))\n    return np.column_stack((f1, f2))\n\n\ndef ztd1_theoretical_front():\n    \"\"\"\n    Compute the theoretical Pareto front for ZTD1.\n    \"\"\"\n    f1_theo = np.linspace(0, 1, 200)\n    f2_theo = 1 - np.sqrt(f1_theo)\n    return f1_theo, f2_theo\n\n\n# Define two reference points (for example, points on the Pareto front)\nreference_points = np.array([[0.5, 0.2], [0.1, 0.6]])\n\n# Set up RNSGA-II algorithm with epsilon = 0.01\nalgorithm = Rnsga2(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=ExponentialCrossover(exponential_crossover_rate=0.75),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_ztd1,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=30,\n    population_size=50,\n    num_offsprings=50,\n    num_iterations=700,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    reference_points=reference_points,\n    verbose=False,\n    epsilon=0.005,\n    seed=1729,\n)\n\n# Run the algorithm\nalgorithm.run()\n\n# Get the best Pareto front obtained (as a Population instance)\nbest: Population = algorithm.population.best_as_population\nobtained_fitness = best.fitness\n\n# Compute the theoretical Pareto front for ZTD1\nf1_theo, f2_theo = ztd1_theoretical_front()\n\n# Plot the theoretical Pareto front, obtained front, and reference points\nplt.figure(figsize=(10, 6))\nplt.plot(f1_theo, f2_theo, \"k-\", linewidth=2, label=\"Theoretical Pareto Front\")\nplt.scatter(\n    obtained_fitness[:, 0],\n    obtained_fitness[:, 1],\n    c=\"r\",\n    marker=\"o\",\n    label=\"Obtained Front\",\n)\nplt.scatter(\n    [pt[0] for pt in reference_points],\n    [pt[1] for pt in reference_points],\n    marker=\"*\",\n    s=200,\n    color=\"magenta\",\n    label=\"Reference Points\",\n)\nplt.xlabel(\"$f_1$\", fontsize=14)\nplt.ylabel(\"$f_2$\", fontsize=14)\nplt.title(\"ZTD1 Pareto Front: Theoretical vs Obtained (RNSGA-II)\", fontsize=16)\nplt.legend()\nplt.grid(True)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  from pymoors import (     Rnsga2,     RandomSamplingFloat,     GaussianMutation,     ExponentialCrossover,     CloseDuplicatesCleaner,     Constraints ) from pymoors.schemas import Population from pymoors.typing import TwoDArray  np.seterr(invalid=\"ignore\")   def evaluate_ztd1(x: TwoDArray) -&gt; TwoDArray:     \"\"\"     Evaluate the ZTD1 objectives in a fully vectorized manner.     \"\"\"     f1 = x[:, 0]     g = 1 + 9.0 / (30 - 1) * np.sum(x[:, 1:], axis=1)     f2 = g * (1 - np.power((f1 / g), 0.5))     return np.column_stack((f1, f2))   def ztd1_theoretical_front():     \"\"\"     Compute the theoretical Pareto front for ZTD1.     \"\"\"     f1_theo = np.linspace(0, 1, 200)     f2_theo = 1 - np.sqrt(f1_theo)     return f1_theo, f2_theo   # Define two reference points (for example, points on the Pareto front) reference_points = np.array([[0.5, 0.2], [0.1, 0.6]])  # Set up RNSGA-II algorithm with epsilon = 0.01 algorithm = Rnsga2(     sampler=RandomSamplingFloat(min=0, max=1),     crossover=ExponentialCrossover(exponential_crossover_rate=0.75),     mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),     fitness_fn=evaluate_ztd1,     constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),     duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),     num_vars=30,     population_size=50,     num_offsprings=50,     num_iterations=700,     mutation_rate=0.1,     crossover_rate=0.9,     keep_infeasible=False,     reference_points=reference_points,     verbose=False,     epsilon=0.005,     seed=1729, )  # Run the algorithm algorithm.run()  # Get the best Pareto front obtained (as a Population instance) best: Population = algorithm.population.best_as_population obtained_fitness = best.fitness  # Compute the theoretical Pareto front for ZTD1 f1_theo, f2_theo = ztd1_theoretical_front()  # Plot the theoretical Pareto front, obtained front, and reference points plt.figure(figsize=(10, 6)) plt.plot(f1_theo, f2_theo, \"k-\", linewidth=2, label=\"Theoretical Pareto Front\") plt.scatter(     obtained_fitness[:, 0],     obtained_fitness[:, 1],     c=\"r\",     marker=\"o\",     label=\"Obtained Front\", ) plt.scatter(     [pt[0] for pt in reference_points],     [pt[1] for pt in reference_points],     marker=\"*\",     s=200,     color=\"magenta\",     label=\"Reference Points\", ) plt.xlabel(\"$f_1$\", fontsize=14) plt.ylabel(\"$f_2$\", fontsize=14) plt.title(\"ZTD1 Pareto Front: Theoretical vs Obtained (RNSGA-II)\", fontsize=16) plt.legend() plt.grid(True) plt.show()"},{"location":"user_guide/algorithms/python/notebooks/spea2.html","title":"Spea2","text":"In\u00a0[3]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pymoors import (\n    Spea2,\n    RandomSamplingFloat,\n    GaussianMutation,\n    ExponentialCrossover,\n    CloseDuplicatesCleaner,\n    Constraints\n)\nfrom pymoors.schemas import Population\nfrom pymoors.typing import TwoDArray\n\n\ndef evaluate_zdt6(population: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Evaluate the ZDT6 objectives in a fully vectorized manner.\n    \"\"\"\n    x1 = population[:, 0]\n    n = population.shape[1]\n    # g = 1 + (9/(n-1)) * sum(x[1:])\n    g = 1 + (9 / (n - 1)) * np.sum(population[:, 1:], axis=1)\n    # f1 = 1 - exp(-4*x1) * sin^6(6*pi*x1)\n    f1 = 1 - np.exp(-4 * x1) * np.sin(6 * np.pi * x1) ** 6\n    # h = 1 - (f1/g)^2\n    h = 1 - (f1 / g) ** 2\n    # f2 = g * h\n    f2 = g * h\n    return np.column_stack((f1, f2))\n\n\ndef zdt6_theoretical_front(num_points=1000):\n    \"\"\"\n    Compute the theoretical Pareto front for ZDT6.\n    \"\"\"\n    x1 = np.linspace(0, 1, num_points)\n    f1 = 1 - np.exp(-4 * x1) * np.sin(6 * np.pi * x1) ** 6\n    # when g = 1 \u2192 f2 = 1 - f1^2\n    f2 = 1 - f1**2\n    return f1, f2\n\n\n# Set up the SPEA2 algorithm for ZDT6\nalgorithm = Spea2(\n    sampler=RandomSamplingFloat(min=0, max=1),\n    crossover=ExponentialCrossover(exponential_crossover_rate=0.75),\n    mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),\n    fitness_fn=evaluate_zdt6,\n    constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),\n    duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),\n    num_vars=30,\n    population_size=200,\n    num_offsprings=200,\n    num_iterations=500,\n    mutation_rate=0.1,\n    crossover_rate=0.9,\n    keep_infeasible=False,\n    seed=42,\n    verbose=False,\n)\n\n# Run SPEA2 on ZDT6\nalgorithm.run()\n\n# Extract the obtained Pareto front\nbest: Population = algorithm.population.best_as_population\nobtained_fitness = best.fitness\nf1_found = obtained_fitness[:, 0]\nf2_found = obtained_fitness[:, 1]\n\n# Compute the theoretical front\nf1_theo, f2_theo = zdt6_theoretical_front()\n\n# Plot theoretical vs obtained\nplt.figure(figsize=(10, 6))\nplt.scatter(f1_theo, f2_theo, marker=\"D\", label=\"Theoretical Pareto Front\")\nplt.scatter(f1_found, f2_found, c=\"r\", marker=\"o\", s=10, label=\"Obtained Front\")\nplt.xlabel(\"$f_1$\")\nplt.ylabel(\"$f_2$\")\nplt.title(\"ZDT6 Pareto Front: Theoretical vs Obtained\")\nplt.legend()\nplt.grid(True)\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  from pymoors import (     Spea2,     RandomSamplingFloat,     GaussianMutation,     ExponentialCrossover,     CloseDuplicatesCleaner,     Constraints ) from pymoors.schemas import Population from pymoors.typing import TwoDArray   def evaluate_zdt6(population: TwoDArray) -&gt; TwoDArray:     \"\"\"     Evaluate the ZDT6 objectives in a fully vectorized manner.     \"\"\"     x1 = population[:, 0]     n = population.shape[1]     # g = 1 + (9/(n-1)) * sum(x[1:])     g = 1 + (9 / (n - 1)) * np.sum(population[:, 1:], axis=1)     # f1 = 1 - exp(-4*x1) * sin^6(6*pi*x1)     f1 = 1 - np.exp(-4 * x1) * np.sin(6 * np.pi * x1) ** 6     # h = 1 - (f1/g)^2     h = 1 - (f1 / g) ** 2     # f2 = g * h     f2 = g * h     return np.column_stack((f1, f2))   def zdt6_theoretical_front(num_points=1000):     \"\"\"     Compute the theoretical Pareto front for ZDT6.     \"\"\"     x1 = np.linspace(0, 1, num_points)     f1 = 1 - np.exp(-4 * x1) * np.sin(6 * np.pi * x1) ** 6     # when g = 1 \u2192 f2 = 1 - f1^2     f2 = 1 - f1**2     return f1, f2   # Set up the SPEA2 algorithm for ZDT6 algorithm = Spea2(     sampler=RandomSamplingFloat(min=0, max=1),     crossover=ExponentialCrossover(exponential_crossover_rate=0.75),     mutation=GaussianMutation(gene_mutation_rate=0.1, sigma=0.01),     fitness_fn=evaluate_zdt6,     constraints_fn=Constraints(lower_bound=0.0, upper_bound=1.0),     duplicates_cleaner=CloseDuplicatesCleaner(epsilon=1e-8),     num_vars=30,     population_size=200,     num_offsprings=200,     num_iterations=500,     mutation_rate=0.1,     crossover_rate=0.9,     keep_infeasible=False,     seed=42,     verbose=False, )  # Run SPEA2 on ZDT6 algorithm.run()  # Extract the obtained Pareto front best: Population = algorithm.population.best_as_population obtained_fitness = best.fitness f1_found = obtained_fitness[:, 0] f2_found = obtained_fitness[:, 1]  # Compute the theoretical front f1_theo, f2_theo = zdt6_theoretical_front()  # Plot theoretical vs obtained plt.figure(figsize=(10, 6)) plt.scatter(f1_theo, f2_theo, marker=\"D\", label=\"Theoretical Pareto Front\") plt.scatter(f1_found, f2_found, c=\"r\", marker=\"o\", s=10, label=\"Obtained Front\") plt.xlabel(\"$f_1$\") plt.ylabel(\"$f_2$\") plt.title(\"ZDT6 Pareto Front: Theoretical vs Obtained\") plt.legend() plt.grid(True) plt.show()"},{"location":"user_guide/algorithms/rust/agemoea.html","title":"Agemoea","text":"<pre><code>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::AgeMoeaBuilder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, RandomSamplingFloat, SimulatedBinaryCrossover},\n    genetic::Population\n};\nuse plotters::prelude::*;\n\n/// Evaluate the ZDT1 objectives in a fully vectorized manner.\nfn evaluate_zdt1(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    // First objective: f1 is simply the first column.\n    let n = genes.nrows();\n    let m = genes.ncols();\n\n    let clamped = genes.mapv(|v| v.clamp(0.0, 1.0));\n    let f1 = clamped.column(0).to_owned();\n\n    // Compute g for each candidate: g = 1 + (9/(n-1)) * sum(x[1:])\n    let tail = clamped.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);\n\n    // Compute the second objective: f2 = g * (1 - sqrt(f1/g))\n    let ratio = &amp;f1 / &amp;g;\n    let f2 = &amp;g * &amp;(1.0 - ratio.mapv(|r| r.sqrt()));\n\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result\n}\n\n// Create constraints using the macro impl_constraints_fn\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\n/// Compute the theoretical Pareto front for ZDT1.\nfn zdt1_theoretical_front() -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let steps = 200;\n    let f1_theo: Vec&lt;f64&gt; = (0..steps)\n        .map(|i| i as f64 / (steps as f64 - 1.0))\n        .collect();\n    let f2_theo: Vec&lt;f64&gt; = f1_theo.iter().map(|&amp;f1| 1.0 - f1.sqrt()).collect();\n    (f1_theo, f2_theo)\n}\n\n// Set up AgeMoea algorithm\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let mut algorithm = AgeMoeaBuilder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(SimulatedBinaryCrossover::new(15.0))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))\n        .fitness_fn(evaluate_zdt1)\n        .constraints_fn(BoundConstraints)\n        .num_vars(30)\n        .population_size(100)\n        .num_offsprings(100)\n        .num_iterations(200)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(42)\n        .build()\n        .expect(\"Failed to build AgeMOEA\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"AgeMOEA run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// Compute the theoretical Pareto front for ZDT1\nlet (f1_theo, f2_theo) = zdt1_theoretical_front();\n\n// Plot the theoretical Pareto front and the obtained front\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    // Compute min/max from actual data\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n\n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n\n    // Add a small margin (5%)\n    let xr = (x_max - x_min);\n    let yr = (y_max - y_min);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"ZDT1 Pareto Front: Theoretical vs Obtained\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    // Plot theoretical front as markers (e.g., diamonds) to show discontinuities.\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));\n\n    // Plot obtained front as red circles.\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\n// Emit as rich output for evcxr\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</code></pre>"},{"location":"user_guide/algorithms/rust/ibea.html","title":"Ibea","text":"<pre><code>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{array, Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::IbeaBuilder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{\n        GaussianMutation, RandomSamplingFloat, SimulatedBinaryCrossover,\n        survival::moo::IbeaHyperVolumeSurvivalOperator,\n    },\n    genetic::Population\n};\nuse plotters::prelude::*;\n\n\n// ==============================\n// EXPO2 \u2014 Objective Evaluation\n// ==============================\nfn evaluate_expo2(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    /// EXPO2 (minimization, 2 objectives).\n    ///\n    /// g(x) = 1 + (9/(n-1)) * sum_{i=2..n} x_i\n    /// f1(x) = x1\n    /// f2(x) = g(x) * exp( -5 * x1 / g(x) )\n    ///\n    /// Typical domain: x_i in [0, 1], i=1..n (e.g., n = 30).\n    let n = genes.nrows();\n    let m = genes.ncols();\n    if m &lt; 2 {\n        panic!(\"EXPO2 requires at least 2 decision variables.\");\n    }\n\n    // g(x)\n    let tail = genes.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);\n\n    let f1 = genes.column(0).to_owned();\n    let f2 = g.iter().zip(f1.iter()).map(|(gi, &amp;f1i)| gi * (-5.0 * f1i / gi).exp()).collect::&lt;Vec&lt;_&gt;&gt;();\n\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;Array2::from_shape_vec((n, 1), f2).unwrap().column(0));\n    result\n}\n\n\n// ==========================================\n// Theoretical Front (g=1 =&gt; x2..xn = 0; f2=exp(-5 f1))\n// ==========================================\n// Returns (f1, f2) arrays of the EXPO2 Pareto front:\n//      f1 in [0, 1], f2 = exp(-5 f1)\nfn expo2_theoretical_front(num_points: usize) -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let mut f1_theo = Vec::with_capacity(num_points);\n    let mut f2_theo = Vec::with_capacity(num_points);\n    for i in 0..num_points {\n        let t = if num_points &lt;= 1 { 0.0 } else { i as f64 / (num_points as f64 - 1.0) };\n        f1_theo.push(t);\n        f2_theo.push((-5.0 * t).exp());\n    }\n    (f1_theo, f2_theo)\n}\n\n\n// =============================\n// Algorithm Setup (IBEA-H)\n// =============================\n// Problem dimensionality\n\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let num_vars: usize = 30;\n    // Hypervolume reference point (minimization \u21d2 worse-than-worst)\n    // We put [4.0, 4.0] far from the normalized range [0,1]\n    let hv_reference = array![4.0, 4.0];\n    // kappa controls the selection pressure in IBEA\n    let kappa = 0.05;\n    let survivor = IbeaHyperVolumeSurvivalOperator::new(hv_reference, kappa);\n\n    let mut algorithm = IbeaBuilder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(SimulatedBinaryCrossover::new(15.0))\n        .mutation(GaussianMutation::new(0.1, 0.1))\n        .survivor(survivor)\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-6))\n        .fitness_fn(evaluate_expo2)\n        .constraints_fn(BoundConstraints)\n        .num_vars(num_vars)\n        .population_size(600)\n        .num_offsprings(600)\n        .num_iterations(600)\n        .mutation_rate(0.2)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(1)\n        .build()\n        .expect(\"Failed to build IBEA\");\n\n    // ===============\n    // Run IBEA\n    // ===============\n    algorithm.run().expect(\"IBEA run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Best front (Population)\nlet fitness = population.fitness;\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\nlet (f1_theo, f2_theo) = expo2_theoretical_front(400);\n\n// Plot the theoretical Pareto front, obtained front, and reference points\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n\n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n\n    let xr = (x_max - x_min).max(1e-9);\n    let yr = (y_max - y_min).max(1e-9);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"EXPO2 Pareto Front: Theoretical vs Obtained (IBEA HyperVolume)\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 2, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 4, RGBColor(31, 119, 180).filled()));\n\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</code></pre>"},{"location":"user_guide/algorithms/rust/nsga2.html","title":"Nsga2","text":"<pre><code>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::Nsga2Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, RandomSamplingFloat, ExponentialCrossover},\n    genetic::Population\n};\nuse plotters::prelude::*;\n\n/// Evaluate the ZDT3 objectives in a fully vectorized manner.\nfn evaluate_zdt3(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    // First objective: f1 is simply the first column.\n    // NOTE: We clamp to [0,1] during evaluation to keep the domain consistent with ZDT3.\n    // This mirrors the Python setup where variables are constrained to [0,1].\n    let n = genes.nrows();\n    let m = genes.ncols();\n\n    let clamped = genes.mapv(|v| v.clamp(0.0, 1.0));\n    let f1 = clamped.column(0).to_owned();\n\n    // Compute g for each candidate: g = 1 + (9/(n-1)) * sum(x[1:])\n    let tail = clamped.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);\n\n    // Compute h for each candidate: h = 1 - sqrt(f1/g) - (f1/g)*sin(10*pi*f1)\n    let ratio = &amp;f1 / &amp;g;\n    let sin_term = f1.mapv(|v| (10.0 * std::f64::consts::PI * v).sin());\n    let h = 1.0 - ratio.mapv(|r| r.sqrt()) - &amp;(&amp;ratio * &amp;sin_term);\n\n    // Compute the second objective: f2 = g * h\n    let f2 = &amp;g * &amp;h;\n\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result\n}\n\n// Create constraints using the macro impl_constraints_fn\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\n\n/// Compute the theoretical Pareto front for ZDT3.\n///\n/// Returns:\n///     f1_theo (np.ndarray): f1 values on the theoretical front.\n///     f2_theo (np.ndarray): Corresponding f2 values.\n///\n/// Instead of using a dense linspace, we sample only a few points per interval to\n/// clearly illustrate the discontinuous nature of the front.\nfn zdt3_theoretical_front() -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    // Define the intervals for f1 where the Pareto front exists\n    let intervals: &amp;[(f64, f64)] = &amp;[\n        (0.0, 0.0830015349),\n        (0.1822287280, 0.2577623634),\n        (0.4093136748, 0.4538828821),\n        (0.6183967944, 0.6525117038),\n        (0.8233317983, 0.85518),\n    ];\n\n    let mut f1_theo: Vec&lt;f64&gt; = Vec::new();\n    let mut f2_theo: Vec&lt;f64&gt; = Vec::new();\n\n    // Use a small number of points per interval (e.g., 20) to highlight the discontinuities.\n    for (start, end) in intervals.iter().copied() {\n        let steps = 20usize;\n        for i in 0..steps {\n            let t = i as f64 / (steps as f64 - 1.0);\n            let f1 = start + t * (end - start);\n            let f2 = 1.0 - f1.sqrt() - f1 * (10.0 * std::f64::consts::PI * f1).sin();\n            f1_theo.push(f1);\n            f2_theo.push(f2);\n        }\n    }\n\n    (f1_theo, f2_theo)\n}\n\n// Set up the NSGA2 algorithm with the above definitions\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let mut algorithm = Nsga2Builder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(ExponentialCrossover::new(0.75))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-5))\n        .fitness_fn(evaluate_zdt3)\n        .constraints_fn(BoundConstraints)\n        .num_vars(30)\n        .population_size(200)\n        .num_offsprings(200)\n        .num_iterations(300)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(42)\n        .build()\n        .expect(\"Failed to build NSGA2\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"NSGA2 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// Compute the theoretical Pareto front for ZDT3\nlet (f1_theo, f2_theo) = zdt3_theoretical_front();\n\n// Plot the theoretical Pareto front and the obtained front\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    // Compute min/max from actual data\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n\n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n\n    // Add a small margin (5%)\n    let xr = (x_max - x_min);\n    let yr = (y_max - y_min);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"ZDT3 Pareto Front: Theoretical vs Obtained\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    // Plot theoretical front as markers (e.g., diamonds) to show discontinuities.\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));\n\n    // Plot obtained front as red circles.\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\n// Emit as rich output for evcxr\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</code></pre>"},{"location":"user_guide/algorithms/rust/nsga3.html","title":"Nsga3","text":"<pre><code>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotly = \"*\"\n\nuse ndarray::{Array1, Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::Nsga3Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{\n        GaussianMutation,\n        RandomSamplingFloat,\n        SimulatedBinaryCrossover,\n        Nsga3ReferencePointsSurvival,\n        Nsga3ReferencePoints,\n        DanAndDenisReferencePoints,\n        StructuredReferencePoints\n    },\n    genetic::Population,\n};\n\nuse plotly::{Plot, Scatter3D, Layout, Trace};\nuse plotly::common::{Mode, Marker, Title, MarkerSymbol};\nuse plotly::color::NamedColor;\nuse plotly::layout::{LayoutScene as Scene, Axis as PlotlyAxis};\n\n\n/// Evaluate the DTLZ2 objectives for a 3-objective problem.\n///\n/// The decision vector x has num_vars components. For the Pareto front,\n/// the auxiliary function g(x) is minimized (g(x)=0) by setting the last\n/// num_vars-2 variables to 0.5.\n///\n/// The objectives are computed as:\n///   f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2)\n///   f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2)\n///   f3(x) = (1+g) * sin((pi/2)*x1)\nfn evaluate_dtlz2(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let n = genes.nrows();\n    let pi_over_2 = std::f64::consts::PI / 2.0;\n\n    // Compute the auxiliary function g(x) using variables 3 to num_vars.\n    let tail = genes.slice(s![.., 2..]).to_owned();\n    let g_vec: Array1&lt;f64&gt; = tail.mapv(|v| (v - 0.5).powi(2)).sum_axis(Axis(1));\n\n    // x1, x2\n    let x1 = genes.column(0).to_owned();\n    let x2 = genes.column(1).to_owned();\n\n    // Trig terms\n    let cos_x1 = x1.mapv(|v| (pi_over_2 * v).cos());\n    let cos_x2 = x2.mapv(|v| (pi_over_2 * v).cos());\n    let sin_x1 = x1.mapv(|v| (pi_over_2 * v).sin());\n    let sin_x2 = x2.mapv(|v| (pi_over_2 * v).sin());\n\n    let one_plus_g = g_vec.mapv(|g| 1.0 + g);\n\n    // f1, f2, f3 as Array1\n    let f1 = &amp;one_plus_g * &amp;cos_x1 * &amp;cos_x2;\n    let f2 = &amp;one_plus_g * &amp;cos_x1 * &amp;sin_x2;\n    let f3 = &amp;one_plus_g * &amp;sin_x1;\n\n    // Stack into (n, 3)\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 3));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result.column_mut(2).assign(&amp;f3);\n    result\n}\n\n/// Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives).\n///\n/// For the Pareto-optimal front, g(x) = 0, which implies that the decision variables\n/// x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2:\n///   f1 = cos((pi/2)*x1) * cos((pi/2)*x2)\n///   f2 = cos((pi/2)*x1) * sin((pi/2)*x2)\n///   f3 = sin((pi/2)*x1)\n/// These points lie on a portion of the unit hypersphere in the positive orthant.\nfn dtlz2_theoretical_front(num_points: usize) -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let pi_over_2 = std::f64::consts::PI / 2.0;\n\n    let mut f1_all = Vec::with_capacity(num_points * num_points);\n    let mut f2_all = Vec::with_capacity(num_points * num_points);\n    let mut f3_all = Vec::with_capacity(num_points * num_points);\n\n    for i in 0..num_points {\n        let x1 = if num_points &gt; 1 {\n            i as f64 / (num_points as f64 - 1.0)\n        } else {\n            0.0\n        };\n        for j in 0..num_points {\n            let x2 = if num_points &gt; 1 {\n                j as f64 / (num_points as f64 - 1.0)\n            } else {\n                0.0\n            };\n\n            let f1 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).cos();\n            let f2 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).sin();\n            let f3 = (pi_over_2 * x1).sin();\n\n            f1_all.push(f1);\n            f2_all.push(f2);\n            f3_all.push(f3);\n        }\n    }\n\n    (f1_all, f2_all, f3_all)\n}\n\n// Set up the NSGA-III algorithm for DTLZ2.\n// For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k.\n// Here, we choose k = 10, so num_vars = 2 + 10 = 12.\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\n\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let rp = DanAndDenisReferencePoints::new(100, 3).generate();\n    let nsga3_rp = Nsga3ReferencePoints::new(rp, false);\n    let survivor = Nsga3ReferencePointsSurvival::new(nsga3_rp);\n    let mut algorithm = Nsga3Builder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(SimulatedBinaryCrossover::new(10.0)) // distribution_index = 10\n        .mutation(GaussianMutation::new(0.1, 0.01))     // gene_mutation_rate = 0.1, sigma = 0.01\n        .survivor(survivor)\n        .fitness_fn(evaluate_dtlz2)\n        .constraints_fn(BoundConstraints)\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))\n        .num_vars(12)\n        .population_size(500)\n        .num_offsprings(500)\n        .num_iterations(700)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(1729)\n        .build()\n        .expect(\"Failed to build NSGA3\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"NSGA3 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Define again rp just for plotting\nlet rp_plot: Array2&lt;f64&gt; = DanAndDenisReferencePoints::new(100, 3).generate();\nlet rp_f1: Vec&lt;f64&gt; = rp_plot.column(0).to_vec();\nlet rp_f2: Vec&lt;f64&gt; = rp_plot.column(1).to_vec();\nlet rp_f3: Vec&lt;f64&gt; = rp_plot.column(2).to_vec();\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2, f3])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\nlet f3_found: Vec&lt;f64&gt; = fitness.column(2).to_vec();\n\n// Compute the theoretical Pareto front for DTLZ2 (dense grid on the positive octant of the unit sphere)\nlet (f1_theo, f2_theo, f3_theo) = dtlz2_theoretical_front(50);\n\n// Build Plotly traces for 3D scatter (theoretical vs obtained)\nlet theoretical_trace = Scatter3D::new(f1_theo.clone(), f2_theo.clone(), f3_theo.clone())\n    .mode(Mode::Markers)\n    .name(\"Theoretical Pareto Front\")\n    .marker(Marker::new().size(3).color(NamedColor::Black).opacity(0.5));\n\nlet obtained_trace = Scatter3D::new(f1_found.clone(), f2_found.clone(), f3_found.clone())\n    .mode(Mode::Markers)\n    .name(\"Obtained Front\")\n    .marker(Marker::new().size(5).color(NamedColor::Red));\n\nlet refpoints_trace = Scatter3D::new(rp_f1, rp_f2, rp_f3)\n    .mode(Mode::Markers)\n    .name(\"Reference Points\")\n    .marker(\n        Marker::new()\n            .size(8)\n            .color(NamedColor::Magenta)\n            .symbol(MarkerSymbol::Star)\n    );\n\n// Layout con Title builder y PlotlyAxis (alias para evitar conflicto con ndarray::Axis)\nlet layout: Layout = Layout::new()\n    .width(800)\n    .height(600)\n    .title(Title::from(\"DTLZ2 Pareto Front: Theoretical vs Obtained (NSGA-III)\"))\n    .scene(\n        Scene::new()\n            .x_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;1&lt;/sub&gt;\")))\n            .y_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;2&lt;/sub&gt;\")))\n            .z_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;3&lt;/sub&gt;\")))\n        // .aspect_mode(plotly::layout::scene::AspectMode::Cube) // opcional\n    );\n\n// Compose the plot\nlet mut plot = Plot::new();\nplot.add_trace(theoretical_trace);\nplot.add_trace(obtained_trace);\nplot.add_trace(refpoints_trace);\nplot.set_layout(layout);\n\n// Render as rich HTML for evcxr\nlet html = plot.to_html();\nprintln!(\"EVCXR_BEGIN_CONTENT text/html\\n{}\\nEVCXR_END_CONTENT\", html);\n</code></pre>"},{"location":"user_guide/algorithms/rust/revea.html","title":"Revea","text":"<pre><code>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotly = \"*\"\n\nuse ndarray::{Array1, Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::ReveaBuilder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{\n        GaussianMutation,\n        RandomSamplingFloat,\n        SimulatedBinaryCrossover,\n        DanAndDenisReferencePoints,\n        StructuredReferencePoints,\n        ReveaReferencePointsSurvival\n    },\n    genetic::Population,\n};\n\nuse plotly::{Plot, Scatter3D, Layout, Trace};\nuse plotly::common::{Mode, Marker, Title, MarkerSymbol};\nuse plotly::color::NamedColor;\nuse plotly::layout::{LayoutScene as Scene, Axis as PlotlyAxis};\n\n\n/// Evaluate the DTLZ2 objectives for a 3-objective problem.\n///\n/// The decision vector x has num_vars components. For the Pareto front,\n/// the auxiliary function g(x) is minimized (g(x)=0) by setting the last\n/// num_vars-2 variables to 0.5.\n///\n/// The objectives are computed as:\n///   f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2)\n///   f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2)\n///   f3(x) = (1+g) * sin((pi/2)*x1)\nfn evaluate_dtlz2(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let n = genes.nrows();\n    let pi_over_2 = std::f64::consts::PI / 2.0;\n\n    // Compute the auxiliary function g(x) using variables 3 to num_vars.\n    let tail = genes.slice(s![.., 2..]).to_owned();\n    let g_vec: Array1&lt;f64&gt; = tail.mapv(|v| (v - 0.5).powi(2)).sum_axis(Axis(1));\n\n    // x1, x2\n    let x1 = genes.column(0).to_owned();\n    let x2 = genes.column(1).to_owned();\n\n    // Trig terms\n    let cos_x1 = x1.mapv(|v| (pi_over_2 * v).cos());\n    let cos_x2 = x2.mapv(|v| (pi_over_2 * v).cos());\n    let sin_x1 = x1.mapv(|v| (pi_over_2 * v).sin());\n    let sin_x2 = x2.mapv(|v| (pi_over_2 * v).sin());\n\n    let one_plus_g = g_vec.mapv(|g| 1.0 + g);\n\n    // f1, f2, f3 as Array1\n    let f1 = &amp;one_plus_g * &amp;cos_x1 * &amp;cos_x2;\n    let f2 = &amp;one_plus_g * &amp;cos_x1 * &amp;sin_x2;\n    let f3 = &amp;one_plus_g * &amp;sin_x1;\n\n    // Stack into (n, 3)\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 3));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result.column_mut(2).assign(&amp;f3);\n    result\n}\n\n/// Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives).\n///\n/// For the Pareto-optimal front, g(x) = 0, which implies that the decision variables\n/// x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2:\n///   f1 = cos((pi/2)*x1) * cos((pi/2)*x2)\n///   f2 = cos((pi/2)*x1) * sin((pi/2)*x2)\n///   f3 = sin((pi/2)*x1)\n/// These points lie on a portion of the unit hypersphere in the positive orthant.\nfn dtlz2_theoretical_front(num_points: usize) -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let pi_over_2 = std::f64::consts::PI / 2.0;\n\n    let mut f1_all = Vec::with_capacity(num_points * num_points);\n    let mut f2_all = Vec::with_capacity(num_points * num_points);\n    let mut f3_all = Vec::with_capacity(num_points * num_points);\n\n    for i in 0..num_points {\n        let x1 = if num_points &gt; 1 {\n            i as f64 / (num_points as f64 - 1.0)\n        } else {\n            0.0\n        };\n        for j in 0..num_points {\n            let x2 = if num_points &gt; 1 {\n                j as f64 / (num_points as f64 - 1.0)\n            } else {\n                0.0\n            };\n\n            let f1 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).cos();\n            let f2 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).sin();\n            let f3 = (pi_over_2 * x1).sin();\n\n            f1_all.push(f1);\n            f2_all.push(f2);\n            f3_all.push(f3);\n        }\n    }\n\n    (f1_all, f2_all, f3_all)\n}\n\n// Set up the REVEA algorithm for DTLZ2.\n// For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k.\n// Here, we choose k = 10, so num_vars = 2 + 10 = 12.\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let num_iterations = 600;\n    let rp = DanAndDenisReferencePoints::new(101, 3).generate();\n    let alpha = 2.5;\n    let frequency = 0.2;\n    let survivor = ReveaReferencePointsSurvival::new(rp, alpha, frequency, num_iterations);\n\n    let mut algorithm = ReveaBuilder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(SimulatedBinaryCrossover::new(10.0)) // distribution_index = 10\n        .mutation(GaussianMutation::new(0.1, 0.01))     // gene_mutation_rate = 0.1, sigma = 0.01\n        .survivor(survivor)\n        .fitness_fn(evaluate_dtlz2)\n        .constraints_fn(BoundConstraints)\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))\n        .num_vars(12)\n        .population_size(200)\n        .num_offsprings(200)\n        .num_iterations(num_iterations)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(1729)\n        .build()\n        .expect(\"Failed to build REVEA\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"REVEA run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Define again rp just for plotting\nlet rp_plot: Array2&lt;f64&gt; = DanAndDenisReferencePoints::new(100, 3).generate();\nlet rp_f1: Vec&lt;f64&gt; = rp_plot.column(0).to_vec();\nlet rp_f2: Vec&lt;f64&gt; = rp_plot.column(1).to_vec();\nlet rp_f3: Vec&lt;f64&gt; = rp_plot.column(2).to_vec();\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2, f3])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\nlet f3_found: Vec&lt;f64&gt; = fitness.column(2).to_vec();\n\n// Compute the theoretical Pareto front for DTLZ2 (dense grid on the positive octant of the unit sphere)\nlet (f1_theo, f2_theo, f3_theo) = dtlz2_theoretical_front(50);\n\n// Build Plotly traces for 3D scatter (theoretical vs obtained)\nlet theoretical_trace = Scatter3D::new(f1_theo.clone(), f2_theo.clone(), f3_theo.clone())\n    .mode(Mode::Markers)\n    .name(\"Theoretical Pareto Front\")\n    .marker(Marker::new().size(3).color(NamedColor::Black).opacity(0.5));\n\nlet obtained_trace = Scatter3D::new(f1_found.clone(), f2_found.clone(), f3_found.clone())\n    .mode(Mode::Markers)\n    .name(\"Obtained Front (REVEA)\")\n    .marker(Marker::new().size(5).color(NamedColor::Red));\n\nlet refpoints_trace = Scatter3D::new(rp_f1, rp_f2, rp_f3)\n    .mode(Mode::Markers)\n    .name(\"Reference Points\")\n    .marker(\n        Marker::new()\n            .size(8)\n            .color(NamedColor::Magenta)\n            .symbol(MarkerSymbol::Star)\n    );\n\n// Layout con Title builder y PlotlyAxis (alias para evitar conflicto con ndarray::Axis)\nlet layout: Layout = Layout::new()\n    .width(800)\n    .height(600)\n    .title(Title::from(\"DTLZ2 Pareto Front: Theoretical vs Obtained (REVEA)\"))\n    .scene(\n        Scene::new()\n            .x_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;1&lt;/sub&gt;\")))\n            .y_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;2&lt;/sub&gt;\")))\n            .z_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;3&lt;/sub&gt;\")))\n        // .aspect_mode(plotly::layout::scene::AspectMode::Cube) // optional\n    );\n\n// Compose the plot\nlet mut plot = Plot::new();\nplot.add_trace(theoretical_trace);\nplot.add_trace(obtained_trace);\nplot.add_trace(refpoints_trace);\nplot.set_layout(layout);\n\n// Render as rich HTML for evcxr\nlet html = plot.to_html();\nprintln!(\"EVCXR_BEGIN_CONTENT text/html\\n{}\\nEVCXR_END_CONTENT\", html);\n</code></pre>"},{"location":"user_guide/algorithms/rust/rnsga2.html","title":"Rnsga2","text":"<pre><code>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{s, array, Array2, Axis, Ix2};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::Rnsga2Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, RandomSamplingFloat, ExponentialCrossover, Rnsga2ReferencePointsSurvival},\n    genetic::Population,\n};\nuse plotters::prelude::*\n\n/// Evaluate the ZTD1 objectives in a fully vectorized manner.\nfn evaluate_ztd1(x: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let n = x.nrows();\n    let m = x.ncols();\n\n    // clamp to [0,1] to mirror the Python domain constraints\n    let clamped = x.mapv(|v| v.clamp(0.0, 1.0));\n\n    let f1 = clamped.column(0).to_owned();\n    let tail = clamped.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + 9.0 / ((m as f64) - 1.0) * s);\n    let ratio = &amp;f1 / &amp;g;\n    let f2 = &amp;g * (1.0 - ratio.mapv(|r| r.sqrt()));\n\n    let mut out = Array2::&lt;f64&gt;::zeros((n, 2));\n    out.column_mut(0).assign(&amp;f1);\n    out.column_mut(1).assign(&amp;f2);\n    out\n}\n\n/// Compute the theoretical Pareto front for ZTD1.\nfn ztd1_theoretical_front() -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let mut f1_theo = Vec::with_capacity(200);\n    let mut f2_theo = Vec::with_capacity(200);\n    for i in 0..200 {\n        let v = i as f64 / 199.0;\n        f1_theo.push(v);\n        f2_theo.push(1.0 - v.sqrt());\n    }\n    (f1_theo, f2_theo)\n}\n\n// Create constraints using the macro impl_constraints_fn\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\n\n\n// Set up RNSGA-II algorithm with epsilon = 0.005\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    // Define two reference points (for example, points on the Pareto front)\n    let rp: Array2&lt;f64&gt; = array![[0.5, 0.2], [0.1, 0.6]];\n    let epsilon = 0.005;\n    let survivor = Rnsga2ReferencePointsSurvival::new(rp, epsilon);\n    let mut algorithm = Rnsga2Builder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(ExponentialCrossover::new(0.75))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .survivor(survivor)\n        .fitness_fn(evaluate_ztd1)\n        .constraints_fn(BoundConstraints)\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))\n        .num_vars(30)\n        .population_size(50)\n        .num_offsprings(50)\n        .num_iterations(700)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(1729)\n        .build()\n        .expect(\"Failed to build RNSGA-II\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"RNSGA2 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Compute the theoretical Pareto front for ZTD1\nlet (f1_theo, f2_theo) = ztd1_theoretical_front();\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// Compute the theoretical Pareto front for ZTD1\nlet (f1_theo, f2_theo) = ztd1_theoretical_front();\n\n// Plot the theoretical Pareto front, obtained front, and reference points\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 600));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    let grid_color = RGBColor(220, 220, 220);\n\n    // Build axis ranges with headroom including reference points\n    let reference_points: Vec&lt;[f64; 2]&gt; = vec![[0.5, 0.2], [0.1, 0.6]];\n\n    // Compute min/max from actual data\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n\n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n\n    // Add a small margin (5%)\n    let xr = (x_max - x_min);\n    let yr = (y_max - y_min);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"ZDT1 Pareto Front: Theoretical vs Obtained (R-NSGA-II)\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")                      // plt.xlabel(\"$f_1$\")\n        .y_desc(\"f2\")                      // plt.ylabel(\"$f_2$\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;grid_color)     // plt.grid(True)\n        .draw()\n        .unwrap();\n\n    // Theoretical Pareto Front (black solid line, linewidth=2)\n    chart.draw_series(LineSeries::new(\n        f1_theo.iter().cloned().zip(f2_theo.iter().cloned()),\n        ShapeStyle {\n            color: BLACK.to_rgba(),\n            filled: false,\n            stroke_width: 2,\n        },\n    )).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| PathElement::new(vec![(x - 10, y), (x + 10, y)], &amp;BLACK));\n\n    // Obtained Front (red circles)\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 4, RGBColor(255, 0, 0).filled()));\n\n    // Reference Points\n    chart.draw_series(\n        reference_points.iter().map(|p| {\n            TriangleMarker::new((p[0], p[1]), 8, MAGENTA.filled())\n        })\n    ).unwrap()\n     .label(\"Reference Points\")\n     .legend(|(x, y)| TriangleMarker::new((x, y), 8, MAGENTA.filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;BLACK.mix(0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\n// Emit as rich output for evcxr\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</code></pre>"},{"location":"user_guide/algorithms/rust/spea2.html","title":"Spea2","text":"<pre><code>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::Spea2Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, RandomSamplingFloat, ExponentialCrossover},\n    genetic::Population\n};\n\nuse plotters::prelude::*;\n\n/// Evaluate the ZDT6 objectives in a fully vectorized manner.\nfn evaluate_zdt6(population: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let n = population.nrows();\n    let m = population.ncols();\n\n    let x1 = population.column(0).to_owned();\n    // g = 1 + (9/(n-1)) * sum(x[1:])\n    let tail = population.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);\n\n    // f1 = 1 - exp(-4*x1) * sin^6(6*pi*x1)\n    let sin6 = x1.mapv(|v| (6.0 * std::f64::consts::PI * v).sin().powi(6));\n    let f1 = x1.mapv(|v| 1.0) - x1.mapv(|v| (-4.0 * v).exp()) * sin6;\n\n    // h = 1 - (f1/g)^2\n    let ratio = &amp;f1 / &amp;g;\n    let h = ratio.mapv(|r| 1.0 - r.powi(2));\n\n    // f2 = g * h\n    let f2 = &amp;g * &amp;h;\n\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result\n}\n\n/// Compute the theoretical Pareto front for ZDT6.\nfn zdt6_theoretical_front(num_points: usize) -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let mut f1: Vec&lt;f64&gt; = Vec::with_capacity(num_points);\n    let mut f2: Vec&lt;f64&gt; = Vec::with_capacity(num_points);\n\n    for i in 0..num_points {\n        let x1 = if num_points &gt; 1 {\n            i as f64 / (num_points as f64 - 1.0)\n        } else {\n            0.0\n        };\n        let f1_i = 1.0 - (-4.0 * x1).exp() * (6.0 * std::f64::consts::PI * x1).sin().powi(6);\n        // when g = 1 \u2192 f2 = 1 - f1^2\n        let f2_i = 1.0 - f1_i.powi(2);\n        f1.push(f1_i);\n        f2.push(f2_i);\n    }\n\n    (f1, f2)\n}\n\n// Set up the SPEA2 algorithm for ZDT6\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let mut algorithm = Spea2Builder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(ExponentialCrossover::new(0.75))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))\n        .fitness_fn(evaluate_zdt6)\n        .constraints_fn(BoundConstraints)\n        .num_vars(30)\n        .population_size(200)\n        .num_offsprings(200)\n        .num_iterations(500)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .seed(42)\n        .verbose(false)\n        .build()\n        .expect(\"Failed to build SPEA2\");\n\n    // Run SPEA2 on ZDT6\n    algorithm.run().expect(\"SPEA2 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// Compute the theoretical Pareto front for ZDT6\nlet (f1_theo, f2_theo) = zdt6_theoretical_front(1000);\n\n// Plot the theoretical Pareto front and the obtained front\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    // Compute min/max from actual data\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n\n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n\n    // Add a small margin (5%)\n    let xr = (x_max - x_min).max(1e-9);\n    let yr = (y_max - y_min).max(1e-9);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"ZDT6 Pareto Front: Theoretical vs Obtained (SPEA2)\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    // Plot theoretical front as blue markers.\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));\n\n    // Plot obtained front as red circles.\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\n// Emit as rich output for evcxr\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</code></pre>"},{"location":"user_guide/algorithms/rust/notebooks/agemoea.html","title":"Agemoea","text":"In\u00a0[6]: Copied! <pre>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::AgeMoeaBuilder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, RandomSamplingFloat, SimulatedBinaryCrossover},\n    genetic::Population\n};\nuse plotters::prelude::*;\n\n/// Evaluate the ZDT1 objectives in a fully vectorized manner.\nfn evaluate_zdt1(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    // First objective: f1 is simply the first column.\n    let n = genes.nrows();\n    let m = genes.ncols();\n\n    let clamped = genes.mapv(|v| v.clamp(0.0, 1.0));\n    let f1 = clamped.column(0).to_owned();\n\n    // Compute g for each candidate: g = 1 + (9/(n-1)) * sum(x[1:])\n    let tail = clamped.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);\n\n    // Compute the second objective: f2 = g * (1 - sqrt(f1/g))\n    let ratio = &amp;f1 / &amp;g;\n    let f2 = &amp;g * &amp;(1.0 - ratio.mapv(|r| r.sqrt()));\n\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result\n}\n\n// Create constraints using the macro impl_constraints_fn\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\n/// Compute the theoretical Pareto front for ZDT1.\nfn zdt1_theoretical_front() -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let steps = 200;\n    let f1_theo: Vec&lt;f64&gt; = (0..steps)\n        .map(|i| i as f64 / (steps as f64 - 1.0))\n        .collect();\n    let f2_theo: Vec&lt;f64&gt; = f1_theo.iter().map(|&amp;f1| 1.0 - f1.sqrt()).collect();\n    (f1_theo, f2_theo)\n}\n\n// Set up AgeMoea algorithm\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let mut algorithm = AgeMoeaBuilder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(SimulatedBinaryCrossover::new(15.0))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))\n        .fitness_fn(evaluate_zdt1)\n        .constraints_fn(BoundConstraints)\n        .num_vars(30)\n        .population_size(100)\n        .num_offsprings(100)\n        .num_iterations(200)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(42)\n        .build()\n        .expect(\"Failed to build AgeMOEA\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"AgeMOEA run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// Compute the theoretical Pareto front for ZDT1\nlet (f1_theo, f2_theo) = zdt1_theoretical_front();\n\n// Plot the theoretical Pareto front and the obtained front\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    // Compute min/max from actual data\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n    \n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n    \n    // Add a small margin (5%)\n    let xr = (x_max - x_min);\n    let yr = (y_max - y_min);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"ZDT1 Pareto Front: Theoretical vs Obtained\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    // Plot theoretical front as markers (e.g., diamonds) to show discontinuities.\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));\n\n    // Plot obtained front as red circles.\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\n// Emit as rich output for evcxr\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</pre> :dep ndarray = \"*\" :dep moors = \"*\" :dep plotters = \"0.3.6\"  use ndarray::{Array2, Axis, Ix2, s}; use moors::{     impl_constraints_fn,     algorithms::AgeMoeaBuilder,     duplicates::CloseDuplicatesCleaner,     operators::{GaussianMutation, RandomSamplingFloat, SimulatedBinaryCrossover},     genetic::Population }; use plotters::prelude::*;  /// Evaluate the ZDT1 objectives in a fully vectorized manner. fn evaluate_zdt1(genes: &amp;Array2) -&gt; Array2 {     // First objective: f1 is simply the first column.     let n = genes.nrows();     let m = genes.ncols();      let clamped = genes.mapv(|v| v.clamp(0.0, 1.0));     let f1 = clamped.column(0).to_owned();      // Compute g for each candidate: g = 1 + (9/(n-1)) * sum(x[1:])     let tail = clamped.slice(s![.., 1..]);     let sums = tail.sum_axis(Axis(1));     let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);      // Compute the second objective: f2 = g * (1 - sqrt(f1/g))     let ratio = &amp;f1 / &amp;g     let f2 = &amp;g * &amp;(1.0 - ratio.mapv(|r| r.sqrt()));      let mut result = Array2::::zeros((n, 2));     result.column_mut(0).assign(&amp;f1);     result.column_mut(1).assign(&amp;f2);     result }  // Create constraints using the macro impl_constraints_fn impl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);  /// Compute the theoretical Pareto front for ZDT1. fn zdt1_theoretical_front() -&gt; (Vec, Vec) {     let steps = 200;     let f1_theo: Vec = (0..steps)         .map(|i| i as f64 / (steps as f64 - 1.0))         .collect();     let f2_theo: Vec = f1_theo.iter().map(|&amp;f1| 1.0 - f1.sqrt()).collect();     (f1_theo, f2_theo) }  // Set up AgeMoea algorithm let population: Population = {     let mut algorithm = AgeMoeaBuilder::default()         .sampler(RandomSamplingFloat::new(0.0, 1.0))         .crossover(SimulatedBinaryCrossover::new(15.0))         .mutation(GaussianMutation::new(0.1, 0.01))         .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))         .fitness_fn(evaluate_zdt1)         .constraints_fn(BoundConstraints)         .num_vars(30)         .population_size(100)         .num_offsprings(100)         .num_iterations(200)         .mutation_rate(0.1)         .crossover_rate(0.9)         .keep_infeasible(false)         .verbose(false)         .seed(42)         .build()         .expect(\"Failed to build AgeMOEA\");      // Run the algorithm     algorithm.run().expect(\"AgeMOEA run failed\");     algorithm.population().unwrap().clone() };  // Get the best Pareto front obtained (as a Population instance) let fitness = population.fitness;  // Extract the obtained fitness values (each row is [f1, f2]) let f1_found: Vec = fitness.column(0).to_vec(); let f2_found: Vec = fitness.column(1).to_vec();  // Compute the theoretical Pareto front for ZDT1 let (f1_theo, f2_theo) = zdt1_theoretical_front();  // Plot the theoretical Pareto front and the obtained front let mut svg = String::new(); {     let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));     let root = backend.into_drawing_area();     root.fill(&amp;WHITE).unwrap();      // Compute min/max from actual data     let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);     let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);          for &amp;x in f1_theo.iter().chain(f1_found.iter()) {         if x &lt; x_min { x_min = x; }         if x &gt; x_max { x_max = x; }     }     for &amp;y in f2_theo.iter().chain(f2_found.iter()) {         if y &lt; y_min { y_min = y; }         if y &gt; y_max { y_max = y; }     }          // Add a small margin (5%)     let xr = (x_max - x_min);     let yr = (y_max - y_min);     x_min -= xr * 0.05;     x_max += xr * 0.05;     y_min -= yr * 0.05;     y_max += yr * 0.05;      let mut chart = ChartBuilder::on(&amp;root)         .caption(\"ZDT1 Pareto Front: Theoretical vs Obtained\", (\"DejaVu Sans\", 22))         .margin(10)         .x_label_area_size(40)         .y_label_area_size(60)         .build_cartesian_2d(x_min..x_max, y_min..y_max)         .unwrap();      chart.configure_mesh()         .x_desc(\"f1\")         .y_desc(\"f2\")         .axis_desc_style((\"DejaVu Sans\", 14))         .light_line_style(&amp;RGBColor(220, 220, 220))         .draw()         .unwrap();      // Plot theoretical front as markers (e.g., diamonds) to show discontinuities.     chart.draw_series(         f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {             Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())         })     ).unwrap()      .label(\"Theoretical Pareto Front\")      .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));      // Plot obtained front as red circles.     chart.draw_series(         f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {             Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())         })     ).unwrap()      .label(\"Obtained Front\")      .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));      chart.configure_series_labels()         .border_style(&amp;RGBAColor(0, 0, 0, 0.3))         .background_style(&amp;WHITE.mix(0.9))         .label_font((\"DejaVu Sans\", 13))         .draw()         .unwrap();      root.present().unwrap(); }  // Emit as rich output for evcxr println!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);  Out[6]:"},{"location":"user_guide/algorithms/rust/notebooks/ibea.html","title":"Ibea","text":"In\u00a0[6]: Copied! <pre>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{array, Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::IbeaBuilder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{\n        GaussianMutation, RandomSamplingFloat, SimulatedBinaryCrossover,\n        survival::moo::IbeaHyperVolumeSurvivalOperator,\n    },\n    genetic::Population\n};\nuse plotters::prelude::*;\n\n\n// ==============================\n// EXPO2 \u2014 Objective Evaluation\n// ==============================\nfn evaluate_expo2(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    /// EXPO2 (minimization, 2 objectives).\n    ///\n    /// g(x) = 1 + (9/(n-1)) * sum_{i=2..n} x_i\n    /// f1(x) = x1\n    /// f2(x) = g(x) * exp( -5 * x1 / g(x) )\n    ///\n    /// Typical domain: x_i in [0, 1], i=1..n (e.g., n = 30).\n    let n = genes.nrows();\n    let m = genes.ncols();\n    if m &lt; 2 {\n        panic!(\"EXPO2 requires at least 2 decision variables.\");\n    }\n\n    // g(x)\n    let tail = genes.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);\n\n    let f1 = genes.column(0).to_owned();\n    let f2 = g.iter().zip(f1.iter()).map(|(gi, &amp;f1i)| gi * (-5.0 * f1i / gi).exp()).collect::&lt;Vec&lt;_&gt;&gt;();\n\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;Array2::from_shape_vec((n, 1), f2).unwrap().column(0));\n    result\n}\n\n\n// ==========================================\n// Theoretical Front (g=1 =&gt; x2..xn = 0; f2=exp(-5 f1))\n// ==========================================\n// Returns (f1, f2) arrays of the EXPO2 Pareto front:\n//      f1 in [0, 1], f2 = exp(-5 f1)\nfn expo2_theoretical_front(num_points: usize) -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let mut f1_theo = Vec::with_capacity(num_points);\n    let mut f2_theo = Vec::with_capacity(num_points);\n    for i in 0..num_points {\n        let t = if num_points &lt;= 1 { 0.0 } else { i as f64 / (num_points as f64 - 1.0) };\n        f1_theo.push(t);\n        f2_theo.push((-5.0 * t).exp());\n    }\n    (f1_theo, f2_theo)\n}\n\n\n// =============================\n// Algorithm Setup (IBEA-H)\n// =============================\n// Problem dimensionality\n\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let num_vars: usize = 30;\n    // Hypervolume reference point (minimization \u21d2 worse-than-worst)\n    // We put [4.0, 4.0] far from the normalized range [0,1]\n    let hv_reference = array![4.0, 4.0];\n    // kappa controls the selection pressure in IBEA\n    let kappa = 0.05;\n    let survivor = IbeaHyperVolumeSurvivalOperator::new(hv_reference, kappa);\n\n    let mut algorithm = IbeaBuilder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(SimulatedBinaryCrossover::new(15.0))\n        .mutation(GaussianMutation::new(0.1, 0.1))\n        .survivor(survivor)\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-6))\n        .fitness_fn(evaluate_expo2)\n        .constraints_fn(BoundConstraints)\n        .num_vars(num_vars)\n        .population_size(600)\n        .num_offsprings(600)\n        .num_iterations(600)\n        .mutation_rate(0.2)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(1)\n        .build()\n        .expect(\"Failed to build IBEA\");\n\n    // ===============\n    // Run IBEA\n    // ===============\n    algorithm.run().expect(\"IBEA run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Best front (Population)\nlet fitness = population.fitness;\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\nlet (f1_theo, f2_theo) = expo2_theoretical_front(400);\n\n// Plot the theoretical Pareto front, obtained front, and reference points\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n\n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n\n    let xr = (x_max - x_min).max(1e-9);\n    let yr = (y_max - y_min).max(1e-9);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"EXPO2 Pareto Front: Theoretical vs Obtained (IBEA HyperVolume)\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 2, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 4, RGBColor(31, 119, 180).filled()));\n\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</pre> :dep ndarray = \"*\" :dep moors = \"*\" :dep plotters = \"0.3.6\"  use ndarray::{array, Array2, Axis, Ix2, s}; use moors::{     impl_constraints_fn,     algorithms::IbeaBuilder,     duplicates::CloseDuplicatesCleaner,     operators::{         GaussianMutation, RandomSamplingFloat, SimulatedBinaryCrossover,         survival::moo::IbeaHyperVolumeSurvivalOperator,     },     genetic::Population }; use plotters::prelude::*;   // ============================== // EXPO2 \u2014 Objective Evaluation // ============================== fn evaluate_expo2(genes: &amp;Array2) -&gt; Array2 {     /// EXPO2 (minimization, 2 objectives).     ///     /// g(x) = 1 + (9/(n-1)) * sum_{i=2..n} x_i     /// f1(x) = x1     /// f2(x) = g(x) * exp( -5 * x1 / g(x) )     ///     /// Typical domain: x_i in [0, 1], i=1..n (e.g., n = 30).     let n = genes.nrows();     let m = genes.ncols();     if m &lt; 2 {         panic!(\"EXPO2 requires at least 2 decision variables.\");     }      // g(x)     let tail = genes.slice(s![.., 1..]);     let sums = tail.sum_axis(Axis(1));     let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);      let f1 = genes.column(0).to_owned();     let f2 = g.iter().zip(f1.iter()).map(|(gi, &amp;f1i)| gi * (-5.0 * f1i / gi).exp()).collect::&gt;();      let mut result = Array2::::zeros((n, 2));     result.column_mut(0).assign(&amp;f1);     result.column_mut(1).assign(&amp;Array2::from_shape_vec((n, 1), f2).unwrap().column(0));     result }   // ========================================== // Theoretical Front (g=1 =&gt; x2..xn = 0; f2=exp(-5 f1)) // ========================================== // Returns (f1, f2) arrays of the EXPO2 Pareto front: //      f1 in [0, 1], f2 = exp(-5 f1) fn expo2_theoretical_front(num_points: usize) -&gt; (Vec, Vec) {     let mut f1_theo = Vec::with_capacity(num_points);     let mut f2_theo = Vec::with_capacity(num_points);     for i in 0..num_points {         let t = if num_points &lt;= 1 { 0.0 } else { i as f64 / (num_points as f64 - 1.0) };         f1_theo.push(t);         f2_theo.push((-5.0 * t).exp());     }     (f1_theo, f2_theo) }   // ============================= // Algorithm Setup (IBEA-H) // ============================= // Problem dimensionality  impl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);  let population: Population = {     let num_vars: usize = 30;     // Hypervolume reference point (minimization \u21d2 worse-than-worst)     // We put [4.0, 4.0] far from the normalized range [0,1]     let hv_reference = array![4.0, 4.0];     // kappa controls the selection pressure in IBEA     let kappa = 0.05;     let survivor = IbeaHyperVolumeSurvivalOperator::new(hv_reference, kappa);      let mut algorithm = IbeaBuilder::default()         .sampler(RandomSamplingFloat::new(0.0, 1.0))         .crossover(SimulatedBinaryCrossover::new(15.0))         .mutation(GaussianMutation::new(0.1, 0.1))         .survivor(survivor)         .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-6))         .fitness_fn(evaluate_expo2)         .constraints_fn(BoundConstraints)         .num_vars(num_vars)         .population_size(600)         .num_offsprings(600)         .num_iterations(600)         .mutation_rate(0.2)         .crossover_rate(0.9)         .keep_infeasible(false)         .verbose(false)         .seed(1)         .build()         .expect(\"Failed to build IBEA\");      // ===============     // Run IBEA     // ===============     algorithm.run().expect(\"IBEA run failed\");     algorithm.population().unwrap().clone() };  // Best front (Population) let fitness = population.fitness; let f1_found: Vec = fitness.column(0).to_vec(); let f2_found: Vec = fitness.column(1).to_vec();  let (f1_theo, f2_theo) = expo2_theoretical_front(400);  // Plot the theoretical Pareto front, obtained front, and reference points let mut svg = String::new(); {     let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));     let root = backend.into_drawing_area();     root.fill(&amp;WHITE).unwrap();      let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);     let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);      for &amp;x in f1_theo.iter().chain(f1_found.iter()) {         if x &lt; x_min { x_min = x; }         if x &gt; x_max { x_max = x; }     }     for &amp;y in f2_theo.iter().chain(f2_found.iter()) {         if y &lt; y_min { y_min = y; }         if y &gt; y_max { y_max = y; }     }      let xr = (x_max - x_min).max(1e-9);     let yr = (y_max - y_min).max(1e-9);     x_min -= xr * 0.05;     x_max += xr * 0.05;     y_min -= yr * 0.05;     y_max += yr * 0.05;      let mut chart = ChartBuilder::on(&amp;root)         .caption(\"EXPO2 Pareto Front: Theoretical vs Obtained (IBEA HyperVolume)\", (\"DejaVu Sans\", 22))         .margin(10)         .x_label_area_size(40)         .y_label_area_size(60)         .build_cartesian_2d(x_min..x_max, y_min..y_max)         .unwrap();      chart.configure_mesh()         .x_desc(\"f1\")         .y_desc(\"f2\")         .axis_desc_style((\"DejaVu Sans\", 14))         .light_line_style(&amp;RGBColor(220, 220, 220))         .draw()         .unwrap();      chart.draw_series(         f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {             Circle::new((x, y), 2, RGBColor(31, 119, 180).filled())         })     ).unwrap()      .label(\"Theoretical Pareto Front\")      .legend(|(x, y)| Circle::new((x, y), 4, RGBColor(31, 119, 180).filled()));      chart.draw_series(         f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {             Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())         })     ).unwrap()      .label(\"Obtained Front\")      .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));      chart.configure_series_labels()         .border_style(&amp;RGBAColor(0, 0, 0, 0.3))         .background_style(&amp;WHITE.mix(0.9))         .label_font((\"DejaVu Sans\", 13))         .draw()         .unwrap();      root.present().unwrap(); }  println!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg); Out[6]:"},{"location":"user_guide/algorithms/rust/notebooks/nsga2.html","title":"Nsga2","text":"In\u00a0[7]: Copied! <pre>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::Nsga2Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, RandomSamplingFloat, ExponentialCrossover},\n    genetic::Population\n};\nuse plotters::prelude::*;\n\n/// Evaluate the ZDT3 objectives in a fully vectorized manner.\nfn evaluate_zdt3(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    // First objective: f1 is simply the first column.\n    // NOTE: We clamp to [0,1] during evaluation to keep the domain consistent with ZDT3.\n    // This mirrors the Python setup where variables are constrained to [0,1].\n    let n = genes.nrows();\n    let m = genes.ncols();\n\n    let clamped = genes.mapv(|v| v.clamp(0.0, 1.0));\n    let f1 = clamped.column(0).to_owned();\n\n    // Compute g for each candidate: g = 1 + (9/(n-1)) * sum(x[1:])\n    let tail = clamped.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);\n\n    // Compute h for each candidate: h = 1 - sqrt(f1/g) - (f1/g)*sin(10*pi*f1)\n    let ratio = &amp;f1 / &amp;g;\n    let sin_term = f1.mapv(|v| (10.0 * std::f64::consts::PI * v).sin());\n    let h = 1.0 - ratio.mapv(|r| r.sqrt()) - &amp;(&amp;ratio * &amp;sin_term);\n\n    // Compute the second objective: f2 = g * h\n    let f2 = &amp;g * &amp;h;\n\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result\n}\n\n// Create constraints using the macro impl_constraints_fn\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\n\n/// Compute the theoretical Pareto front for ZDT3.\n///\n/// Returns:\n///     f1_theo (np.ndarray): f1 values on the theoretical front.\n///     f2_theo (np.ndarray): Corresponding f2 values.\n///\n/// Instead of using a dense linspace, we sample only a few points per interval to\n/// clearly illustrate the discontinuous nature of the front.\nfn zdt3_theoretical_front() -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    // Define the intervals for f1 where the Pareto front exists\n    let intervals: &amp;[(f64, f64)] = &amp;[\n        (0.0, 0.0830015349),\n        (0.1822287280, 0.2577623634),\n        (0.4093136748, 0.4538828821),\n        (0.6183967944, 0.6525117038),\n        (0.8233317983, 0.85518),\n    ];\n\n    let mut f1_theo: Vec&lt;f64&gt; = Vec::new();\n    let mut f2_theo: Vec&lt;f64&gt; = Vec::new();\n\n    // Use a small number of points per interval (e.g., 20) to highlight the discontinuities.\n    for (start, end) in intervals.iter().copied() {\n        let steps = 20usize;\n        for i in 0..steps {\n            let t = i as f64 / (steps as f64 - 1.0);\n            let f1 = start + t * (end - start);\n            let f2 = 1.0 - f1.sqrt() - f1 * (10.0 * std::f64::consts::PI * f1).sin();\n            f1_theo.push(f1);\n            f2_theo.push(f2);\n        }\n    }\n\n    (f1_theo, f2_theo)\n}\n\n// Set up the NSGA2 algorithm with the above definitions\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let mut algorithm = Nsga2Builder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(ExponentialCrossover::new(0.75))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-5))\n        .fitness_fn(evaluate_zdt3)\n        .constraints_fn(BoundConstraints)\n        .num_vars(30)\n        .population_size(200)\n        .num_offsprings(200)\n        .num_iterations(300)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(42)\n        .build()\n        .expect(\"Failed to build NSGA2\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"NSGA2 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// Compute the theoretical Pareto front for ZDT3\nlet (f1_theo, f2_theo) = zdt3_theoretical_front();\n\n// Plot the theoretical Pareto front and the obtained front\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    // Compute min/max from actual data\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n    \n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n    \n    // Add a small margin (5%)\n    let xr = (x_max - x_min);\n    let yr = (y_max - y_min);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"ZDT3 Pareto Front: Theoretical vs Obtained\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    // Plot theoretical front as markers (e.g., diamonds) to show discontinuities.\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));\n\n    // Plot obtained front as red circles.\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\n// Emit as rich output for evcxr\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</pre> :dep ndarray = \"*\" :dep moors = \"*\" :dep plotters = \"0.3.6\"  use ndarray::{Array2, Axis, Ix2, s}; use moors::{     impl_constraints_fn,     algorithms::Nsga2Builder,     duplicates::CloseDuplicatesCleaner,     operators::{GaussianMutation, RandomSamplingFloat, ExponentialCrossover},     genetic::Population }; use plotters::prelude::*;  /// Evaluate the ZDT3 objectives in a fully vectorized manner. fn evaluate_zdt3(genes: &amp;Array2) -&gt; Array2 {     // First objective: f1 is simply the first column.     // NOTE: We clamp to [0,1] during evaluation to keep the domain consistent with ZDT3.     // This mirrors the Python setup where variables are constrained to [0,1].     let n = genes.nrows();     let m = genes.ncols();      let clamped = genes.mapv(|v| v.clamp(0.0, 1.0));     let f1 = clamped.column(0).to_owned();      // Compute g for each candidate: g = 1 + (9/(n-1)) * sum(x[1:])     let tail = clamped.slice(s![.., 1..]);     let sums = tail.sum_axis(Axis(1));     let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);      // Compute h for each candidate: h = 1 - sqrt(f1/g) - (f1/g)*sin(10*pi*f1)     let ratio = &amp;f1 / &amp;g     let sin_term = f1.mapv(|v| (10.0 * std::f64::consts::PI * v).sin());     let h = 1.0 - ratio.mapv(|r| r.sqrt()) - &amp;(\u2236 * &amp;sin_term);      // Compute the second objective: f2 = g * h     let f2 = &amp;g * &amp;h      let mut result = Array2::::zeros((n, 2));     result.column_mut(0).assign(&amp;f1);     result.column_mut(1).assign(&amp;f2);     result }  // Create constraints using the macro impl_constraints_fn impl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);   /// Compute the theoretical Pareto front for ZDT3. /// /// Returns: ///     f1_theo (np.ndarray): f1 values on the theoretical front. ///     f2_theo (np.ndarray): Corresponding f2 values. /// /// Instead of using a dense linspace, we sample only a few points per interval to /// clearly illustrate the discontinuous nature of the front. fn zdt3_theoretical_front() -&gt; (Vec, Vec) {     // Define the intervals for f1 where the Pareto front exists     let intervals: &amp;[(f64, f64)] = &amp;[         (0.0, 0.0830015349),         (0.1822287280, 0.2577623634),         (0.4093136748, 0.4538828821),         (0.6183967944, 0.6525117038),         (0.8233317983, 0.85518),     ];      let mut f1_theo: Vec = Vec::new();     let mut f2_theo: Vec = Vec::new();      // Use a small number of points per interval (e.g., 20) to highlight the discontinuities.     for (start, end) in intervals.iter().copied() {         let steps = 20usize;         for i in 0..steps {             let t = i as f64 / (steps as f64 - 1.0);             let f1 = start + t * (end - start);             let f2 = 1.0 - f1.sqrt() - f1 * (10.0 * std::f64::consts::PI * f1).sin();             f1_theo.push(f1);             f2_theo.push(f2);         }     }      (f1_theo, f2_theo) }  // Set up the NSGA2 algorithm with the above definitions let population: Population = {     let mut algorithm = Nsga2Builder::default()         .sampler(RandomSamplingFloat::new(0.0, 1.0))         .crossover(ExponentialCrossover::new(0.75))         .mutation(GaussianMutation::new(0.1, 0.01))         .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-5))         .fitness_fn(evaluate_zdt3)         .constraints_fn(BoundConstraints)         .num_vars(30)         .population_size(200)         .num_offsprings(200)         .num_iterations(300)         .mutation_rate(0.1)         .crossover_rate(0.9)         .keep_infeasible(false)         .verbose(false)         .seed(42)         .build()         .expect(\"Failed to build NSGA2\");      // Run the algorithm     algorithm.run().expect(\"NSGA2 run failed\");     algorithm.population().unwrap().clone() };  // Get the best Pareto front obtained (as a Population instance) let fitness = population.fitness;  // Extract the obtained fitness values (each row is [f1, f2]) let f1_found: Vec = fitness.column(0).to_vec(); let f2_found: Vec = fitness.column(1).to_vec();  // Compute the theoretical Pareto front for ZDT3 let (f1_theo, f2_theo) = zdt3_theoretical_front();  // Plot the theoretical Pareto front and the obtained front let mut svg = String::new(); {     let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));     let root = backend.into_drawing_area();     root.fill(&amp;WHITE).unwrap();      // Compute min/max from actual data     let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);     let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);          for &amp;x in f1_theo.iter().chain(f1_found.iter()) {         if x &lt; x_min { x_min = x; }         if x &gt; x_max { x_max = x; }     }     for &amp;y in f2_theo.iter().chain(f2_found.iter()) {         if y &lt; y_min { y_min = y; }         if y &gt; y_max { y_max = y; }     }          // Add a small margin (5%)     let xr = (x_max - x_min);     let yr = (y_max - y_min);     x_min -= xr * 0.05;     x_max += xr * 0.05;     y_min -= yr * 0.05;     y_max += yr * 0.05;      let mut chart = ChartBuilder::on(&amp;root)         .caption(\"ZDT3 Pareto Front: Theoretical vs Obtained\", (\"DejaVu Sans\", 22))         .margin(10)         .x_label_area_size(40)         .y_label_area_size(60)         .build_cartesian_2d(x_min..x_max, y_min..y_max)         .unwrap();      chart.configure_mesh()         .x_desc(\"f1\")         .y_desc(\"f2\")         .axis_desc_style((\"DejaVu Sans\", 14))         .light_line_style(&amp;RGBColor(220, 220, 220))         .draw()         .unwrap();      // Plot theoretical front as markers (e.g., diamonds) to show discontinuities.     chart.draw_series(         f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {             Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())         })     ).unwrap()      .label(\"Theoretical Pareto Front\")      .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));      // Plot obtained front as red circles.     chart.draw_series(         f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {             Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())         })     ).unwrap()      .label(\"Obtained Front\")      .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));      chart.configure_series_labels()         .border_style(&amp;RGBAColor(0, 0, 0, 0.3))         .background_style(&amp;WHITE.mix(0.9))         .label_font((\"DejaVu Sans\", 13))         .draw()         .unwrap();      root.present().unwrap(); }  // Emit as rich output for evcxr println!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);  Out[7]: In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"user_guide/algorithms/rust/notebooks/nsga3.html","title":"Nsga3","text":"In\u00a0[19]: Copied! <pre>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotly = \"*\"\n\nuse ndarray::{Array1, Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::Nsga3Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{\n        GaussianMutation,\n        RandomSamplingFloat,\n        SimulatedBinaryCrossover,\n        Nsga3ReferencePointsSurvival,\n        Nsga3ReferencePoints,\n        DanAndDenisReferencePoints,\n        StructuredReferencePoints\n    },\n    genetic::Population,\n};\n\nuse plotly::{Plot, Scatter3D, Layout, Trace};\nuse plotly::common::{Mode, Marker, Title, MarkerSymbol};\nuse plotly::color::NamedColor;\nuse plotly::layout::{LayoutScene as Scene, Axis as PlotlyAxis};\n\n\n/// Evaluate the DTLZ2 objectives for a 3-objective problem.\n///\n/// The decision vector x has num_vars components. For the Pareto front,\n/// the auxiliary function g(x) is minimized (g(x)=0) by setting the last\n/// num_vars-2 variables to 0.5.\n///\n/// The objectives are computed as:\n///   f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2)\n///   f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2)\n///   f3(x) = (1+g) * sin((pi/2)*x1)\nfn evaluate_dtlz2(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let n = genes.nrows();\n    let pi_over_2 = std::f64::consts::PI / 2.0;\n\n    // Compute the auxiliary function g(x) using variables 3 to num_vars.\n    let tail = genes.slice(s![.., 2..]).to_owned();\n    let g_vec: Array1&lt;f64&gt; = tail.mapv(|v| (v - 0.5).powi(2)).sum_axis(Axis(1));\n\n    // x1, x2\n    let x1 = genes.column(0).to_owned();\n    let x2 = genes.column(1).to_owned();\n\n    // Trig terms\n    let cos_x1 = x1.mapv(|v| (pi_over_2 * v).cos());\n    let cos_x2 = x2.mapv(|v| (pi_over_2 * v).cos());\n    let sin_x1 = x1.mapv(|v| (pi_over_2 * v).sin());\n    let sin_x2 = x2.mapv(|v| (pi_over_2 * v).sin());\n\n    let one_plus_g = g_vec.mapv(|g| 1.0 + g);\n\n    // f1, f2, f3 as Array1\n    let f1 = &amp;one_plus_g * &amp;cos_x1 * &amp;cos_x2;\n    let f2 = &amp;one_plus_g * &amp;cos_x1 * &amp;sin_x2;\n    let f3 = &amp;one_plus_g * &amp;sin_x1;\n\n    // Stack into (n, 3)\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 3));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result.column_mut(2).assign(&amp;f3);\n    result\n}\n\n/// Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives).\n///\n/// For the Pareto-optimal front, g(x) = 0, which implies that the decision variables\n/// x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2:\n///   f1 = cos((pi/2)*x1) * cos((pi/2)*x2)\n///   f2 = cos((pi/2)*x1) * sin((pi/2)*x2)\n///   f3 = sin((pi/2)*x1)\n/// These points lie on a portion of the unit hypersphere in the positive orthant.\nfn dtlz2_theoretical_front(num_points: usize) -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let pi_over_2 = std::f64::consts::PI / 2.0;\n\n    let mut f1_all = Vec::with_capacity(num_points * num_points);\n    let mut f2_all = Vec::with_capacity(num_points * num_points);\n    let mut f3_all = Vec::with_capacity(num_points * num_points);\n\n    for i in 0..num_points {\n        let x1 = if num_points &gt; 1 {\n            i as f64 / (num_points as f64 - 1.0)\n        } else {\n            0.0\n        };\n        for j in 0..num_points {\n            let x2 = if num_points &gt; 1 {\n                j as f64 / (num_points as f64 - 1.0)\n            } else {\n                0.0\n            };\n\n            let f1 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).cos();\n            let f2 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).sin();\n            let f3 = (pi_over_2 * x1).sin();\n\n            f1_all.push(f1);\n            f2_all.push(f2);\n            f3_all.push(f3);\n        }\n    }\n\n    (f1_all, f2_all, f3_all)\n}\n\n// Set up the NSGA-III algorithm for DTLZ2.\n// For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k.\n// Here, we choose k = 10, so num_vars = 2 + 10 = 12.\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\n\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let rp = DanAndDenisReferencePoints::new(100, 3).generate();\n    let nsga3_rp = Nsga3ReferencePoints::new(rp, false);\n    let survivor = Nsga3ReferencePointsSurvival::new(nsga3_rp);\n    let mut algorithm = Nsga3Builder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(SimulatedBinaryCrossover::new(10.0)) // distribution_index = 10\n        .mutation(GaussianMutation::new(0.1, 0.01))     // gene_mutation_rate = 0.1, sigma = 0.01\n        .survivor(survivor)\n        .fitness_fn(evaluate_dtlz2)\n        .constraints_fn(BoundConstraints)\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))\n        .num_vars(12)\n        .population_size(500)\n        .num_offsprings(500)\n        .num_iterations(700)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(1729)\n        .build()\n        .expect(\"Failed to build NSGA3\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"NSGA3 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Define again rp just for plotting\nlet rp_plot: Array2&lt;f64&gt; = DanAndDenisReferencePoints::new(100, 3).generate();\nlet rp_f1: Vec&lt;f64&gt; = rp_plot.column(0).to_vec();\nlet rp_f2: Vec&lt;f64&gt; = rp_plot.column(1).to_vec();\nlet rp_f3: Vec&lt;f64&gt; = rp_plot.column(2).to_vec();\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2, f3])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\nlet f3_found: Vec&lt;f64&gt; = fitness.column(2).to_vec();\n\n// Compute the theoretical Pareto front for DTLZ2 (dense grid on the positive octant of the unit sphere)\nlet (f1_theo, f2_theo, f3_theo) = dtlz2_theoretical_front(50);\n\n// Build Plotly traces for 3D scatter (theoretical vs obtained)\nlet theoretical_trace = Scatter3D::new(f1_theo.clone(), f2_theo.clone(), f3_theo.clone())\n    .mode(Mode::Markers)\n    .name(\"Theoretical Pareto Front\")\n    .marker(Marker::new().size(3).color(NamedColor::Black).opacity(0.5));\n\nlet obtained_trace = Scatter3D::new(f1_found.clone(), f2_found.clone(), f3_found.clone())\n    .mode(Mode::Markers)\n    .name(\"Obtained Front\")\n    .marker(Marker::new().size(5).color(NamedColor::Red));\n\nlet refpoints_trace = Scatter3D::new(rp_f1, rp_f2, rp_f3)\n    .mode(Mode::Markers)\n    .name(\"Reference Points\")\n    .marker(\n        Marker::new()\n            .size(8)\n            .color(NamedColor::Magenta)\n            .symbol(MarkerSymbol::Star)\n    );\n\n// Layout con Title builder y PlotlyAxis (alias para evitar conflicto con ndarray::Axis)\nlet layout: Layout = Layout::new()\n    .width(800)\n    .height(600)\n    .title(Title::from(\"DTLZ2 Pareto Front: Theoretical vs Obtained (NSGA-III)\"))\n    .scene(\n        Scene::new()\n            .x_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;1&lt;/sub&gt;\")))\n            .y_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;2&lt;/sub&gt;\")))\n            .z_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;3&lt;/sub&gt;\")))\n        // .aspect_mode(plotly::layout::scene::AspectMode::Cube) // opcional\n    );\n\n// Compose the plot\nlet mut plot = Plot::new();\nplot.add_trace(theoretical_trace);\nplot.add_trace(obtained_trace);\nplot.add_trace(refpoints_trace);\nplot.set_layout(layout);\n\n// Render as rich HTML for evcxr\nlet html = plot.to_html();\nprintln!(\"EVCXR_BEGIN_CONTENT text/html\\n{}\\nEVCXR_END_CONTENT\", html);\n</pre> :dep ndarray = \"*\" :dep moors = \"*\" :dep plotly = \"*\"  use ndarray::{Array1, Array2, Axis, Ix2, s}; use moors::{     impl_constraints_fn,     algorithms::Nsga3Builder,     duplicates::CloseDuplicatesCleaner,     operators::{         GaussianMutation,         RandomSamplingFloat,         SimulatedBinaryCrossover,         Nsga3ReferencePointsSurvival,         Nsga3ReferencePoints,         DanAndDenisReferencePoints,         StructuredReferencePoints     },     genetic::Population, };  use plotly::{Plot, Scatter3D, Layout, Trace}; use plotly::common::{Mode, Marker, Title, MarkerSymbol}; use plotly::color::NamedColor; use plotly::layout::{LayoutScene as Scene, Axis as PlotlyAxis};   /// Evaluate the DTLZ2 objectives for a 3-objective problem. /// /// The decision vector x has num_vars components. For the Pareto front, /// the auxiliary function g(x) is minimized (g(x)=0) by setting the last /// num_vars-2 variables to 0.5. /// /// The objectives are computed as: ///   f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2) ///   f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2) ///   f3(x) = (1+g) * sin((pi/2)*x1) fn evaluate_dtlz2(genes: &amp;Array2) -&gt; Array2 {     let n = genes.nrows();     let pi_over_2 = std::f64::consts::PI / 2.0;      // Compute the auxiliary function g(x) using variables 3 to num_vars.     let tail = genes.slice(s![.., 2..]).to_owned();     let g_vec: Array1 = tail.mapv(|v| (v - 0.5).powi(2)).sum_axis(Axis(1));      // x1, x2     let x1 = genes.column(0).to_owned();     let x2 = genes.column(1).to_owned();      // Trig terms     let cos_x1 = x1.mapv(|v| (pi_over_2 * v).cos());     let cos_x2 = x2.mapv(|v| (pi_over_2 * v).cos());     let sin_x1 = x1.mapv(|v| (pi_over_2 * v).sin());     let sin_x2 = x2.mapv(|v| (pi_over_2 * v).sin());      let one_plus_g = g_vec.mapv(|g| 1.0 + g);      // f1, f2, f3 as Array1     let f1 = &amp;one_plus_g * &amp;cos_x1 * &amp;cos_x2;     let f2 = &amp;one_plus_g * &amp;cos_x1 * &amp;sin_x2;     let f3 = &amp;one_plus_g * &amp;sin_x1;      // Stack into (n, 3)     let mut result = Array2::::zeros((n, 3));     result.column_mut(0).assign(&amp;f1);     result.column_mut(1).assign(&amp;f2);     result.column_mut(2).assign(&amp;f3);     result }  /// Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives). /// /// For the Pareto-optimal front, g(x) = 0, which implies that the decision variables /// x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2: ///   f1 = cos((pi/2)*x1) * cos((pi/2)*x2) ///   f2 = cos((pi/2)*x1) * sin((pi/2)*x2) ///   f3 = sin((pi/2)*x1) /// These points lie on a portion of the unit hypersphere in the positive orthant. fn dtlz2_theoretical_front(num_points: usize) -&gt; (Vec, Vec, Vec) {     let pi_over_2 = std::f64::consts::PI / 2.0;      let mut f1_all = Vec::with_capacity(num_points * num_points);     let mut f2_all = Vec::with_capacity(num_points * num_points);     let mut f3_all = Vec::with_capacity(num_points * num_points);      for i in 0..num_points {         let x1 = if num_points &gt; 1 {             i as f64 / (num_points as f64 - 1.0)         } else {             0.0         };         for j in 0..num_points {             let x2 = if num_points &gt; 1 {                 j as f64 / (num_points as f64 - 1.0)             } else {                 0.0             };              let f1 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).cos();             let f2 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).sin();             let f3 = (pi_over_2 * x1).sin();              f1_all.push(f1);             f2_all.push(f2);             f3_all.push(f3);         }     }      (f1_all, f2_all, f3_all) }  // Set up the NSGA-III algorithm for DTLZ2. // For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k. // Here, we choose k = 10, so num_vars = 2 + 10 = 12. impl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);   let population: Population = {     let rp = DanAndDenisReferencePoints::new(100, 3).generate();     let nsga3_rp = Nsga3ReferencePoints::new(rp, false);     let survivor = Nsga3ReferencePointsSurvival::new(nsga3_rp);     let mut algorithm = Nsga3Builder::default()         .sampler(RandomSamplingFloat::new(0.0, 1.0))         .crossover(SimulatedBinaryCrossover::new(10.0)) // distribution_index = 10         .mutation(GaussianMutation::new(0.1, 0.01))     // gene_mutation_rate = 0.1, sigma = 0.01         .survivor(survivor)         .fitness_fn(evaluate_dtlz2)         .constraints_fn(BoundConstraints)         .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))         .num_vars(12)         .population_size(500)         .num_offsprings(500)         .num_iterations(700)         .mutation_rate(0.1)         .crossover_rate(0.9)         .keep_infeasible(false)         .verbose(false)         .seed(1729)         .build()         .expect(\"Failed to build NSGA3\");      // Run the algorithm     algorithm.run().expect(\"NSGA3 run failed\");     algorithm.population().unwrap().clone() };  // Define again rp just for plotting let rp_plot: Array2 = DanAndDenisReferencePoints::new(100, 3).generate(); let rp_f1: Vec = rp_plot.column(0).to_vec(); let rp_f2: Vec = rp_plot.column(1).to_vec(); let rp_f3: Vec = rp_plot.column(2).to_vec();  // Get the best Pareto front obtained (as a Population instance) let fitness = population.fitness;  // Extract the obtained fitness values (each row is [f1, f2, f3]) let f1_found: Vec = fitness.column(0).to_vec(); let f2_found: Vec = fitness.column(1).to_vec(); let f3_found: Vec = fitness.column(2).to_vec();  // Compute the theoretical Pareto front for DTLZ2 (dense grid on the positive octant of the unit sphere) let (f1_theo, f2_theo, f3_theo) = dtlz2_theoretical_front(50);  // Build Plotly traces for 3D scatter (theoretical vs obtained) let theoretical_trace = Scatter3D::new(f1_theo.clone(), f2_theo.clone(), f3_theo.clone())     .mode(Mode::Markers)     .name(\"Theoretical Pareto Front\")     .marker(Marker::new().size(3).color(NamedColor::Black).opacity(0.5));  let obtained_trace = Scatter3D::new(f1_found.clone(), f2_found.clone(), f3_found.clone())     .mode(Mode::Markers)     .name(\"Obtained Front\")     .marker(Marker::new().size(5).color(NamedColor::Red));  let refpoints_trace = Scatter3D::new(rp_f1, rp_f2, rp_f3)     .mode(Mode::Markers)     .name(\"Reference Points\")     .marker(         Marker::new()             .size(8)             .color(NamedColor::Magenta)             .symbol(MarkerSymbol::Star)     );  // Layout con Title builder y PlotlyAxis (alias para evitar conflicto con ndarray::Axis) let layout: Layout = Layout::new()     .width(800)     .height(600)     .title(Title::from(\"DTLZ2 Pareto Front: Theoretical vs Obtained (NSGA-III)\"))     .scene(         Scene::new()             .x_axis(PlotlyAxis::new().title(Title::from(\"f<sub>1</sub>\")))             .y_axis(PlotlyAxis::new().title(Title::from(\"f<sub>2</sub>\")))             .z_axis(PlotlyAxis::new().title(Title::from(\"f<sub>3</sub>\")))         // .aspect_mode(plotly::layout::scene::AspectMode::Cube) // opcional     );  // Compose the plot let mut plot = Plot::new(); plot.add_trace(theoretical_trace); plot.add_trace(obtained_trace); plot.add_trace(refpoints_trace); plot.set_layout(layout);  // Render as rich HTML for evcxr let html = plot.to_html(); println!(\"EVCXR_BEGIN_CONTENT text/html\\n{}\\nEVCXR_END_CONTENT\", html);  Out[19]:"},{"location":"user_guide/algorithms/rust/notebooks/revea.html","title":"Revea","text":"In\u00a0[6]: Copied! <pre>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotly = \"*\"\n\nuse ndarray::{Array1, Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::ReveaBuilder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{\n        GaussianMutation,\n        RandomSamplingFloat,\n        SimulatedBinaryCrossover,\n        DanAndDenisReferencePoints,\n        StructuredReferencePoints,\n        ReveaReferencePointsSurvival\n    },\n    genetic::Population,\n};\n\nuse plotly::{Plot, Scatter3D, Layout, Trace};\nuse plotly::common::{Mode, Marker, Title, MarkerSymbol};\nuse plotly::color::NamedColor;\nuse plotly::layout::{LayoutScene as Scene, Axis as PlotlyAxis};\n\n\n/// Evaluate the DTLZ2 objectives for a 3-objective problem.\n///\n/// The decision vector x has num_vars components. For the Pareto front,\n/// the auxiliary function g(x) is minimized (g(x)=0) by setting the last\n/// num_vars-2 variables to 0.5.\n///\n/// The objectives are computed as:\n///   f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2)\n///   f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2)\n///   f3(x) = (1+g) * sin((pi/2)*x1)\nfn evaluate_dtlz2(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let n = genes.nrows();\n    let pi_over_2 = std::f64::consts::PI / 2.0;\n\n    // Compute the auxiliary function g(x) using variables 3 to num_vars.\n    let tail = genes.slice(s![.., 2..]).to_owned();\n    let g_vec: Array1&lt;f64&gt; = tail.mapv(|v| (v - 0.5).powi(2)).sum_axis(Axis(1));\n\n    // x1, x2\n    let x1 = genes.column(0).to_owned();\n    let x2 = genes.column(1).to_owned();\n\n    // Trig terms\n    let cos_x1 = x1.mapv(|v| (pi_over_2 * v).cos());\n    let cos_x2 = x2.mapv(|v| (pi_over_2 * v).cos());\n    let sin_x1 = x1.mapv(|v| (pi_over_2 * v).sin());\n    let sin_x2 = x2.mapv(|v| (pi_over_2 * v).sin());\n\n    let one_plus_g = g_vec.mapv(|g| 1.0 + g);\n\n    // f1, f2, f3 as Array1\n    let f1 = &amp;one_plus_g * &amp;cos_x1 * &amp;cos_x2;\n    let f2 = &amp;one_plus_g * &amp;cos_x1 * &amp;sin_x2;\n    let f3 = &amp;one_plus_g * &amp;sin_x1;\n\n    // Stack into (n, 3)\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 3));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result.column_mut(2).assign(&amp;f3);\n    result\n}\n\n/// Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives).\n///\n/// For the Pareto-optimal front, g(x) = 0, which implies that the decision variables\n/// x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2:\n///   f1 = cos((pi/2)*x1) * cos((pi/2)*x2)\n///   f2 = cos((pi/2)*x1) * sin((pi/2)*x2)\n///   f3 = sin((pi/2)*x1)\n/// These points lie on a portion of the unit hypersphere in the positive orthant.\nfn dtlz2_theoretical_front(num_points: usize) -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let pi_over_2 = std::f64::consts::PI / 2.0;\n\n    let mut f1_all = Vec::with_capacity(num_points * num_points);\n    let mut f2_all = Vec::with_capacity(num_points * num_points);\n    let mut f3_all = Vec::with_capacity(num_points * num_points);\n\n    for i in 0..num_points {\n        let x1 = if num_points &gt; 1 {\n            i as f64 / (num_points as f64 - 1.0)\n        } else {\n            0.0\n        };\n        for j in 0..num_points {\n            let x2 = if num_points &gt; 1 {\n                j as f64 / (num_points as f64 - 1.0)\n            } else {\n                0.0\n            };\n\n            let f1 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).cos();\n            let f2 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).sin();\n            let f3 = (pi_over_2 * x1).sin();\n\n            f1_all.push(f1);\n            f2_all.push(f2);\n            f3_all.push(f3);\n        }\n    }\n\n    (f1_all, f2_all, f3_all)\n}\n\n// Set up the REVEA algorithm for DTLZ2.\n// For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k.\n// Here, we choose k = 10, so num_vars = 2 + 10 = 12.\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let num_iterations = 600;\n    let rp = DanAndDenisReferencePoints::new(101, 3).generate();\n    let alpha = 2.5;\n    let frequency = 0.2;\n    let survivor = ReveaReferencePointsSurvival::new(rp, alpha, frequency, num_iterations);\n    \n    let mut algorithm = ReveaBuilder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(SimulatedBinaryCrossover::new(10.0)) // distribution_index = 10\n        .mutation(GaussianMutation::new(0.1, 0.01))     // gene_mutation_rate = 0.1, sigma = 0.01\n        .survivor(survivor)\n        .fitness_fn(evaluate_dtlz2)\n        .constraints_fn(BoundConstraints)\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))\n        .num_vars(12)\n        .population_size(200)\n        .num_offsprings(200)\n        .num_iterations(num_iterations)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(1729)\n        .build()\n        .expect(\"Failed to build REVEA\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"REVEA run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Define again rp just for plotting\nlet rp_plot: Array2&lt;f64&gt; = DanAndDenisReferencePoints::new(100, 3).generate();\nlet rp_f1: Vec&lt;f64&gt; = rp_plot.column(0).to_vec();\nlet rp_f2: Vec&lt;f64&gt; = rp_plot.column(1).to_vec();\nlet rp_f3: Vec&lt;f64&gt; = rp_plot.column(2).to_vec();\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2, f3])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\nlet f3_found: Vec&lt;f64&gt; = fitness.column(2).to_vec();\n\n// Compute the theoretical Pareto front for DTLZ2 (dense grid on the positive octant of the unit sphere)\nlet (f1_theo, f2_theo, f3_theo) = dtlz2_theoretical_front(50);\n\n// Build Plotly traces for 3D scatter (theoretical vs obtained)\nlet theoretical_trace = Scatter3D::new(f1_theo.clone(), f2_theo.clone(), f3_theo.clone())\n    .mode(Mode::Markers)\n    .name(\"Theoretical Pareto Front\")\n    .marker(Marker::new().size(3).color(NamedColor::Black).opacity(0.5));\n\nlet obtained_trace = Scatter3D::new(f1_found.clone(), f2_found.clone(), f3_found.clone())\n    .mode(Mode::Markers)\n    .name(\"Obtained Front (REVEA)\")\n    .marker(Marker::new().size(5).color(NamedColor::Red));\n\nlet refpoints_trace = Scatter3D::new(rp_f1, rp_f2, rp_f3)\n    .mode(Mode::Markers)\n    .name(\"Reference Points\")\n    .marker(\n        Marker::new()\n            .size(8)\n            .color(NamedColor::Magenta)\n            .symbol(MarkerSymbol::Star)\n    );\n\n// Layout con Title builder y PlotlyAxis (alias para evitar conflicto con ndarray::Axis)\nlet layout: Layout = Layout::new()\n    .width(800)\n    .height(600)\n    .title(Title::from(\"DTLZ2 Pareto Front: Theoretical vs Obtained (REVEA)\"))\n    .scene(\n        Scene::new()\n            .x_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;1&lt;/sub&gt;\")))\n            .y_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;2&lt;/sub&gt;\")))\n            .z_axis(PlotlyAxis::new().title(Title::from(\"f&lt;sub&gt;3&lt;/sub&gt;\")))\n        // .aspect_mode(plotly::layout::scene::AspectMode::Cube) // optional\n    );\n\n// Compose the plot\nlet mut plot = Plot::new();\nplot.add_trace(theoretical_trace);\nplot.add_trace(obtained_trace);\nplot.add_trace(refpoints_trace);\nplot.set_layout(layout);\n\n// Render as rich HTML for evcxr\nlet html = plot.to_html();\nprintln!(\"EVCXR_BEGIN_CONTENT text/html\\n{}\\nEVCXR_END_CONTENT\", html);\n</pre> :dep ndarray = \"*\" :dep moors = \"*\" :dep plotly = \"*\"  use ndarray::{Array1, Array2, Axis, Ix2, s}; use moors::{     impl_constraints_fn,     algorithms::ReveaBuilder,     duplicates::CloseDuplicatesCleaner,     operators::{         GaussianMutation,         RandomSamplingFloat,         SimulatedBinaryCrossover,         DanAndDenisReferencePoints,         StructuredReferencePoints,         ReveaReferencePointsSurvival     },     genetic::Population, };  use plotly::{Plot, Scatter3D, Layout, Trace}; use plotly::common::{Mode, Marker, Title, MarkerSymbol}; use plotly::color::NamedColor; use plotly::layout::{LayoutScene as Scene, Axis as PlotlyAxis};   /// Evaluate the DTLZ2 objectives for a 3-objective problem. /// /// The decision vector x has num_vars components. For the Pareto front, /// the auxiliary function g(x) is minimized (g(x)=0) by setting the last /// num_vars-2 variables to 0.5. /// /// The objectives are computed as: ///   f1(x) = (1+g) * cos((pi/2)*x1) * cos((pi/2)*x2) ///   f2(x) = (1+g) * cos((pi/2)*x1) * sin((pi/2)*x2) ///   f3(x) = (1+g) * sin((pi/2)*x1) fn evaluate_dtlz2(genes: &amp;Array2) -&gt; Array2 {     let n = genes.nrows();     let pi_over_2 = std::f64::consts::PI / 2.0;      // Compute the auxiliary function g(x) using variables 3 to num_vars.     let tail = genes.slice(s![.., 2..]).to_owned();     let g_vec: Array1 = tail.mapv(|v| (v - 0.5).powi(2)).sum_axis(Axis(1));      // x1, x2     let x1 = genes.column(0).to_owned();     let x2 = genes.column(1).to_owned();      // Trig terms     let cos_x1 = x1.mapv(|v| (pi_over_2 * v).cos());     let cos_x2 = x2.mapv(|v| (pi_over_2 * v).cos());     let sin_x1 = x1.mapv(|v| (pi_over_2 * v).sin());     let sin_x2 = x2.mapv(|v| (pi_over_2 * v).sin());      let one_plus_g = g_vec.mapv(|g| 1.0 + g);      // f1, f2, f3 as Array1     let f1 = &amp;one_plus_g * &amp;cos_x1 * &amp;cos_x2;     let f2 = &amp;one_plus_g * &amp;cos_x1 * &amp;sin_x2;     let f3 = &amp;one_plus_g * &amp;sin_x1;      // Stack into (n, 3)     let mut result = Array2::::zeros((n, 3));     result.column_mut(0).assign(&amp;f1);     result.column_mut(1).assign(&amp;f2);     result.column_mut(2).assign(&amp;f3);     result }  /// Compute a set of points approximating the theoretical Pareto front for DTLZ2 (3 objectives). /// /// For the Pareto-optimal front, g(x) = 0, which implies that the decision variables /// x_3, ..., x_n are fixed at 0.5. Therefore, the front can be generated by varying x1 and x2: ///   f1 = cos((pi/2)*x1) * cos((pi/2)*x2) ///   f2 = cos((pi/2)*x1) * sin((pi/2)*x2) ///   f3 = sin((pi/2)*x1) /// These points lie on a portion of the unit hypersphere in the positive orthant. fn dtlz2_theoretical_front(num_points: usize) -&gt; (Vec, Vec, Vec) {     let pi_over_2 = std::f64::consts::PI / 2.0;      let mut f1_all = Vec::with_capacity(num_points * num_points);     let mut f2_all = Vec::with_capacity(num_points * num_points);     let mut f3_all = Vec::with_capacity(num_points * num_points);      for i in 0..num_points {         let x1 = if num_points &gt; 1 {             i as f64 / (num_points as f64 - 1.0)         } else {             0.0         };         for j in 0..num_points {             let x2 = if num_points &gt; 1 {                 j as f64 / (num_points as f64 - 1.0)             } else {                 0.0             };              let f1 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).cos();             let f2 = (pi_over_2 * x1).cos() * (pi_over_2 * x2).sin();             let f3 = (pi_over_2 * x1).sin();              f1_all.push(f1);             f2_all.push(f2);             f3_all.push(f3);         }     }      (f1_all, f2_all, f3_all) }  // Set up the REVEA algorithm for DTLZ2. // For DTLZ2, a typical choice is num_vars = (number of objectives - 1) + k. // Here, we choose k = 10, so num_vars = 2 + 10 = 12. impl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);  let population: Population = {     let num_iterations = 600;     let rp = DanAndDenisReferencePoints::new(101, 3).generate();     let alpha = 2.5;     let frequency = 0.2;     let survivor = ReveaReferencePointsSurvival::new(rp, alpha, frequency, num_iterations);          let mut algorithm = ReveaBuilder::default()         .sampler(RandomSamplingFloat::new(0.0, 1.0))         .crossover(SimulatedBinaryCrossover::new(10.0)) // distribution_index = 10         .mutation(GaussianMutation::new(0.1, 0.01))     // gene_mutation_rate = 0.1, sigma = 0.01         .survivor(survivor)         .fitness_fn(evaluate_dtlz2)         .constraints_fn(BoundConstraints)         .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))         .num_vars(12)         .population_size(200)         .num_offsprings(200)         .num_iterations(num_iterations)         .mutation_rate(0.1)         .crossover_rate(0.9)         .keep_infeasible(false)         .verbose(false)         .seed(1729)         .build()         .expect(\"Failed to build REVEA\");      // Run the algorithm     algorithm.run().expect(\"REVEA run failed\");     algorithm.population().unwrap().clone() };  // Define again rp just for plotting let rp_plot: Array2 = DanAndDenisReferencePoints::new(100, 3).generate(); let rp_f1: Vec = rp_plot.column(0).to_vec(); let rp_f2: Vec = rp_plot.column(1).to_vec(); let rp_f3: Vec = rp_plot.column(2).to_vec();  // Get the best Pareto front obtained (as a Population instance) let fitness = population.fitness;  // Extract the obtained fitness values (each row is [f1, f2, f3]) let f1_found: Vec = fitness.column(0).to_vec(); let f2_found: Vec = fitness.column(1).to_vec(); let f3_found: Vec = fitness.column(2).to_vec();  // Compute the theoretical Pareto front for DTLZ2 (dense grid on the positive octant of the unit sphere) let (f1_theo, f2_theo, f3_theo) = dtlz2_theoretical_front(50);  // Build Plotly traces for 3D scatter (theoretical vs obtained) let theoretical_trace = Scatter3D::new(f1_theo.clone(), f2_theo.clone(), f3_theo.clone())     .mode(Mode::Markers)     .name(\"Theoretical Pareto Front\")     .marker(Marker::new().size(3).color(NamedColor::Black).opacity(0.5));  let obtained_trace = Scatter3D::new(f1_found.clone(), f2_found.clone(), f3_found.clone())     .mode(Mode::Markers)     .name(\"Obtained Front (REVEA)\")     .marker(Marker::new().size(5).color(NamedColor::Red));  let refpoints_trace = Scatter3D::new(rp_f1, rp_f2, rp_f3)     .mode(Mode::Markers)     .name(\"Reference Points\")     .marker(         Marker::new()             .size(8)             .color(NamedColor::Magenta)             .symbol(MarkerSymbol::Star)     );  // Layout con Title builder y PlotlyAxis (alias para evitar conflicto con ndarray::Axis) let layout: Layout = Layout::new()     .width(800)     .height(600)     .title(Title::from(\"DTLZ2 Pareto Front: Theoretical vs Obtained (REVEA)\"))     .scene(         Scene::new()             .x_axis(PlotlyAxis::new().title(Title::from(\"f<sub>1</sub>\")))             .y_axis(PlotlyAxis::new().title(Title::from(\"f<sub>2</sub>\")))             .z_axis(PlotlyAxis::new().title(Title::from(\"f<sub>3</sub>\")))         // .aspect_mode(plotly::layout::scene::AspectMode::Cube) // optional     );  // Compose the plot let mut plot = Plot::new(); plot.add_trace(theoretical_trace); plot.add_trace(obtained_trace); plot.add_trace(refpoints_trace); plot.set_layout(layout);  // Render as rich HTML for evcxr let html = plot.to_html(); println!(\"EVCXR_BEGIN_CONTENT text/html\\n{}\\nEVCXR_END_CONTENT\", html);  Out[6]: In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"user_guide/algorithms/rust/notebooks/rnsga2.html","title":"Rnsga2","text":"In\u00a0[3]: Copied! <pre>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{s, array, Array2, Axis, Ix2};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::Rnsga2Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, RandomSamplingFloat, ExponentialCrossover, Rnsga2ReferencePointsSurvival},\n    genetic::Population,\n};\nuse plotters::prelude::*\n\n/// Evaluate the ZTD1 objectives in a fully vectorized manner.\nfn evaluate_ztd1(x: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let n = x.nrows();\n    let m = x.ncols();\n\n    // clamp to [0,1] to mirror the Python domain constraints\n    let clamped = x.mapv(|v| v.clamp(0.0, 1.0));\n\n    let f1 = clamped.column(0).to_owned();\n    let tail = clamped.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + 9.0 / ((m as f64) - 1.0) * s);\n    let ratio = &amp;f1 / &amp;g;\n    let f2 = &amp;g * (1.0 - ratio.mapv(|r| r.sqrt()));\n\n    let mut out = Array2::&lt;f64&gt;::zeros((n, 2));\n    out.column_mut(0).assign(&amp;f1);\n    out.column_mut(1).assign(&amp;f2);\n    out\n}\n\n/// Compute the theoretical Pareto front for ZTD1.\nfn ztd1_theoretical_front() -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let mut f1_theo = Vec::with_capacity(200);\n    let mut f2_theo = Vec::with_capacity(200);\n    for i in 0..200 {\n        let v = i as f64 / 199.0;\n        f1_theo.push(v);\n        f2_theo.push(1.0 - v.sqrt());\n    }\n    (f1_theo, f2_theo)\n}\n\n// Create constraints using the macro impl_constraints_fn\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\n\n\n// Set up RNSGA-II algorithm with epsilon = 0.005\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    // Define two reference points (for example, points on the Pareto front)\n    let rp: Array2&lt;f64&gt; = array![[0.5, 0.2], [0.1, 0.6]];\n    let epsilon = 0.005;\n    let survivor = Rnsga2ReferencePointsSurvival::new(rp, epsilon);\n    let mut algorithm = Rnsga2Builder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(ExponentialCrossover::new(0.75))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .survivor(survivor)\n        .fitness_fn(evaluate_ztd1)\n        .constraints_fn(BoundConstraints)\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))\n        .num_vars(30)\n        .population_size(50)\n        .num_offsprings(50)\n        .num_iterations(700)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .verbose(false)\n        .seed(1729)\n        .build()\n        .expect(\"Failed to build RNSGA-II\");\n\n    // Run the algorithm\n    algorithm.run().expect(\"RNSGA2 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n// Compute the theoretical Pareto front for ZTD1\nlet (f1_theo, f2_theo) = ztd1_theoretical_front();\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// Compute the theoretical Pareto front for ZTD1\nlet (f1_theo, f2_theo) = ztd1_theoretical_front();\n\n// Plot the theoretical Pareto front, obtained front, and reference points\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 600));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    let grid_color = RGBColor(220, 220, 220);\n\n    // Build axis ranges with headroom including reference points\n    let reference_points: Vec&lt;[f64; 2]&gt; = vec![[0.5, 0.2], [0.1, 0.6]];\n\n    // Compute min/max from actual data\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n    \n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n\n    // Add a small margin (5%)\n    let xr = (x_max - x_min);\n    let yr = (y_max - y_min);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"ZDT1 Pareto Front: Theoretical vs Obtained (R-NSGA-II)\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")                      // plt.xlabel(\"$f_1$\")\n        .y_desc(\"f2\")                      // plt.ylabel(\"$f_2$\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;grid_color)     // plt.grid(True)\n        .draw()\n        .unwrap();\n\n    // Theoretical Pareto Front (black solid line, linewidth=2)\n    chart.draw_series(LineSeries::new(\n        f1_theo.iter().cloned().zip(f2_theo.iter().cloned()),\n        ShapeStyle {\n            color: BLACK.to_rgba(),\n            filled: false,\n            stroke_width: 2,\n        },\n    )).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| PathElement::new(vec![(x - 10, y), (x + 10, y)], &amp;BLACK));\n\n    // Obtained Front (red circles)\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 4, RGBColor(255, 0, 0).filled()));\n\n    // Reference Points\n    chart.draw_series(\n        reference_points.iter().map(|p| {\n            TriangleMarker::new((p[0], p[1]), 8, MAGENTA.filled())\n        })\n    ).unwrap()\n     .label(\"Reference Points\")\n     .legend(|(x, y)| TriangleMarker::new((x, y), 8, MAGENTA.filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;BLACK.mix(0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\n// Emit as rich output for evcxr\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</pre> :dep ndarray = \"*\" :dep moors = \"*\" :dep plotters = \"0.3.6\"  use ndarray::{s, array, Array2, Axis, Ix2}; use moors::{     impl_constraints_fn,     algorithms::Rnsga2Builder,     duplicates::CloseDuplicatesCleaner,     operators::{GaussianMutation, RandomSamplingFloat, ExponentialCrossover, Rnsga2ReferencePointsSurvival},     genetic::Population, }; use plotters::prelude::*  /// Evaluate the ZTD1 objectives in a fully vectorized manner. fn evaluate_ztd1(x: &amp;Array2) -&gt; Array2 {     let n = x.nrows();     let m = x.ncols();      // clamp to [0,1] to mirror the Python domain constraints     let clamped = x.mapv(|v| v.clamp(0.0, 1.0));      let f1 = clamped.column(0).to_owned();     let tail = clamped.slice(s![.., 1..]);     let sums = tail.sum_axis(Axis(1));     let g = sums.mapv(|s| 1.0 + 9.0 / ((m as f64) - 1.0) * s);     let ratio = &amp;f1 / &amp;g     let f2 = &amp;g * (1.0 - ratio.mapv(|r| r.sqrt()));      let mut out = Array2::::zeros((n, 2));     out.column_mut(0).assign(&amp;f1);     out.column_mut(1).assign(&amp;f2);     out }  /// Compute the theoretical Pareto front for ZTD1. fn ztd1_theoretical_front() -&gt; (Vec, Vec) {     let mut f1_theo = Vec::with_capacity(200);     let mut f2_theo = Vec::with_capacity(200);     for i in 0..200 {         let v = i as f64 / 199.0;         f1_theo.push(v);         f2_theo.push(1.0 - v.sqrt());     }     (f1_theo, f2_theo) }  // Create constraints using the macro impl_constraints_fn impl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);    // Set up RNSGA-II algorithm with epsilon = 0.005 let population: Population = {     // Define two reference points (for example, points on the Pareto front)     let rp: Array2 = array![[0.5, 0.2], [0.1, 0.6]];     let epsilon = 0.005;     let survivor = Rnsga2ReferencePointsSurvival::new(rp, epsilon);     let mut algorithm = Rnsga2Builder::default()         .sampler(RandomSamplingFloat::new(0.0, 1.0))         .crossover(ExponentialCrossover::new(0.75))         .mutation(GaussianMutation::new(0.1, 0.01))         .survivor(survivor)         .fitness_fn(evaluate_ztd1)         .constraints_fn(BoundConstraints)         .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))         .num_vars(30)         .population_size(50)         .num_offsprings(50)         .num_iterations(700)         .mutation_rate(0.1)         .crossover_rate(0.9)         .keep_infeasible(false)         .verbose(false)         .seed(1729)         .build()         .expect(\"Failed to build RNSGA-II\");      // Run the algorithm     algorithm.run().expect(\"RNSGA2 run failed\");     algorithm.population().unwrap().clone() };  // Compute the theoretical Pareto front for ZTD1 let (f1_theo, f2_theo) = ztd1_theoretical_front();  // Get the best Pareto front obtained (as a Population instance) let fitness = population.fitness;  // Extract the obtained fitness values (each row is [f1, f2]) let f1_found: Vec = fitness.column(0).to_vec(); let f2_found: Vec = fitness.column(1).to_vec();  // Compute the theoretical Pareto front for ZTD1 let (f1_theo, f2_theo) = ztd1_theoretical_front();  // Plot the theoretical Pareto front, obtained front, and reference points let mut svg = String::new(); {     let backend = SVGBackend::with_string(&amp;mut svg, (1000, 600));     let root = backend.into_drawing_area();     root.fill(&amp;WHITE).unwrap();      let grid_color = RGBColor(220, 220, 220);      // Build axis ranges with headroom including reference points     let reference_points: Vec&lt;[f64; 2]&gt; = vec![[0.5, 0.2], [0.1, 0.6]];      // Compute min/max from actual data     let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);     let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);          for &amp;x in f1_theo.iter().chain(f1_found.iter()) {         if x &lt; x_min { x_min = x; }         if x &gt; x_max { x_max = x; }     }     for &amp;y in f2_theo.iter().chain(f2_found.iter()) {         if y &lt; y_min { y_min = y; }         if y &gt; y_max { y_max = y; }     }      // Add a small margin (5%)     let xr = (x_max - x_min);     let yr = (y_max - y_min);     x_min -= xr * 0.05;     x_max += xr * 0.05;     y_min -= yr * 0.05;     y_max += yr * 0.05;      let mut chart = ChartBuilder::on(&amp;root)         .caption(\"ZDT1 Pareto Front: Theoretical vs Obtained (R-NSGA-II)\", (\"DejaVu Sans\", 22))         .margin(10)         .x_label_area_size(40)         .y_label_area_size(60)         .build_cartesian_2d(x_min..x_max, y_min..y_max)         .unwrap();      chart.configure_mesh()         .x_desc(\"f1\")                      // plt.xlabel(\"$f_1$\")         .y_desc(\"f2\")                      // plt.ylabel(\"$f_2$\")         .axis_desc_style((\"DejaVu Sans\", 14))         .light_line_style(&amp;grid_color)     // plt.grid(True)         .draw()         .unwrap();      // Theoretical Pareto Front (black solid line, linewidth=2)     chart.draw_series(LineSeries::new(         f1_theo.iter().cloned().zip(f2_theo.iter().cloned()),         ShapeStyle {             color: BLACK.to_rgba(),             filled: false,             stroke_width: 2,         },     )).unwrap()      .label(\"Theoretical Pareto Front\")      .legend(|(x, y)| PathElement::new(vec![(x - 10, y), (x + 10, y)], &amp;BLACK));      // Obtained Front (red circles)     chart.draw_series(         f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {             Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())         })     ).unwrap()      .label(\"Obtained Front\")      .legend(|(x, y)| Circle::new((x, y), 4, RGBColor(255, 0, 0).filled()));      // Reference Points     chart.draw_series(         reference_points.iter().map(|p| {             TriangleMarker::new((p[0], p[1]), 8, MAGENTA.filled())         })     ).unwrap()      .label(\"Reference Points\")      .legend(|(x, y)| TriangleMarker::new((x, y), 8, MAGENTA.filled()));      chart.configure_series_labels()         .border_style(&amp;BLACK.mix(0.3))         .background_style(&amp;WHITE.mix(0.9))         .label_font((\"DejaVu Sans\", 13))         .draw()         .unwrap();      root.present().unwrap(); }  // Emit as rich output for evcxr println!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);  Out[3]: In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"user_guide/algorithms/rust/notebooks/spea2.html","title":"Spea2","text":"In\u00a0[7]: Copied! <pre>:dep ndarray = \"*\"\n:dep moors = \"*\"\n:dep plotters = \"0.3.6\"\n\nuse ndarray::{Array2, Axis, Ix2, s};\nuse moors::{\n    impl_constraints_fn,\n    algorithms::Spea2Builder,\n    duplicates::CloseDuplicatesCleaner,\n    operators::{GaussianMutation, RandomSamplingFloat, ExponentialCrossover},\n    genetic::Population\n};\n\nuse plotters::prelude::*;\n\n/// Evaluate the ZDT6 objectives in a fully vectorized manner.\nfn evaluate_zdt6(population: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let n = population.nrows();\n    let m = population.ncols();\n\n    let x1 = population.column(0).to_owned();\n    // g = 1 + (9/(n-1)) * sum(x[1:])\n    let tail = population.slice(s![.., 1..]);\n    let sums = tail.sum_axis(Axis(1));\n    let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);\n\n    // f1 = 1 - exp(-4*x1) * sin^6(6*pi*x1)\n    let sin6 = x1.mapv(|v| (6.0 * std::f64::consts::PI * v).sin().powi(6));\n    let f1 = x1.mapv(|v| 1.0) - x1.mapv(|v| (-4.0 * v).exp()) * sin6;\n\n    // h = 1 - (f1/g)^2\n    let ratio = &amp;f1 / &amp;g;\n    let h = ratio.mapv(|r| 1.0 - r.powi(2));\n\n    // f2 = g * h\n    let f2 = &amp;g * &amp;h;\n\n    let mut result = Array2::&lt;f64&gt;::zeros((n, 2));\n    result.column_mut(0).assign(&amp;f1);\n    result.column_mut(1).assign(&amp;f2);\n    result\n}\n\n/// Compute the theoretical Pareto front for ZDT6.\nfn zdt6_theoretical_front(num_points: usize) -&gt; (Vec&lt;f64&gt;, Vec&lt;f64&gt;) {\n    let mut f1: Vec&lt;f64&gt; = Vec::with_capacity(num_points);\n    let mut f2: Vec&lt;f64&gt; = Vec::with_capacity(num_points);\n\n    for i in 0..num_points {\n        let x1 = if num_points &gt; 1 {\n            i as f64 / (num_points as f64 - 1.0)\n        } else {\n            0.0\n        };\n        let f1_i = 1.0 - (-4.0 * x1).exp() * (6.0 * std::f64::consts::PI * x1).sin().powi(6);\n        // when g = 1 \u2192 f2 = 1 - f1^2\n        let f2_i = 1.0 - f1_i.powi(2);\n        f1.push(f1_i);\n        f2.push(f2_i);\n    }\n\n    (f1, f2)\n}\n\n// Set up the SPEA2 algorithm for ZDT6\nimpl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);\n\nlet population: Population&lt;Ix2, Ix2&gt; = {\n    let mut algorithm = Spea2Builder::default()\n        .sampler(RandomSamplingFloat::new(0.0, 1.0))\n        .crossover(ExponentialCrossover::new(0.75))\n        .mutation(GaussianMutation::new(0.1, 0.01))\n        .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))\n        .fitness_fn(evaluate_zdt6)\n        .constraints_fn(BoundConstraints)\n        .num_vars(30)\n        .population_size(200)\n        .num_offsprings(200)\n        .num_iterations(500)\n        .mutation_rate(0.1)\n        .crossover_rate(0.9)\n        .keep_infeasible(false)\n        .seed(42)\n        .verbose(false)\n        .build()\n        .expect(\"Failed to build SPEA2\");\n\n    // Run SPEA2 on ZDT6\n    algorithm.run().expect(\"SPEA2 run failed\");\n    algorithm.population().unwrap().clone()\n};\n\n\n// Get the best Pareto front obtained (as a Population instance)\nlet fitness = population.fitness;\n\n// Extract the obtained fitness values (each row is [f1, f2])\nlet f1_found: Vec&lt;f64&gt; = fitness.column(0).to_vec();\nlet f2_found: Vec&lt;f64&gt; = fitness.column(1).to_vec();\n\n// Compute the theoretical Pareto front for ZDT6\nlet (f1_theo, f2_theo) = zdt6_theoretical_front(1000);\n\n// Plot the theoretical Pareto front and the obtained front\nlet mut svg = String::new();\n{\n    let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));\n    let root = backend.into_drawing_area();\n    root.fill(&amp;WHITE).unwrap();\n\n    // Compute min/max from actual data\n    let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);\n    let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);\n    \n    for &amp;x in f1_theo.iter().chain(f1_found.iter()) {\n        if x &lt; x_min { x_min = x; }\n        if x &gt; x_max { x_max = x; }\n    }\n    for &amp;y in f2_theo.iter().chain(f2_found.iter()) {\n        if y &lt; y_min { y_min = y; }\n        if y &gt; y_max { y_max = y; }\n    }\n    \n    // Add a small margin (5%)\n    let xr = (x_max - x_min).max(1e-9);\n    let yr = (y_max - y_min).max(1e-9);\n    x_min -= xr * 0.05;\n    x_max += xr * 0.05;\n    y_min -= yr * 0.05;\n    y_max += yr * 0.05;\n\n    let mut chart = ChartBuilder::on(&amp;root)\n        .caption(\"ZDT6 Pareto Front: Theoretical vs Obtained (SPEA2)\", (\"DejaVu Sans\", 22))\n        .margin(10)\n        .x_label_area_size(40)\n        .y_label_area_size(60)\n        .build_cartesian_2d(x_min..x_max, y_min..y_max)\n        .unwrap();\n\n    chart.configure_mesh()\n        .x_desc(\"f1\")\n        .y_desc(\"f2\")\n        .axis_desc_style((\"DejaVu Sans\", 14))\n        .light_line_style(&amp;RGBColor(220, 220, 220))\n        .draw()\n        .unwrap();\n\n    // Plot theoretical front as blue markers.\n    chart.draw_series(\n        f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())\n        })\n    ).unwrap()\n     .label(\"Theoretical Pareto Front\")\n     .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));\n\n    // Plot obtained front as red circles.\n    chart.draw_series(\n        f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {\n            Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())\n        })\n    ).unwrap()\n     .label(\"Obtained Front\")\n     .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));\n\n    chart.configure_series_labels()\n        .border_style(&amp;RGBAColor(0, 0, 0, 0.3))\n        .background_style(&amp;WHITE.mix(0.9))\n        .label_font((\"DejaVu Sans\", 13))\n        .draw()\n        .unwrap();\n\n    root.present().unwrap();\n}\n\n// Emit as rich output for evcxr\nprintln!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg);\n</pre> :dep ndarray = \"*\" :dep moors = \"*\" :dep plotters = \"0.3.6\"  use ndarray::{Array2, Axis, Ix2, s}; use moors::{     impl_constraints_fn,     algorithms::Spea2Builder,     duplicates::CloseDuplicatesCleaner,     operators::{GaussianMutation, RandomSamplingFloat, ExponentialCrossover},     genetic::Population };  use plotters::prelude::*;  /// Evaluate the ZDT6 objectives in a fully vectorized manner. fn evaluate_zdt6(population: &amp;Array2) -&gt; Array2 {     let n = population.nrows();     let m = population.ncols();      let x1 = population.column(0).to_owned();     // g = 1 + (9/(n-1)) * sum(x[1:])     let tail = population.slice(s![.., 1..]);     let sums = tail.sum_axis(Axis(1));     let g = sums.mapv(|s| 1.0 + (9.0 / ((m as f64) - 1.0)) * s);      // f1 = 1 - exp(-4*x1) * sin^6(6*pi*x1)     let sin6 = x1.mapv(|v| (6.0 * std::f64::consts::PI * v).sin().powi(6));     let f1 = x1.mapv(|v| 1.0) - x1.mapv(|v| (-4.0 * v).exp()) * sin6;      // h = 1 - (f1/g)^2     let ratio = &amp;f1 / &amp;g     let h = ratio.mapv(|r| 1.0 - r.powi(2));      // f2 = g * h     let f2 = &amp;g * &amp;h      let mut result = Array2::::zeros((n, 2));     result.column_mut(0).assign(&amp;f1);     result.column_mut(1).assign(&amp;f2);     result }  /// Compute the theoretical Pareto front for ZDT6. fn zdt6_theoretical_front(num_points: usize) -&gt; (Vec, Vec) {     let mut f1: Vec = Vec::with_capacity(num_points);     let mut f2: Vec = Vec::with_capacity(num_points);      for i in 0..num_points {         let x1 = if num_points &gt; 1 {             i as f64 / (num_points as f64 - 1.0)         } else {             0.0         };         let f1_i = 1.0 - (-4.0 * x1).exp() * (6.0 * std::f64::consts::PI * x1).sin().powi(6);         // when g = 1 \u2192 f2 = 1 - f1^2         let f2_i = 1.0 - f1_i.powi(2);         f1.push(f1_i);         f2.push(f2_i);     }      (f1, f2) }  // Set up the SPEA2 algorithm for ZDT6 impl_constraints_fn!(BoundConstraints, lower_bound = 0.0, upper_bound = 1.0);  let population: Population = {     let mut algorithm = Spea2Builder::default()         .sampler(RandomSamplingFloat::new(0.0, 1.0))         .crossover(ExponentialCrossover::new(0.75))         .mutation(GaussianMutation::new(0.1, 0.01))         .duplicates_cleaner(CloseDuplicatesCleaner::new(1e-8))         .fitness_fn(evaluate_zdt6)         .constraints_fn(BoundConstraints)         .num_vars(30)         .population_size(200)         .num_offsprings(200)         .num_iterations(500)         .mutation_rate(0.1)         .crossover_rate(0.9)         .keep_infeasible(false)         .seed(42)         .verbose(false)         .build()         .expect(\"Failed to build SPEA2\");      // Run SPEA2 on ZDT6     algorithm.run().expect(\"SPEA2 run failed\");     algorithm.population().unwrap().clone() };   // Get the best Pareto front obtained (as a Population instance) let fitness = population.fitness;  // Extract the obtained fitness values (each row is [f1, f2]) let f1_found: Vec = fitness.column(0).to_vec(); let f2_found: Vec = fitness.column(1).to_vec();  // Compute the theoretical Pareto front for ZDT6 let (f1_theo, f2_theo) = zdt6_theoretical_front(1000);  // Plot the theoretical Pareto front and the obtained front let mut svg = String::new(); {     let backend = SVGBackend::with_string(&amp;mut svg, (1000, 700));     let root = backend.into_drawing_area();     root.fill(&amp;WHITE).unwrap();      // Compute min/max from actual data     let (mut x_min, mut x_max) = (f1_theo[0], f1_theo[0]);     let (mut y_min, mut y_max) = (f2_theo[0], f2_theo[0]);          for &amp;x in f1_theo.iter().chain(f1_found.iter()) {         if x &lt; x_min { x_min = x; }         if x &gt; x_max { x_max = x; }     }     for &amp;y in f2_theo.iter().chain(f2_found.iter()) {         if y &lt; y_min { y_min = y; }         if y &gt; y_max { y_max = y; }     }          // Add a small margin (5%)     let xr = (x_max - x_min).max(1e-9);     let yr = (y_max - y_min).max(1e-9);     x_min -= xr * 0.05;     x_max += xr * 0.05;     y_min -= yr * 0.05;     y_max += yr * 0.05;      let mut chart = ChartBuilder::on(&amp;root)         .caption(\"ZDT6 Pareto Front: Theoretical vs Obtained (SPEA2)\", (\"DejaVu Sans\", 22))         .margin(10)         .x_label_area_size(40)         .y_label_area_size(60)         .build_cartesian_2d(x_min..x_max, y_min..y_max)         .unwrap();      chart.configure_mesh()         .x_desc(\"f1\")         .y_desc(\"f2\")         .axis_desc_style((\"DejaVu Sans\", 14))         .light_line_style(&amp;RGBColor(220, 220, 220))         .draw()         .unwrap();      // Plot theoretical front as blue markers.     chart.draw_series(         f1_theo.iter().zip(f2_theo.iter()).map(|(&amp;x, &amp;y)| {             Circle::new((x, y), 5, RGBColor(31, 119, 180).filled())         })     ).unwrap()      .label(\"Theoretical Pareto Front\")      .legend(|(x, y)| Circle::new((x, y), 5, RGBColor(31, 119, 180).filled()));      // Plot obtained front as red circles.     chart.draw_series(         f1_found.iter().zip(f2_found.iter()).map(|(&amp;x, &amp;y)| {             Circle::new((x, y), 3, RGBColor(255, 0, 0).filled())         })     ).unwrap()      .label(\"Obtained Front\")      .legend(|(x, y)| Circle::new((x, y), 3, RGBColor(255, 0, 0).filled()));      chart.configure_series_labels()         .border_style(&amp;RGBAColor(0, 0, 0, 0.3))         .background_style(&amp;WHITE.mix(0.9))         .label_font((\"DejaVu Sans\", 13))         .draw()         .unwrap();      root.present().unwrap(); }  // Emit as rich output for evcxr println!(\"EVCXR_BEGIN_CONTENT image/svg+xml\\n{}\\nEVCXR_END_CONTENT\", svg); Out[7]:"},{"location":"user_guide/duplicates/duplicates.html","title":"Duplicates Cleaner","text":"<p>In genetic algorithms, one way to maintain diversity is to eliminate duplicates generation after generation. This operation can be computationally expensive but is often essential to ensure that the algorithm continues to explore new individuals that can improve the objectives.</p> <p>Info</p> <p>Benchmarks comparing pymoors/moors with other Python/Rust frameworks will be published soon. These benchmarks will highlight the importance and performance impact of duplicate elimination in genetic algorithms.</p> RustPython <p>A duplicates cleaner in <code>moors</code> is any type that implements the PopulationCleaner trait. For example:</p> <pre><code>use std::collections::HashSet;\n\nuse ndarray::Array2;\nuse ordered_float::OrderedFloat;\n\nuse crate::duplicates::PopulationCleaner;\n\n#[derive(Debug, Clone)]\n/// Exact duplicates cleaner based on Hash\npub struct ExactDuplicatesCleaner;\n\nimpl ExactDuplicatesCleaner {\n    pub fn new() -&gt; Self {\n        Self\n    }\n}\n\nimpl PopulationCleaner for ExactDuplicatesCleaner {\n    fn remove(&amp;self, population: Array2&lt;f64&gt;, reference: Option&lt;&amp;Array2&lt;f64&gt;&gt;) -&gt; Array2&lt;f64&gt; {\n        let ncols = population.ncols();\n        let mut unique_rows: Vec&lt;Vec&lt;f64&gt;&gt; = Vec::new();\n        // A HashSet to hold the hashable representation of rows.\n        let mut seen: HashSet&lt;Vec&lt;OrderedFloat&lt;f64&gt;&gt;&gt; = HashSet::new();\n\n        // If a reference is provided, first add its rows into the set.\n        if let Some(ref_pop) = reference {\n            for row in ref_pop.outer_iter() {\n                let hash_row: Vec&lt;OrderedFloat&lt;f64&gt;&gt; =\n                    row.iter().map(|&amp;x| OrderedFloat(x)).collect();\n                seen.insert(hash_row);\n            }\n        }\n\n        // Iterate over the population rows.\n        for row in population.outer_iter() {\n            let hash_row: Vec&lt;OrderedFloat&lt;f64&gt;&gt; = row.iter().map(|&amp;x| OrderedFloat(x)).collect();\n            // Insert returns true if the row was not in the set.\n            if seen.insert(hash_row) {\n                unique_rows.push(row.to_vec());\n            }\n        }\n\n        // Flatten the unique rows into a single vector.\n        let data_flat: Vec&lt;f64&gt; = unique_rows.into_iter().flatten().collect();\n        Array2::&lt;f64&gt;::from_shape_vec((data_flat.len() / ncols, ncols), data_flat)\n            .expect(\"Failed to create deduplicated Array2\")\n    }\n}\n</code></pre> <p>The main method to implement is <code>remove</code>, which takes two arguments: <code>population</code> and optional <code>reference</code>. If <code>reference</code> is provided, duplicates are determined by comparing each row in the population to all rows in the reference. The last is very important, when new offsprings are created, they may be unique, but if we compare them with the current population (in this case <code>reference</code>) they may not be unique.</p> <p>Currently pymoors doesn't support user-defined duplicates cleaner. This feature will be available soon once this issue is done</p>"},{"location":"user_guide/duplicates/duplicates.html#exact-duplicates-cleaner","title":"Exact Duplicates Cleaner","text":"<p>Based on exact elimination, meaning that two individuals (genes1 and genes2) are considered duplicates if and only if each element in genes1 is equal to the corresponding element in genes2. Internally, this cleaner uses Rust\u2019s HashSet.</p> RustPython <p>To use exact duplicates cleaner in <code>moors</code> just pass to the algorithm the cleaner instance</p> <pre><code>use ndarray::{array, Array2};\n\nuse moors::ExactDuplicatesCleaner;\n\nlet raw_data = vec![\n    1.0, 2.0, 3.0, // row 0\n    4.0, 5.0, 6.0, // row 1\n    1.0, 2.0, 3.0, // row 2 (duplicate of row 0)\n    7.0, 8.0, 9.0, // row 3\n    4.0, 5.0, 6.0, // row 4 (duplicate of row 1)\n];\nlet population =\n    Array2::&lt;f64&gt;::from_shape_vec((5, 3), raw_data).expect(\"Failed to create test array\");\n\nlet cleaner = ExactDuplicatesCleaner::new();\nlet cleaned = cleaner.remove(population, None);\n\nlet expected = array![\n    [1.0, 2.0, 3.0],\n    [4.0, 5.0, 6.0],\n    [7.0, 8.0, 9.0],\n];\n\nassert_eq!(cleaned, expected);\n</code></pre> <p>To use exact duplicates cleaner in <code>pymoors</code> just pass to the algorithm the cleaner object</p> <pre><code>import numpy as np\n\nfrom pymoors import ExactDuplicatesCleaner\n\ncleaner = ExactDuplicatesCleaner()\n\nraw_data = np.array([\n    [1.0, 2.0, 3.0],  # row 0\n    [4.0, 5.0, 6.0],  # row 1\n    [1.0, 2.0, 3.0],  # row 2 (duplicate of row 0)\n    [7.0, 8.0, 9.0],  # row 3\n    [4.0, 5.0, 6.0],  # row 4 (duplicate of row 1)\n])\n\ncleaned = cleaner.remove(raw_data)\n\nexpected = np.array([\n    [1.0, 2.0, 3.0],\n    [4.0, 5.0, 6.0],\n    [7.0, 8.0, 9.0],\n])\n\nnp.testing.assert_array_equal(cleaned, expected)\n</code></pre>"},{"location":"user_guide/duplicates/duplicates.html#close-duplicates-cleaner","title":"Close Duplicates Cleaner","text":"<p>This is designed for real-valued problems where two individuals are very similar, but not exactly identical. In such cases, it is beneficial to consider them as duplicates based on a proximity metric\u2014typically the Euclidean distance. This cleaner implements a cleaner of this style that uses the square of the Euclidean distance between two individuals and considers them duplicates if this value is below a configurable tolerance (epsilon).</p> RustPython <p>To use close duplicates cleaner in <code>moors</code> just pass to the algorithm the cleaner instance</p> <pre><code>use ndarray::array;\n\nuse moors::CloseDuplicatesCleaner;\n\nlet population = array![[1.0, 2.0, 3.0], [10.0, 10.0, 10.0]];\nlet reference = array![[1.01, 2.01, 3.01]];  // close to row 0 of population\nlet epsilon = 0.05;\nlet cleaner = CloseDuplicatesCleaner::new(epsilon);\nlet cleaned = cleaner.remove(population, Some(&amp;reference));\n// Row 0 should be removed.\nassert_eq!(cleaned.nrows(), 1);\nassert_eq!(cleaned.row(0).to_vec(), vec![10.0, 10.0, 10.0]);\n</code></pre> <p>To use close duplicates cleaner in <code>pymoors</code> just pass to the algorithm the cleaner object</p> <pre><code>import numpy as np\n\nfrom pymoors import CloseDuplicatesCleaner\n\npopulation = np.array([[1.0, 2.0, 3.0], [10.0, 10.0, 10.0]])\nreference = np.array([[1.01, 2.01, 3.01]]) # close to row 0 of population\nepsilon = 0.05;\n\ncleaner = CloseDuplicatesCleaner(epsilon=1e-5)\n\ncleaned = cleaner.remove(population, Some(&amp;reference));\n# Row 0 should be removed.\nassert len(cleaned) == 1;\nnp.testing.assert_array_equal(cleaned, np.array([10.0, 10.0, 10.0]));\n</code></pre> <p>Caution</p> <p>This duplicate elimination algorithm can be computationally expensive when the population size and the number of offsprings are large, because it requires calculating the distance matrix among offsprings first, and then between offsprings and the current population to ensure duplicate elimination using this criterion. The algorithm has a complexity of O(n*m) where n is the population size and m is the number of offsprings.</p>"},{"location":"user_guide/duplicates/python/close.html","title":"Close","text":"<p>To use close duplicates cleaner in <code>pymoors</code> just pass to the algorithm the cleaner object</p> <pre><code>import numpy as np\n\nfrom pymoors import CloseDuplicatesCleaner\n\npopulation = np.array([[1.0, 2.0, 3.0], [10.0, 10.0, 10.0]])\nreference = np.array([[1.01, 2.01, 3.01]]) # close to row 0 of population\nepsilon = 0.05;\n\ncleaner = CloseDuplicatesCleaner(epsilon=1e-5)\n\ncleaned = cleaner.remove(population, Some(&amp;reference));\n# Row 0 should be removed.\nassert len(cleaned) == 1;\nnp.testing.assert_array_equal(cleaned, np.array([10.0, 10.0, 10.0]));\n</code></pre>"},{"location":"user_guide/duplicates/python/custom.html","title":"Custom","text":"<p>Currently pymoors doesn't support user-defined duplicates cleaner. This feature will be available soon once this issue is done</p>"},{"location":"user_guide/duplicates/python/exact.html","title":"Exact","text":"<p>To use exact duplicates cleaner in <code>pymoors</code> just pass to the algorithm the cleaner object</p> <pre><code>import numpy as np\n\nfrom pymoors import ExactDuplicatesCleaner\n\ncleaner = ExactDuplicatesCleaner()\n\nraw_data = np.array([\n    [1.0, 2.0, 3.0],  # row 0\n    [4.0, 5.0, 6.0],  # row 1\n    [1.0, 2.0, 3.0],  # row 2 (duplicate of row 0)\n    [7.0, 8.0, 9.0],  # row 3\n    [4.0, 5.0, 6.0],  # row 4 (duplicate of row 1)\n])\n\ncleaned = cleaner.remove(raw_data)\n\nexpected = np.array([\n    [1.0, 2.0, 3.0],\n    [4.0, 5.0, 6.0],\n    [7.0, 8.0, 9.0],\n])\n\nnp.testing.assert_array_equal(cleaned, expected)\n</code></pre>"},{"location":"user_guide/duplicates/rust/close.html","title":"Close","text":"<p>To use close duplicates cleaner in <code>moors</code> just pass to the algorithm the cleaner instance</p> <pre><code>use ndarray::array;\n\nuse moors::CloseDuplicatesCleaner;\n\nlet population = array![[1.0, 2.0, 3.0], [10.0, 10.0, 10.0]];\nlet reference = array![[1.01, 2.01, 3.01]];  // close to row 0 of population\nlet epsilon = 0.05;\nlet cleaner = CloseDuplicatesCleaner::new(epsilon);\nlet cleaned = cleaner.remove(population, Some(&amp;reference));\n// Row 0 should be removed.\nassert_eq!(cleaned.nrows(), 1);\nassert_eq!(cleaned.row(0).to_vec(), vec![10.0, 10.0, 10.0]);\n</code></pre>"},{"location":"user_guide/duplicates/rust/custom.html","title":"Custom","text":"<p>A duplicates cleaner in <code>moors</code> is any type that implements the PopulationCleaner trait. For example:</p> <pre><code>use std::collections::HashSet;\n\nuse ndarray::Array2;\nuse ordered_float::OrderedFloat;\n\nuse crate::duplicates::PopulationCleaner;\n\n#[derive(Debug, Clone)]\n/// Exact duplicates cleaner based on Hash\npub struct ExactDuplicatesCleaner;\n\nimpl ExactDuplicatesCleaner {\n    pub fn new() -&gt; Self {\n        Self\n    }\n}\n\nimpl PopulationCleaner for ExactDuplicatesCleaner {\n    fn remove(&amp;self, population: Array2&lt;f64&gt;, reference: Option&lt;&amp;Array2&lt;f64&gt;&gt;) -&gt; Array2&lt;f64&gt; {\n        let ncols = population.ncols();\n        let mut unique_rows: Vec&lt;Vec&lt;f64&gt;&gt; = Vec::new();\n        // A HashSet to hold the hashable representation of rows.\n        let mut seen: HashSet&lt;Vec&lt;OrderedFloat&lt;f64&gt;&gt;&gt; = HashSet::new();\n\n        // If a reference is provided, first add its rows into the set.\n        if let Some(ref_pop) = reference {\n            for row in ref_pop.outer_iter() {\n                let hash_row: Vec&lt;OrderedFloat&lt;f64&gt;&gt; =\n                    row.iter().map(|&amp;x| OrderedFloat(x)).collect();\n                seen.insert(hash_row);\n            }\n        }\n\n        // Iterate over the population rows.\n        for row in population.outer_iter() {\n            let hash_row: Vec&lt;OrderedFloat&lt;f64&gt;&gt; = row.iter().map(|&amp;x| OrderedFloat(x)).collect();\n            // Insert returns true if the row was not in the set.\n            if seen.insert(hash_row) {\n                unique_rows.push(row.to_vec());\n            }\n        }\n\n        // Flatten the unique rows into a single vector.\n        let data_flat: Vec&lt;f64&gt; = unique_rows.into_iter().flatten().collect();\n        Array2::&lt;f64&gt;::from_shape_vec((data_flat.len() / ncols, ncols), data_flat)\n            .expect(\"Failed to create deduplicated Array2\")\n    }\n}\n</code></pre> <p>The main method to implement is <code>remove</code>, which takes two arguments: <code>population</code> and optional <code>reference</code>. If <code>reference</code> is provided, duplicates are determined by comparing each row in the population to all rows in the reference. The last is very important, when new offsprings are created, they may be unique, but if we compare them with the current population (in this case <code>reference</code>) they may not be unique.</p>"},{"location":"user_guide/duplicates/rust/exact.html","title":"Exact","text":"<p>To use exact duplicates cleaner in <code>moors</code> just pass to the algorithm the cleaner instance</p> <pre><code>use ndarray::{array, Array2};\n\nuse moors::ExactDuplicatesCleaner;\n\nlet raw_data = vec![\n    1.0, 2.0, 3.0, // row 0\n    4.0, 5.0, 6.0, // row 1\n    1.0, 2.0, 3.0, // row 2 (duplicate of row 0)\n    7.0, 8.0, 9.0, // row 3\n    4.0, 5.0, 6.0, // row 4 (duplicate of row 1)\n];\nlet population =\n    Array2::&lt;f64&gt;::from_shape_vec((5, 3), raw_data).expect(\"Failed to create test array\");\n\nlet cleaner = ExactDuplicatesCleaner::new();\nlet cleaned = cleaner.remove(population, None);\n\nlet expected = array![\n    [1.0, 2.0, 3.0],\n    [4.0, 5.0, 6.0],\n    [7.0, 8.0, 9.0],\n];\n\nassert_eq!(cleaned, expected);\n</code></pre>"},{"location":"user_guide/fitness_and_constraints/fitness_and_constraints.html","title":"Fitness and Constraints","text":"<p>In multi-objective optimization, fitness functions assign a numerical score to each candidate solution based on how well it achieves the objectives, while constraint functions measure any violations of problem constraints (e.g., inequalities or equalities).</p> <p>In <code>moors</code>/<code>pymoors</code>, both fitness and constraint functions are implemented as vectorized operations on ndarrays at the population level. That is, instead of evaluating one individual at a time, they accept a 2D array of shape (<code>num_individuals</code>, <code>num_vars</code>) and so that all individuals in the current population are evaluated simultaneously.</p>"},{"location":"user_guide/fitness_and_constraints/fitness_and_constraints.html#fitness","title":"Fitness","text":"<p>Fitness is a numerical measure of how well a candidate solution meets the optimization objectives. It assigns each individual a score that guides selection and reproduction in evolutionary algorithms.</p> RustPython <p>In moors, the way to define objective functions for optimization is through a ndarray. Currently, the only dtype supported is <code>f64</code>, we're planning to relax this in the future. It means that when working with a different dtype, such as binary, its values must be trated as <code>f64</code> (in this case as <code>0.0</code> and <code>1.0</code>).</p> <p>An example is given below</p> <pre><code>use ndarray::{Array2, Axis, stack};\n\n/// DTLZ2 for 3 objectives (m = 3) with k = 0 (so num_vars = m\u22121 = 2):\n/// f1 = cos(\u03c0/2 \u22c5 x0) \u22c5 cos(\u03c0/2 \u22c5 x1)\n/// f2 = cos(\u03c0/2 \u22c5 x0) \u22c5 sin(\u03c0/2 \u22c5 x1)\n/// f3 = sin(\u03c0/2 \u22c5 x0)\nfn fitness_dtlz2_3obj(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let half_pi = std::f64::consts::PI / 2.0;\n    let x0 = genes.column(0).mapv(|v| v * half_pi);\n    let x1 = genes.column(1).mapv(|v| v * half_pi);\n\n    let c0 = x0.mapv(f64::cos);\n    let s0 = x0.mapv(f64::sin);\n    let c1 = x1.mapv(f64::cos);\n    let s1 = x1.mapv(f64::sin);\n\n    let f1 = &amp;c0 * &amp;c1;\n    let f2 = &amp;c0 * &amp;s1;\n    let f3 = s0;\n\n    stack(Axis(1), &amp;[f1.view(), f2.view(), f3.view()]).expect(\"stack failed\")\n}\n</code></pre> <p>This funcion has the signature <code>(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt;</code> and is a valid function for any <code>moors</code> multi-objective optimization algorithm, such as Nsga2, Nsga3 , etc. Note that this function is poblational, meaning that the whole population is evaluated</p> <p>A function for a single objective optimization problem has the signature <code>(genes: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt;</code> and is valid for any <code>moors</code> single optimization algorithm. An example is given below</p> <pre><code>use ndarray::{Array1, Array2, Axix};\n\n/// Simple minimization of 1 - (x**2 + y**2 + z**2)\nfn fitness_sphere(population: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    // For each row [x, y, z], compute 1 - x^2 + y^2 + z^2\n    population.map_axis(Axis(1), |row| 1.0 - row.dot(&amp;row))\n}\n</code></pre> <p>In pymoors, the way to define objective functions for optimization is through a numpy. Currently, the only dtype supported is <code>float</code>, we're planning to relax this in the future. It means that when working with a different dtype, such as binary, its values must be trated as <code>float</code> (in this case as <code>0.0</code> and <code>1.0</code>).</p> <p>This population-level evaluation is very important\u2014it allows the algorithm to efficiently process and compare many individuals at once. When writing your fitness function, make sure it is vectorized and returns one row per individual, where each row contains the evaluated objective values.</p> <p>Below is an example fitness function:</p> <pre><code>import numpy as np\n\nfrom pymoors.typing import TwoDArray\n\ndef fitness_dtlz2_3obj(genes: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    DTLZ2 for 3 objectives (m = 3) with k = 0 (so num_vars = m\u22121 = 2):\n    f1 = cos(\u03c0/2 \u22c5 x0) \u22c5 cos(\u03c0/2 \u22c5 x1)\n    f2 = cos(\u03c0/2 \u22c5 x0) \u22c5 sin(\u03c0/2 \u22c5 x1)\n    f3 = sin(\u03c0/2 \u22c5 x0)\n    \"\"\"\n    half_pi = np.pi / 2.0\n    x0 = genes[:, 0] * half_pi\n    x1 = genes[:, 1] * half_pi\n\n    c0 = np.cos(x0)\n    s0 = np.sin(x0)\n    c1 = np.cos(x1)\n    s1 = np.sin(x1)\n\n    f1 = c0 * c1\n    f2 = c0 * s1\n    f3 = s0\n\n    return np.stack([f1, f2, f3], axis=1)\n</code></pre>"},{"location":"user_guide/fitness_and_constraints/fitness_and_constraints.html#constraints","title":"Constraints","text":"<p>Feasibility is the key concept in constraints. This is very important in optimization, an individual is called feasible if and only if it satisfies all the constraints the problem defines. In <code>moors</code>/<code>pymoors</code> as in many other optimization frameworks, constraints allowed are evaluated as <code>&lt;= 0.0</code>. In genetic algorithms, there are different ways to incorporate feasibility in the search for optimal solutions. In this framework, the guiding philosophy is: feasibility dominates everything, meaning that a feasible individual is always preferred over an infeasible one.</p>"},{"location":"user_guide/fitness_and_constraints/fitness_and_constraints.html#inequality-constraints","title":"Inequality Constraints","text":"<p>In <code>moors</code>/<code>pymoors</code> as mentioned, any output from a constraint function is evaluated as less than or equal to zero. If this condition is met, the individual is considered feasible. For constraints that are naturally expressed as greater than zero, the user should modify the function by multiplying it by -1, as shown in the following example</p> RustPython <pre><code>use ndarray::{Array1, Array2};\n\nfn constraints_sphere_lower_than_zero(population: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    // For each row [x, y, z], compute x^2 + y^2 + z^2 - 1 &lt;= 0\n    population.map_axis(Axis(1), |row| row.dot(&amp;row)) - 1.0\n}\n\nfn constraints_sphere_greather_than_zero(population: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    // For each row [x, y, z], compute x^2 + y^2 + z^2 - 1 =&gt; 0\n    1.0 - population.map_axis(Axis(1), |row| row.dot(&amp;row))\n}\n</code></pre> <pre><code>import numpy as np\n\nfrom pymoors import Constraints\n\n\ndef constraints_sphere_lower_than_zero(population: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    For each individual (row) in the population, compute x^2 + y^2 + z^2 - 1.\n    Constraint is satisfied when this value is \u2264 0.\n    \"\"\"\n    # population shape: (n_individuals, n_dimensions)\n    sum_sq = np.sum(population**2, axis=1)\n    return sum_sq - 1.0\n\ndef constraints_sphere_greater_than_zero(population: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    For each individual (row) in the population, compute 1 - (x^2 + y^2 + z^2).\n    Constraint is satisfied when this value is \u2265 0.\n    \"\"\"\n    sum_sq = np.sum(population**2, axis=1)\n    return 1.0 - sum_sq\n\n\nconstraints = Constraints(ineq = [constraints_sphere_lower_than_zero, constraints_sphere_greater_than_zero])\n</code></pre> <p>constraints as plain numpy function</p> <p>In pymoors, you can pass to the algorithm a callable, in this scenario you must ensure that the return array is always 2D, even if you work with just one constraint.</p>"},{"location":"user_guide/fitness_and_constraints/fitness_and_constraints.html#equality-constraints","title":"Equality Constraints","text":"<p>As is many other frameworks, the known epsilon technique must be used to force \\(g(x) = 0\\), select a tolerance \\(\\epsilon\\) and then transform \\(g\\) into an inquality constraint</p> \\[g_{\\text{ineq}}(x) = \\bigl|g(x)\\bigr| - \\varepsilon \\;\\le\\; 0.\\] <p>An example is given below</p> RustPython <pre><code>use ndarray::{Array2, Array1, Axis};\n\nconst EPSILON: f64 = 1e-6;\n\n/// Returns an Array2 of shape (n, 2) containing two constraints for each row [x, y]:\n/// - Column 0: |x + y - 1| - EPSILON \u2264 0 (equality with \u03b5-tolerance)\n/// - Column 1: x\u00b2 + y\u00b2 - 1.0 \u2264 0 (unit circle inequality)\nfn constraints(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    // Constraint 1: |x + y - 1| - EPSILON\n    let eq = genes.map_axis(Axis(1), |row| (row[0] + row[1] - 1.0).abs() - EPSILON);\n    // Constraint 2: x^2 + y^2 - 1\n    let ineq = genes.map_axis(Axis(1), |row| row[0].powi(2) + row[1].powi(2) - 1.0);\n    // Stack into two columns\n    stack(Axis(1), &amp;[eq.view(), ineq.view()]).unwrap()\n}\n</code></pre> <p>This example ilustrates 2 constraints where one of them is an equality constraint.</p> <p>There is a helper macro <code>moors::impl_constraints_fn</code> that will build the expected constraints for us, trying to simplify at most is  possible the boliparte code</p> <pre><code>use ndarray::{Array2, Array1, Axis};\n\nuse moors::impl_constraints_fn;\n\n/// Equality constraint x + y = 1\nfn constraints_eq(genes: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    genes.map_axis(Axis(1), |row| row[0] + row[1] - 1.0)\n}\n\n/// Inequality constraint: x\u00b2 + y\u00b2 - 1 \u2264 0\nfn constraints_ineq(genes: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    genes.map_axis(Axis(1), |row| row[0].powi(2) + row[1].powi(2) - 1.0)\n}\n\nimpl_constraints_fn!(\n    MyConstraints,\n    ineq = [constraints_ineq],\n    eq   = [constraints_eq],\n);\n</code></pre> <p>This macro generates a new struct <code>MyConstraints</code> than can be passed to any algorithm, you can pass multiple inequality/equality constraints to the macro <code>impl_constraints_fn(MyConstraints, ineq =[g1, g2, ...], eq = [h1, h2, ..])</code>. This macro will use the epsilon technique internally using a fixed tolerance of <code>1e-6</code>, the last in the near future will be seteable by the user.</p> <pre><code>import numpy as np\n\nfrom pymoors.typing import TwoDArray\n\nEPSILON = 1e-6\n\ndef constraints(genes: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Compute two constraints for each row [x, y] in genes:\n      - Column 0: |x + y - 1| - EPSILON \u2264 0  (equality with \u03b5-tolerance)\n      - Column 1: x\u00b2 + y\u00b2 - 1.0 \u2264 0         (unit circle inequality)\n    Returns an array of shape (n, 2).\n    \"\"\"\n    # genes is expected to be shape (n_individuals, 2)\n    x = genes[:, 0]\n    y = genes[:, 1]\n\n    # Constraint 1: |x + y - 1| - EPSILON\n    eq = np.abs(x + y - 1.0) - EPSILON\n\n    # Constraint 2: x^2 + y^2 - 1\n    ineq = x**2 + y**2 - 1.0\n\n    return np.stack((eq, ineq), axis=1)\n</code></pre> <p>This example ilustrates 2 constraints where one of them is an equality constraint. The <code>pymoors.Constraints</code> class lets us skip having to manually implement the epsilon technique; we can simply do</p> <pre><code>from pymoors import Constraints\nfrom pymoors.typing import TwoDArray, OneDArray\n\nEPSILON = 1e-6\n\ndef eq_constr(genes: TwoDArray) -&gt; OneDArray:\n    return genes[:, 0] + genes[:, 1] - 1\n\ndef ineq_constr(genes: TwoDArray) -&gt; OneDArray:\n    return genes[:, 0]**2 + genes[:, 1]**2 - 1\n\nconstraints = Constraints(eq = [eq_constr], ineq = [ineq_constr])\n</code></pre>"},{"location":"user_guide/fitness_and_constraints/fitness_and_constraints.html#lower-and-upper-bounds","title":"Lower and Upper Bounds","text":"RustPython <p>Also this macro has two optional arguments <code>lower_bound</code> and <code>upper_bound</code> that will make each gene bounded by those values.</p> <pre><code>use ndarray::{Array2, Array1, Axis};\n\nuse moors::impl_constraints_fn;\n\n/// Equality constraint x + y = 1\nfn constraints_eq(genes: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    genes.map_axis(Axis(1), |row| row[0] + row[1] - 1.0)\n}\n\nimpl_constraints_fn!(\n    MyBoundedConstraints,\n    eq   = [constraints_eq],\n    lower_bound = -1.0,\n    upper_bound = 1.0\n);\n</code></pre> <p><code>ConstraintsFn</code> trait</p> <p>Internally, <code>constraints</code> as an argument to genetic algorithms is actually any type that implements ConstraintsFn. The <code>impl_constraints_fn</code> macro creates a struct that implements this trait. The types <code>Fn(&amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt;</code> and <code>Fn(&amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt;</code> automatically implement this trait.</p> <p>Also this class has two optional arguments <code>lower_bound</code> and <code>upper_bound</code> that will make each gene bounded by those values.</p> <pre><code>import numpy as np\n\nfrom pymoors import Constraints\n\nEPSILON = 1e-6\n\ndef eq_constr(genes: np.ndarray):\n    return genes[:, 0] + genes[:, 1] - 1\n\nconstraints = Constraints(eq = [eq_constr], lower_bound = 0.0, upper_bound = 1.0)\n</code></pre>"},{"location":"user_guide/fitness_and_constraints/python/eq_constraints.html","title":"Eq constraints","text":"<pre><code>import numpy as np\n\nfrom pymoors.typing import TwoDArray\n\nEPSILON = 1e-6\n\ndef constraints(genes: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    Compute two constraints for each row [x, y] in genes:\n      - Column 0: |x + y - 1| - EPSILON \u2264 0  (equality with \u03b5-tolerance)\n      - Column 1: x\u00b2 + y\u00b2 - 1.0 \u2264 0         (unit circle inequality)\n    Returns an array of shape (n, 2).\n    \"\"\"\n    # genes is expected to be shape (n_individuals, 2)\n    x = genes[:, 0]\n    y = genes[:, 1]\n\n    # Constraint 1: |x + y - 1| - EPSILON\n    eq = np.abs(x + y - 1.0) - EPSILON\n\n    # Constraint 2: x^2 + y^2 - 1\n    ineq = x**2 + y**2 - 1.0\n\n    return np.stack((eq, ineq), axis=1)\n</code></pre> <p>This example ilustrates 2 constraints where one of them is an equality constraint. The <code>pymoors.Constraints</code> class lets us skip having to manually implement the epsilon technique; we can simply do</p> <pre><code>from pymoors import Constraints\nfrom pymoors.typing import TwoDArray, OneDArray\n\nEPSILON = 1e-6\n\ndef eq_constr(genes: TwoDArray) -&gt; OneDArray:\n    return genes[:, 0] + genes[:, 1] - 1\n\ndef ineq_constr(genes: TwoDArray) -&gt; OneDArray:\n    return genes[:, 0]**2 + genes[:, 1]**2 - 1\n\nconstraints = Constraints(eq = [eq_constr], ineq = [ineq_constr])\n</code></pre>"},{"location":"user_guide/fitness_and_constraints/python/fitness.html","title":"Fitness","text":"<p>In pymoors, the way to define objective functions for optimization is through a numpy. Currently, the only dtype supported is <code>float</code>, we're planning to relax this in the future. It means that when working with a different dtype, such as binary, its values must be trated as <code>float</code> (in this case as <code>0.0</code> and <code>1.0</code>).</p> <p>This population-level evaluation is very important\u2014it allows the algorithm to efficiently process and compare many individuals at once. When writing your fitness function, make sure it is vectorized and returns one row per individual, where each row contains the evaluated objective values.</p> <p>Below is an example fitness function:</p> <pre><code>import numpy as np\n\nfrom pymoors.typing import TwoDArray\n\ndef fitness_dtlz2_3obj(genes: TwoDArray) -&gt; TwoDArray:\n    \"\"\"\n    DTLZ2 for 3 objectives (m = 3) with k = 0 (so num_vars = m\u22121 = 2):\n    f1 = cos(\u03c0/2 \u22c5 x0) \u22c5 cos(\u03c0/2 \u22c5 x1)\n    f2 = cos(\u03c0/2 \u22c5 x0) \u22c5 sin(\u03c0/2 \u22c5 x1)\n    f3 = sin(\u03c0/2 \u22c5 x0)\n    \"\"\"\n    half_pi = np.pi / 2.0\n    x0 = genes[:, 0] * half_pi\n    x1 = genes[:, 1] * half_pi\n\n    c0 = np.cos(x0)\n    s0 = np.sin(x0)\n    c1 = np.cos(x1)\n    s1 = np.sin(x1)\n\n    f1 = c0 * c1\n    f2 = c0 * s1\n    f3 = s0\n\n    return np.stack([f1, f2, f3], axis=1)\n</code></pre>"},{"location":"user_guide/fitness_and_constraints/python/ineq_constraints.html","title":"Ineq constraints","text":"<pre><code>import numpy as np\n\nfrom pymoors import Constraints\n\n\ndef constraints_sphere_lower_than_zero(population: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    For each individual (row) in the population, compute x^2 + y^2 + z^2 - 1.\n    Constraint is satisfied when this value is \u2264 0.\n    \"\"\"\n    # population shape: (n_individuals, n_dimensions)\n    sum_sq = np.sum(population**2, axis=1)\n    return sum_sq - 1.0\n\ndef constraints_sphere_greater_than_zero(population: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    For each individual (row) in the population, compute 1 - (x^2 + y^2 + z^2).\n    Constraint is satisfied when this value is \u2265 0.\n    \"\"\"\n    sum_sq = np.sum(population**2, axis=1)\n    return 1.0 - sum_sq\n\n\nconstraints = Constraints(ineq = [constraints_sphere_lower_than_zero, constraints_sphere_greater_than_zero])\n</code></pre> <p>constraints as plain numpy function</p> <p>In pymoors, you can pass to the algorithm a callable, in this scenario you must ensure that the return array is always 2D, even if you work with just one constraint.</p>"},{"location":"user_guide/fitness_and_constraints/python/lower_upper_bounds.html","title":"Lower upper bounds","text":"<p>Also this class has two optional arguments <code>lower_bound</code> and <code>upper_bound</code> that will make each gene bounded by those values.</p> <pre><code>import numpy as np\n\nfrom pymoors import Constraints\n\nEPSILON = 1e-6\n\ndef eq_constr(genes: np.ndarray):\n    return genes[:, 0] + genes[:, 1] - 1\n\nconstraints = Constraints(eq = [eq_constr], lower_bound = 0.0, upper_bound = 1.0)\n</code></pre>"},{"location":"user_guide/fitness_and_constraints/rust/eq_constraints.html","title":"Eq constraints","text":"<pre><code>use ndarray::{Array2, Array1, Axis};\n\nconst EPSILON: f64 = 1e-6;\n\n/// Returns an Array2 of shape (n, 2) containing two constraints for each row [x, y]:\n/// - Column 0: |x + y - 1| - EPSILON \u2264 0 (equality with \u03b5-tolerance)\n/// - Column 1: x\u00b2 + y\u00b2 - 1.0 \u2264 0 (unit circle inequality)\nfn constraints(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    // Constraint 1: |x + y - 1| - EPSILON\n    let eq = genes.map_axis(Axis(1), |row| (row[0] + row[1] - 1.0).abs() - EPSILON);\n    // Constraint 2: x^2 + y^2 - 1\n    let ineq = genes.map_axis(Axis(1), |row| row[0].powi(2) + row[1].powi(2) - 1.0);\n    // Stack into two columns\n    stack(Axis(1), &amp;[eq.view(), ineq.view()]).unwrap()\n}\n</code></pre> <p>This example ilustrates 2 constraints where one of them is an equality constraint.</p> <p>There is a helper macro <code>moors::impl_constraints_fn</code> that will build the expected constraints for us, trying to simplify at most is  possible the boliparte code</p> <pre><code>use ndarray::{Array2, Array1, Axis};\n\nuse moors::impl_constraints_fn;\n\n/// Equality constraint x + y = 1\nfn constraints_eq(genes: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    genes.map_axis(Axis(1), |row| row[0] + row[1] - 1.0)\n}\n\n/// Inequality constraint: x\u00b2 + y\u00b2 - 1 \u2264 0\nfn constraints_ineq(genes: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    genes.map_axis(Axis(1), |row| row[0].powi(2) + row[1].powi(2) - 1.0)\n}\n\nimpl_constraints_fn!(\n    MyConstraints,\n    ineq = [constraints_ineq],\n    eq   = [constraints_eq],\n);\n</code></pre> <p>This macro generates a new struct <code>MyConstraints</code> than can be passed to any algorithm, you can pass multiple inequality/equality constraints to the macro <code>impl_constraints_fn(MyConstraints, ineq =[g1, g2, ...], eq = [h1, h2, ..])</code>. This macro will use the epsilon technique internally using a fixed tolerance of <code>1e-6</code>, the last in the near future will be seteable by the user.</p>"},{"location":"user_guide/fitness_and_constraints/rust/fitness.html","title":"Fitness","text":"<p>In moors, the way to define objective functions for optimization is through a ndarray. Currently, the only dtype supported is <code>f64</code>, we're planning to relax this in the future. It means that when working with a different dtype, such as binary, its values must be trated as <code>f64</code> (in this case as <code>0.0</code> and <code>1.0</code>).</p> <p>An example is given below</p> <pre><code>use ndarray::{Array2, Axis, stack};\n\n/// DTLZ2 for 3 objectives (m = 3) with k = 0 (so num_vars = m\u22121 = 2):\n/// f1 = cos(\u03c0/2 \u22c5 x0) \u22c5 cos(\u03c0/2 \u22c5 x1)\n/// f2 = cos(\u03c0/2 \u22c5 x0) \u22c5 sin(\u03c0/2 \u22c5 x1)\n/// f3 = sin(\u03c0/2 \u22c5 x0)\nfn fitness_dtlz2_3obj(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt; {\n    let half_pi = std::f64::consts::PI / 2.0;\n    let x0 = genes.column(0).mapv(|v| v * half_pi);\n    let x1 = genes.column(1).mapv(|v| v * half_pi);\n\n    let c0 = x0.mapv(f64::cos);\n    let s0 = x0.mapv(f64::sin);\n    let c1 = x1.mapv(f64::cos);\n    let s1 = x1.mapv(f64::sin);\n\n    let f1 = &amp;c0 * &amp;c1;\n    let f2 = &amp;c0 * &amp;s1;\n    let f3 = s0;\n\n    stack(Axis(1), &amp;[f1.view(), f2.view(), f3.view()]).expect(\"stack failed\")\n}\n</code></pre> <p>This funcion has the signature <code>(genes: &amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt;</code> and is a valid function for any <code>moors</code> multi-objective optimization algorithm, such as Nsga2, Nsga3 , etc. Note that this function is poblational, meaning that the whole population is evaluated</p> <p>A function for a single objective optimization problem has the signature <code>(genes: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt;</code> and is valid for any <code>moors</code> single optimization algorithm. An example is given below</p> <pre><code>use ndarray::{Array1, Array2, Axix};\n\n/// Simple minimization of 1 - (x**2 + y**2 + z**2)\nfn fitness_sphere(population: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    // For each row [x, y, z], compute 1 - x^2 + y^2 + z^2\n    population.map_axis(Axis(1), |row| 1.0 - row.dot(&amp;row))\n}\n</code></pre>"},{"location":"user_guide/fitness_and_constraints/rust/ineq_constraints.html","title":"Ineq constraints","text":"<pre><code>use ndarray::{Array1, Array2};\n\nfn constraints_sphere_lower_than_zero(population: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    // For each row [x, y, z], compute x^2 + y^2 + z^2 - 1 &lt;= 0\n    population.map_axis(Axis(1), |row| row.dot(&amp;row)) - 1.0\n}\n\nfn constraints_sphere_greather_than_zero(population: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    // For each row [x, y, z], compute x^2 + y^2 + z^2 - 1 =&gt; 0\n    1.0 - population.map_axis(Axis(1), |row| row.dot(&amp;row))\n}\n</code></pre>"},{"location":"user_guide/fitness_and_constraints/rust/lower_upper_bounds.html","title":"Lower upper bounds","text":"<p>Also this macro has two optional arguments <code>lower_bound</code> and <code>upper_bound</code> that will make each gene bounded by those values.</p> <pre><code>use ndarray::{Array2, Array1, Axis};\n\nuse moors::impl_constraints_fn;\n\n/// Equality constraint x + y = 1\nfn constraints_eq(genes: &amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt; {\n    genes.map_axis(Axis(1), |row| row[0] + row[1] - 1.0)\n}\n\nimpl_constraints_fn!(\n    MyBoundedConstraints,\n    eq   = [constraints_eq],\n    lower_bound = -1.0,\n    upper_bound = 1.0\n);\n</code></pre> <p><code>ConstraintsFn</code> trait</p> <p>Internally, <code>constraints</code> as an argument to genetic algorithms is actually any type that implements ConstraintsFn. The <code>impl_constraints_fn</code> macro creates a struct that implements this trait. The types <code>Fn(&amp;Array2&lt;f64&gt;) -&gt; Array1&lt;f64&gt;</code> and <code>Fn(&amp;Array2&lt;f64&gt;) -&gt; Array2&lt;f64&gt;</code> automatically implement this trait.</p>"},{"location":"user_guide/operators/operators.html","title":"Genetic Operators","text":"<p>Genetic operators are the core of any genetic algorithm; they are responsible for defining how individuals evolve across generations. They are formal mathematical operators defined on populations of candidate solutions, used to generate new individuals by recombining or perturbing existing ones.</p>"},{"location":"user_guide/operators/operators.html#mutation","title":"Mutation","text":"<p>Mutation is a unary genetic operator that introduces random perturbations into an individual\u2019s representation. By randomly flipping, tweaking or replacing genes, mutation maintains population diversity and enables exploration of new regions in the search space.</p> RustPython <p>A mutation operator in <code>moors</code> is any type that implements the MutationOperator trait. For example:</p> <pre><code>use ndarray::ArrayViewMut1;\nuse crate::{operators::MutationOperator, random::RandomGenerator};\n\n#[derive(Debug, Clone)]\n/// Mutation operator that flips bits in a binary individual with a specified mutation rate.\npub struct BitFlipMutation {\n    pub gene_mutation_rate: f64,\n}\n\nimpl BitFlipMutation {\n    pub fn new(gene_mutation_rate: f64) -&gt; Self {\n        Self { gene_mutation_rate }\n    }\n}\n\nimpl MutationOperator for BitFlipMutation {\n    fn mutate&lt;'a&gt;(&amp;self, mut individual: ArrayViewMut1&lt;'a, f64&gt;, rng: &amp;mut impl RandomGenerator) {\n        for gene in individual.iter_mut() {\n            if rng.gen_bool(self.gene_mutation_rate) {\n                *gene = if *gene == 0.0 { 1.0 } else { 0.0 };\n            }\n        }\n    }\n}\n</code></pre> <p>The main method to implement is <code>mutate</code>, which operates at the individual level using an <code>ndarray::ArrayViewMut1</code>. Predefined mutation operators include:</p> <p> Mutation Operator Description BitFlipMutation Randomly flips one or more bits in the binary representation, introducing small variations. GaussianMutation Adds Gaussian noise to each real-valued gene to locally explore the continuous solution space. ScrambleMutation Selects a subsequence and randomly shuffles it, preserving the original elements but altering their order. SwapMutation Swaps the positions of two randomly chosen genes to explore neighboring permutations. DisplacementMutation Extracts a block of the permutation and inserts it at another position, preserving the block\u2019s relative order. UniformRealMutation Resets a real-valued gene based on a uniform distribution. UniformBinaryMutation  Resets a bit to a random 0 or 1 . <p> </p> <p>A mutation operator in <code>pymoors</code> is just a class that defines the <code>operate</code> method:</p> <pre><code>from pymoors.typing import TwoDArray\n\nclass BitFlipMutation:\n    def __init__(self, gene_mutation_rate: float = 0.5):\n        self.gene_mutation_rate = gene_mutation_rate\n\n    def operate(\n        self,\n        population: TwoDArray,\n    ) -&gt; TwoDArray:\n        mask = np.random.random(population.shape) &lt; self.gene_mutation_rate\n        population[mask] = 1.0 - population[mask]\n        return population\n</code></pre> <p><code>operate</code> acts at poblational level, as usual it means that it takes a 2D numpy array and returns 2D array too, where each row is the evaluation of a single individual.</p> <p>There are many built-in mutation operators backed at the rust side</p> <p> Mutation Operator Description <code>pymoors.BitFlipMutation</code> Randomly flips one or more bits in the binary representation, introducing small variations. <code>pymoors.GaussianMutation</code> Adds Gaussian noise to each real-valued gene to locally explore the continuous solution space. <code>pymoors.ScrambleMutation</code> Selects a subsequence and randomly shuffles it, preserving the original elements but altering their order. <code>pymoors.SwapMutation</code> Swaps the positions of two randomly chosen genes to explore neighboring permutations. <code>pymoors.DisplacementMutation</code> Extracts a block of the permutation and inserts it at another position, preserving the block\u2019s relative order. <code>pymoors.UniformRealMutation</code> Resets a real-valued gene based on a uniform distribution. <code>pymoors.UniformBinaryMutation</code>  Resets a bit to a random 0 or 1 . </p> <p><code>operate</code> at poblational level</p> <p>in <code>moors</code> we allow the user to define the crossover at individual or poblational level, but in <code>pymoors</code> we force to work with poblational level. Technical reason is that in each user defined <code>operate</code> call we have to adquire python GIL in the rust side, poblational call requires just 1 call to the GIL.</p>"},{"location":"user_guide/operators/operators.html#crossover","title":"Crossover","text":"<p>Crossover is a binary genetic operator that combines genetic material from two parent individuals by exchanging segments of their representations, producing offspring that inherit traits from both parents. It promotes the exploration of new solution combinations while preserving useful building blocks.</p> RustPython <p>A crossover operator in <code>moors</code> is any type that implements the CrossoverOperator trait. For example:</p> <pre><code>use ndarray::{Array1, Axis, concatenate, s};\nuse crate::operators::CrossoverOperator;\nuse crate::random::RandomGenerator;\n\n#[derive(Debug, Clone)]\n/// Single-point crossover operator for binary-encoded individuals.\npub struct SinglePointBinaryCrossover;\n\nimpl CrossoverOperator for SinglePointBinaryCrossover {\n    fn crossover(\n        &amp;self,\n        parent_a: &amp;Array1&lt;f64&gt;,\n        parent_b: &amp;Array1&lt;f64&gt;,\n        rng: &amp;mut impl RandomGenerator,\n    ) -&gt; (Array1&lt;f64&gt;, Array1&lt;f64&gt;) {\n        let num_genes = parent_a.len();\n        // Select a crossover point between 1 and num_genes - 1\n        let crossover_point = rng.gen_range_usize(1, num_genes);\n        // Split parents at the crossover point and create offspring\n        let offspring_a = concatenate![\n            Axis(0),\n            parent_a.slice(s![..crossover_point]),\n            parent_b.slice(s![crossover_point..])\n        ];\n        let offspring_b = concatenate![\n            Axis(0),\n            parent_b.slice(s![..crossover_point]),\n            parent_a.slice(s![crossover_point..])\n        ];\n        (offspring_a, offspring_b)\n    }\n}\n</code></pre> <p>The main method to implement is <code>crossover</code>, which takes two parents (<code>ndarray::Array1</code>) and produces two offspring. Predefined crossover operators include:</p> <p> Crossover Operator Description ExponentialCrossover For Differential Evolution: starts at a random index and copies consecutive genes from the mutant vector while a uniform random number is below the crossover rate, then fills remaining positions from the target vector. OrderCrossover For permutations: copies a segment between two cut points from one parent, then fills the rest of the child with the remaining genes in the order they appear in the other parent. SimulatedBinaryCrossover For real-valued vectors: generates offspring by sampling each gene from a distribution centered on parent values, mimicking the spread of single-point binary crossover in continuous space. SinglePointBinaryCrossover Selects one crossover point and swaps the tails of two parents at that point to produce two offspring. UniformBinaryCrossover For each bit position, randomly chooses which parent to inherit from (with a given probability), resulting in highly mixed offspring. TwoPointBinaryCrossover Exchanges segments between two parents at two randomly chosen points to create offspring. ArithmeticCrossover Exchanges segments between two parents at two randomly chosen points to create offspring. </p> <p>A crossover operator in <code>pymoors</code> is just a class that defines the <code>operate</code> method:</p> <pre><code>from pymoors.typing import TwoDArray\n\nclass SinglePointBinaryCrossover:\n    def operate(\n        self,\n        parents_a: TwoDArray,\n        parents_b: TwoDArray,\n    ) -&gt; TwoDArray:\n        n_pairs, n_genes = parents_a.shape\n        offsprings = np.empty((2 * n_pairs, n_genes), dtype=parents_a.dtype)\n        for i in range(n_pairs):\n            a = parents_a[i]\n            b = parents_b[i]\n            point = np.random.randint(1, n_genes)\n            c1 = np.concatenate((a[:point], b[point:]))\n            c2 = np.concatenate((b[:point], a[point:]))\n            offsprings[2 * i] = c1\n            offsprings[2 * i + 1] = c2\n        return offsprings\n</code></pre> <p><code>operate</code> acts at poblational level, as usual it means that it takes two parents as 2D numpy arrays and returns a single 2D array of length twice the number of crossovers (two children per crossover).</p> <p>There are many built-in crossover operators backed at the rust side</p> <p> Crossover Operator Description <code>pymoors.ExponentialCrossover</code> For Differential Evolution: starts at a random index and copies consecutive genes from the mutant vector while a uniform random number is below the crossover rate, then fills remaining positions from the target vector. <code>pymoors.OrderCrossover</code> For permutations: copies a segment between two cut points from one parent, then fills the rest of the child with the remaining genes in the order they appear in the other parent. <code>pymoors.SimulatedBinaryCrossover</code> For real-valued vectors: generates offspring by sampling each gene from a distribution centered on parent values, mimicking the spread of single-point binary crossover in continuous space. <code>pymoors.SinglePointBinaryCrossover</code> Selects one crossover point and swaps the tails of two parents at that point to produce two offspring. <code>pymoors.UniformBinaryCrossover</code> For each bit position, randomly chooses which parent to inherit from (with a given probability), resulting in highly mixed offspring. <code>pymoors.TwoPointBinaryCrossover</code> Exchanges segments between two parents at two randomly chosen points to create offspring. <code>pymoors.ArithmeticCrossover</code> Generates offspring by computing a weighted average of two parent solutions (for each gene, child = \u03b1\u00b7parent\u2081 + (1\u2212\u03b1)\u00b7parent\u2082). </p> <p><code>operate</code> at poblational level</p> <p>in <code>moors</code> we allow the user to define the crossover at individual or poblational level, but in <code>pymoors</code> we force to work with poblational level. Technical reason is that in each user defined <code>operate</code> call we have to adquire python GIL in the rust side, poblational call requires just 1 call to the GIL.</p>"},{"location":"user_guide/operators/operators.html#sampling","title":"Sampling","text":"<p>Sampling is a genetic operator that generates new individuals by drawing samples from a defined distribution or the existing population.</p> RustPython <p>A sampling operator in <code>moors</code> is any type that implements the SamplingOperator trait. For example:</p> <pre><code>use ndarray::Array1;\nuse crate::{operators::SamplingOperator, random::RandomGenerator};\n\n/// Sampling operator for binary variables.\n#[derive(Debug, Clone)]\npub struct RandomSamplingBinary;\n\nimpl SamplingOperator for RandomSamplingBinary {\n    fn sample_individual(&amp;self, num_vars: usize, rng: &amp;mut impl RandomGenerator) -&gt; Array1&lt;f64&gt; {\n        (0..num_vars)\n            .map(|_| if rng.gen_bool(0.5) { 1.0 } else { 0.0 })\n            .collect()\n    }\n}\n</code></pre> <p>The main method to implement is <code>sample_individual</code>, which produces an individual as an <code>ndarray::Array1</code>. Predefined sampling operators include:</p> <p> Sampling Operator Description RandomSamplingBinary Generates a vector of random bits, sampling each position independently with equal probability. RandomSamplingFloat Creates a real-valued vector by sampling each gene uniformly within specified bounds. RandomSamplingInt Produces an integer vector by sampling each gene uniformly from a given range. PermutationSampling Generates a random permutation by uniformly shuffling all indices. </p> <p>A sampling operator in <code>pymoors</code> is just a class that defines the <code>operate</code> method:</p> <pre><code>from pymoors.typing import TwoDArray\n\nclass RandomSamplingBinary:\n    def operate(self, population: TwoDArray) -&gt; TwoDArray:\n        mask = np.random.random(population.shape) &lt; 0.5\n        return mask.astype(np.float64)\n</code></pre> <p><code>operate</code> acts at poblational level, as usual it means that it takes a 2D numpy array and returns 2D array too, where each row is a sampled individual.</p> <p> Sampling Operator Description <code>pymoors.RandomSamplingBinary</code> Generates a vector of random bits, sampling each position independently with equal probability. <code>pymoors.RandomSamplingFloat</code> Creates a real-valued vector by sampling each gene uniformly within specified bounds. <code>pymoors.RandomSamplingInt</code> Produces an integer vector by sampling each gene uniformly from a given range. <code>pymoors.PermutationSampling</code> Generates a random permutation by uniformly shuffling all indices. </p>"},{"location":"user_guide/operators/operators.html#selection","title":"Selection","text":"<p>Selection is a genetic operator that chooses individuals from the current population based on their fitness, favoring higher-quality solutions for reproduction.</p> RustPython <p>The selection operator is a bit more restrictive, in that each pre\u2011defined algorithm in <code>moors</code> defines exactly one selection operator. For example, the <code>NSGA-II</code> algorithm uses a ranking\u2011by\u2011crowding\u2011distance selection operator, while <code>NSGA-III</code> uses a random selection operator. The user can only provide their own selection operator to a custom algorithm\u2014not to the algorithms that come pre\u2011defined in moors.</p> <p>A selection operator in <code>moors</code> is any type that implements the SelectionOperator trait. For example:</p> <pre><code>use crate::genetic::{D01, IndividualMOO};\nuse crate::operators::selection::{DuelResult, SelectionOperator};\nuse crate::random::RandomGenerator;\n\n#[derive(Debug, Clone)]\npub struct RandomSelection;\n\nimpl SelectionOperator for RandomSelection {\n    type FDim = ndarray::Ix2;\n\n    fn tournament_duel&lt;'a, ConstrDim&gt;(\n        &amp;self,\n        p1: &amp;IndividualMOO&lt;'a, ConstrDim&gt;,\n        p2: &amp;IndividualMOO&lt;'a, ConstrDim&gt;,\n        rng: &amp;mut impl RandomGenerator,\n    ) -&gt; DuelResult\n    where\n        ConstrDim: D01,\n    {\n        if let result @ DuelResult::LeftWins | result @ DuelResult::RightWins =\n            Self::feasibility_dominates(p1, p2)\n        {\n            return result;\n        }\n        // Otherwise, both are feasible or both are infeasible =&gt; random winner.\n        if rng.gen_bool(0.5) {\n            DuelResult::LeftWins\n        } else {\n            DuelResult::RightWins\n        }\n    }\n}\n</code></pre> <p>Note that we have defined an associated type <code>type FDim = ndarray::Ix2</code>, this is because, in this example, this operator will be used for a multi\u2011objective algorithm. The selection operators defined in pymoors must specify the fitness dimension. Note that this is the selection operator used by the NSGA\u2011III algorithm: it performs a random selection that gives priority to feasibility, which is why we use the trait\u2019s static method <code>Self::feasibility_dominates</code>.</p> <p>User-defined selection operators are still in progress: See this issue for more information.</p>"},{"location":"user_guide/operators/operators.html#survival","title":"Survival","text":"<p>Survival is a genetic operator that determines which individuals are carried over to the next generation based on a general quality criterion.</p> RustPython <p>The survival operator follows the same logic than selection operator, in that each pre\u2011defined algorithm in <code>moors</code> defines exactly one selection operator. For example, the <code>NSGA-II</code> algorithm uses a ranking\u2011by\u2011crowding\u2011distance survival operator, while <code>NSGA-III</code> uses a reference points based operator. The user can only provide their own survival operator to a custom algorithm\u2014not to the algorithms that come pre\u2011defined in moors.</p> <p>A survival operator in <code>moors</code> is any type that implements the SurvivalOperator trait. For example:</p> <pre><code>use crate::genetic::{D01, IndividualMOO};\nuse crate::operators::selection::{DuelResult, SelectionOperator};\nuse crate::random::RandomGenerator;\n\n#[derive(Debug, Clone)]\npub struct RandomSelection;\n\nimpl SelectionOperator for RandomSelection {\n    type FDim = ndarray::Ix2;\n\n    fn tournament_duel&lt;'a, ConstrDim&gt;(\n        &amp;self,\n        p1: &amp;IndividualMOO&lt;'a, ConstrDim&gt;,\n        p2: &amp;IndividualMOO&lt;'a, ConstrDim&gt;,\n        rng: &amp;mut impl RandomGenerator,\n    ) -&gt; DuelResult\n    where\n        ConstrDim: D01,\n    {\n        if let result @ DuelResult::LeftWins | result @ DuelResult::RightWins =\n            Self::feasibility_dominates(p1, p2)\n        {\n            return result;\n        }\n        // Otherwise, both are feasible or both are infeasible =&gt; random winner.\n        if rng.gen_bool(0.5) {\n            DuelResult::LeftWins\n        } else {\n            DuelResult::RightWins\n        }\n    }\n}\n</code></pre> <p>Note that we have defined an associated type <code>type FDim = ndarray::Ix2</code>, this is because, in this example, this operator will be used for a multi\u2011objective algorithm. The selection operators defined in moors must specify the fitness dimension. Note that this is the selection operator used by the NSGA\u2011III algorithm: it performs a random selection that gives priority to feasibility, which is why we use the trait\u2019s static method <code>Self::feasibility_dominates</code>.</p> <p>User-defined survival operators are still in progress: See this issue for more information.</p>"},{"location":"user_guide/operators/python/crossover.html","title":"Crossover","text":"<p>A crossover operator in <code>pymoors</code> is just a class that defines the <code>operate</code> method:</p> <pre><code>from pymoors.typing import TwoDArray\n\nclass SinglePointBinaryCrossover:\n    def operate(\n        self,\n        parents_a: TwoDArray,\n        parents_b: TwoDArray,\n    ) -&gt; TwoDArray:\n        n_pairs, n_genes = parents_a.shape\n        offsprings = np.empty((2 * n_pairs, n_genes), dtype=parents_a.dtype)\n        for i in range(n_pairs):\n            a = parents_a[i]\n            b = parents_b[i]\n            point = np.random.randint(1, n_genes)\n            c1 = np.concatenate((a[:point], b[point:]))\n            c2 = np.concatenate((b[:point], a[point:]))\n            offsprings[2 * i] = c1\n            offsprings[2 * i + 1] = c2\n        return offsprings\n</code></pre> <p><code>operate</code> acts at poblational level, as usual it means that it takes two parents as 2D numpy arrays and returns a single 2D array of length twice the number of crossovers (two children per crossover).</p> <p>There are many built-in crossover operators backed at the rust side</p> Crossover Operator Description `pymoors.ExponentialCrossover` For Differential Evolution: starts at a random index and copies consecutive genes from the mutant vector while a uniform random number is below the crossover rate, then fills remaining positions from the target vector. `pymoors.OrderCrossover` For permutations: copies a segment between two cut points from one parent, then fills the rest of the child with the remaining genes in the order they appear in the other parent. `pymoors.SimulatedBinaryCrossover` For real-valued vectors: generates offspring by sampling each gene from a distribution centered on parent values, mimicking the spread of single-point binary crossover in continuous space. `pymoors.SinglePointBinaryCrossover` Selects one crossover point and swaps the tails of two parents at that point to produce two offspring. `pymoors.UniformBinaryCrossover` For each bit position, randomly chooses which parent to inherit from (with a given probability), resulting in highly mixed offspring. `pymoors.TwoPointBinaryCrossover` Exchanges segments between two parents at two randomly chosen points to create offspring. `pymoors.ArithmeticCrossover` Generates offspring by computing a weighted average of two parent solutions (for each gene, child = \u03b1\u00b7parent\u2081 + (1\u2212\u03b1)\u00b7parent\u2082). <p><code>operate</code> at poblational level</p> <p>in <code>moors</code> we allow the user to define the crossover at individual or poblational level, but in <code>pymoors</code> we force to work with poblational level. Technical reason is that in each user defined <code>operate</code> call we have to adquire python GIL in the rust side, poblational call requires just 1 call to the GIL.</p>"},{"location":"user_guide/operators/python/mutation.html","title":"Mutation","text":"<p>A mutation operator in <code>pymoors</code> is just a class that defines the <code>operate</code> method:</p> <pre><code>from pymoors.typing import TwoDArray\n\nclass BitFlipMutation:\n    def __init__(self, gene_mutation_rate: float = 0.5):\n        self.gene_mutation_rate = gene_mutation_rate\n\n    def operate(\n        self,\n        population: TwoDArray,\n    ) -&gt; TwoDArray:\n        mask = np.random.random(population.shape) &lt; self.gene_mutation_rate\n        population[mask] = 1.0 - population[mask]\n        return population\n</code></pre> <p><code>operate</code> acts at poblational level, as usual it means that it takes a 2D numpy array and returns 2D array too, where each row is the evaluation of a single individual.</p> <p>There are many built-in mutation operators backed at the rust side</p> Mutation Operator Description `pymoors.BitFlipMutation`  Randomly flips one or more bits in the binary representation, introducing small variations. `pymoors.GaussianMutation` Adds Gaussian noise to each real-valued gene to locally explore the continuous solution space. `pymoors.ScrambleMutation`  Selects a subsequence and randomly shuffles it, preserving the original elements but altering their order. `pymoors.SwapMutation`  Swaps the positions of two randomly chosen genes to explore neighboring permutations. `pymoors.DisplacementMutation` Extracts a block of the permutation and inserts it at another position, preserving the block\u2019s relative order. `pymoors.UniformRealMutation` Resets a real-valued gene based on a uniform distribution. `pymoors.UniformBinaryMutation`  Resets a bit to a random 0 or 1 . <p><code>operate</code> at poblational level</p> <p>in <code>moors</code> we allow the user to define the crossover at individual or poblational level, but in <code>pymoors</code> we force to work with poblational level. Technical reason is that in each user defined <code>operate</code> call we have to adquire python GIL in the rust side, poblational call requires just 1 call to the GIL.</p>"},{"location":"user_guide/operators/python/sampling.html","title":"Sampling","text":"<p>A sampling operator in <code>pymoors</code> is just a class that defines the <code>operate</code> method:</p> <pre><code>from pymoors.typing import TwoDArray\n\nclass RandomSamplingBinary:\n    def operate(self, population: TwoDArray) -&gt; TwoDArray:\n        mask = np.random.random(population.shape) &lt; 0.5\n        return mask.astype(np.float64)\n</code></pre> <p><code>operate</code> acts at poblational level, as usual it means that it takes a 2D numpy array and returns 2D array too, where each row is a sampled individual.</p> Sampling Operator Description `pymoors.RandomSamplingBinary` Generates a vector of random bits, sampling each position independently with equal probability. `pymoors.RandomSamplingFloat` Creates a real-valued vector by sampling each gene uniformly within specified bounds. `pymoors.RandomSamplingInt` Produces an integer vector by sampling each gene uniformly from a given range. `pymoors.PermutationSampling` Generates a random permutation by uniformly shuffling all indices."},{"location":"user_guide/operators/python/selection.html","title":"Selection","text":"<p>User-defined selection operators are still in progress: See this issue for more information.</p>"},{"location":"user_guide/operators/python/survival.html","title":"Survival","text":"<p>User-defined survival operators are still in progress: See this issue for more information.</p>"},{"location":"user_guide/operators/rust/crossover.html","title":"Crossover","text":"<p>A crossover operator in <code>moors</code> is any type that implements the CrossoverOperator trait. For example:</p> <pre><code>use ndarray::{Array1, Axis, concatenate, s};\nuse crate::operators::CrossoverOperator;\nuse crate::random::RandomGenerator;\n\n#[derive(Debug, Clone)]\n/// Single-point crossover operator for binary-encoded individuals.\npub struct SinglePointBinaryCrossover;\n\nimpl CrossoverOperator for SinglePointBinaryCrossover {\n    fn crossover(\n        &amp;self,\n        parent_a: &amp;Array1&lt;f64&gt;,\n        parent_b: &amp;Array1&lt;f64&gt;,\n        rng: &amp;mut impl RandomGenerator,\n    ) -&gt; (Array1&lt;f64&gt;, Array1&lt;f64&gt;) {\n        let num_genes = parent_a.len();\n        // Select a crossover point between 1 and num_genes - 1\n        let crossover_point = rng.gen_range_usize(1, num_genes);\n        // Split parents at the crossover point and create offspring\n        let offspring_a = concatenate![\n            Axis(0),\n            parent_a.slice(s![..crossover_point]),\n            parent_b.slice(s![crossover_point..])\n        ];\n        let offspring_b = concatenate![\n            Axis(0),\n            parent_b.slice(s![..crossover_point]),\n            parent_a.slice(s![crossover_point..])\n        ];\n        (offspring_a, offspring_b)\n    }\n}\n</code></pre> <p>The main method to implement is <code>crossover</code>, which takes two parents (<code>ndarray::Array1</code>) and produces two offspring. Predefined crossover operators include:</p> Crossover Operator Description ExponentialCrossover For Differential Evolution: starts at a random index and copies consecutive genes from the mutant vector while a uniform random number is below the crossover rate, then fills remaining positions from the target vector. OrderCrossover For permutations: copies a segment between two cut points from one parent, then fills the rest of the child with the remaining genes in the order they appear in the other parent. SimulatedBinaryCrossover For real-valued vectors: generates offspring by sampling each gene from a distribution centered on parent values, mimicking the spread of single-point binary crossover in continuous space. SinglePointBinaryCrossover Selects one crossover point and swaps the tails of two parents at that point to produce two offspring. UniformBinaryCrossover For each bit position, randomly chooses which parent to inherit from (with a given probability), resulting in highly mixed offspring. TwoPointBinaryCrossover Exchanges segments between two parents at two randomly chosen points to create offspring. ArithmeticCrossover Exchanges segments between two parents at two randomly chosen points to create offspring."},{"location":"user_guide/operators/rust/mutation.html","title":"Mutation","text":"<p>A mutation operator in <code>moors</code> is any type that implements the MutationOperator trait. For example:</p> <pre><code>use ndarray::ArrayViewMut1;\nuse crate::{operators::MutationOperator, random::RandomGenerator};\n\n#[derive(Debug, Clone)]\n/// Mutation operator that flips bits in a binary individual with a specified mutation rate.\npub struct BitFlipMutation {\n    pub gene_mutation_rate: f64,\n}\n\nimpl BitFlipMutation {\n    pub fn new(gene_mutation_rate: f64) -&gt; Self {\n        Self { gene_mutation_rate }\n    }\n}\n\nimpl MutationOperator for BitFlipMutation {\n    fn mutate&lt;'a&gt;(&amp;self, mut individual: ArrayViewMut1&lt;'a, f64&gt;, rng: &amp;mut impl RandomGenerator) {\n        for gene in individual.iter_mut() {\n            if rng.gen_bool(self.gene_mutation_rate) {\n                *gene = if *gene == 0.0 { 1.0 } else { 0.0 };\n            }\n        }\n    }\n}\n</code></pre> <p>The main method to implement is <code>mutate</code>, which operates at the individual level using an <code>ndarray::ArrayViewMut1</code>. Predefined mutation operators include:</p> Mutation Operator Description BitFlipMutation Randomly flips one or more bits in the binary representation, introducing small variations. GaussianMutation Adds Gaussian noise to each real-valued gene to locally explore the continuous solution space. ScrambleMutation Selects a subsequence and randomly shuffles it, preserving the original elements but altering their order. SwapMutation Swaps the positions of two randomly chosen genes to explore neighboring permutations. DisplacementMutation Extracts a block of the permutation and inserts it at another position, preserving the block\u2019s relative order. UniformRealMutation Resets a real-valued gene based on a uniform distribution. UniformBinaryMutation  Resets a bit to a random 0 or 1 ."},{"location":"user_guide/operators/rust/sampling.html","title":"Sampling","text":"<p>A sampling operator in <code>moors</code> is any type that implements the SamplingOperator trait. For example:</p> <pre><code>use ndarray::Array1;\nuse crate::{operators::SamplingOperator, random::RandomGenerator};\n\n/// Sampling operator for binary variables.\n#[derive(Debug, Clone)]\npub struct RandomSamplingBinary;\n\nimpl SamplingOperator for RandomSamplingBinary {\n    fn sample_individual(&amp;self, num_vars: usize, rng: &amp;mut impl RandomGenerator) -&gt; Array1&lt;f64&gt; {\n        (0..num_vars)\n            .map(|_| if rng.gen_bool(0.5) { 1.0 } else { 0.0 })\n            .collect()\n    }\n}\n</code></pre> <p>The main method to implement is <code>sample_individual</code>, which produces an individual as an <code>ndarray::Array1</code>. Predefined sampling operators include:</p> Sampling Operator Description RandomSamplingBinary Generates a vector of random bits, sampling each position independently with equal probability. RandomSamplingFloat Creates a real-valued vector by sampling each gene uniformly within specified bounds. RandomSamplingInt Produces an integer vector by sampling each gene uniformly from a given range. PermutationSampling Generates a random permutation by uniformly shuffling all indices."},{"location":"user_guide/operators/rust/selection.html","title":"Selection","text":"<p>The selection operator is a bit more restrictive, in that each pre\u2011defined algorithm in <code>moors</code> defines exactly one selection operator. For example, the <code>NSGA-II</code> algorithm uses a ranking\u2011by\u2011crowding\u2011distance selection operator, while <code>NSGA-III</code> uses a random selection operator. The user can only provide their own selection operator to a custom algorithm\u2014not to the algorithms that come pre\u2011defined in moors.</p> <p>A selection operator in <code>moors</code> is any type that implements the SelectionOperator trait. For example:</p> <pre><code>use crate::genetic::{D01, IndividualMOO};\nuse crate::operators::selection::{DuelResult, SelectionOperator};\nuse crate::random::RandomGenerator;\n\n#[derive(Debug, Clone)]\npub struct RandomSelection;\n\nimpl SelectionOperator for RandomSelection {\n    type FDim = ndarray::Ix2;\n\n    fn tournament_duel&lt;'a, ConstrDim&gt;(\n        &amp;self,\n        p1: &amp;IndividualMOO&lt;'a, ConstrDim&gt;,\n        p2: &amp;IndividualMOO&lt;'a, ConstrDim&gt;,\n        rng: &amp;mut impl RandomGenerator,\n    ) -&gt; DuelResult\n    where\n        ConstrDim: D01,\n    {\n        if let result @ DuelResult::LeftWins | result @ DuelResult::RightWins =\n            Self::feasibility_dominates(p1, p2)\n        {\n            return result;\n        }\n        // Otherwise, both are feasible or both are infeasible =&gt; random winner.\n        if rng.gen_bool(0.5) {\n            DuelResult::LeftWins\n        } else {\n            DuelResult::RightWins\n        }\n    }\n}\n</code></pre> <p>Note that we have defined an associated type <code>type FDim = ndarray::Ix2</code>, this is because, in this example, this operator will be used for a multi\u2011objective algorithm. The selection operators defined in pymoors must specify the fitness dimension. Note that this is the selection operator used by the NSGA\u2011III algorithm: it performs a random selection that gives priority to feasibility, which is why we use the trait\u2019s static method <code>Self::feasibility_dominates</code>.</p>"},{"location":"user_guide/operators/rust/survival.html","title":"Survival","text":"<p>The survival operator follows the same logic than selection operator, in that each pre\u2011defined algorithm in <code>moors</code> defines exactly one selection operator. For example, the <code>NSGA-II</code> algorithm uses a ranking\u2011by\u2011crowding\u2011distance survival operator, while <code>NSGA-III</code> uses a reference points based operator. The user can only provide their own survival operator to a custom algorithm\u2014not to the algorithms that come pre\u2011defined in moors.</p> <p>A survival operator in <code>moors</code> is any type that implements the SurvivalOperator trait. For example:</p> <pre><code>use crate::genetic::{D01, IndividualMOO};\nuse crate::operators::selection::{DuelResult, SelectionOperator};\nuse crate::random::RandomGenerator;\n\n#[derive(Debug, Clone)]\npub struct RandomSelection;\n\nimpl SelectionOperator for RandomSelection {\n    type FDim = ndarray::Ix2;\n\n    fn tournament_duel&lt;'a, ConstrDim&gt;(\n        &amp;self,\n        p1: &amp;IndividualMOO&lt;'a, ConstrDim&gt;,\n        p2: &amp;IndividualMOO&lt;'a, ConstrDim&gt;,\n        rng: &amp;mut impl RandomGenerator,\n    ) -&gt; DuelResult\n    where\n        ConstrDim: D01,\n    {\n        if let result @ DuelResult::LeftWins | result @ DuelResult::RightWins =\n            Self::feasibility_dominates(p1, p2)\n        {\n            return result;\n        }\n        // Otherwise, both are feasible or both are infeasible =&gt; random winner.\n        if rng.gen_bool(0.5) {\n            DuelResult::LeftWins\n        } else {\n            DuelResult::RightWins\n        }\n    }\n}\n</code></pre> <p>Note that we have defined an associated type <code>type FDim = ndarray::Ix2</code>, this is because, in this example, this operator will be used for a multi\u2011objective algorithm. The selection operators defined in moors must specify the fitness dimension. Note that this is the selection operator used by the NSGA\u2011III algorithm: it performs a random selection that gives priority to feasibility, which is why we use the trait\u2019s static method <code>Self::feasibility_dominates</code>.</p>"}]}